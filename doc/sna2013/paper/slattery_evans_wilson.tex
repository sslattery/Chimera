\documentclass{snamc2013}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}  % allows inclusion of graphics
\usepackage{booktabs}  % nice rules (thick lines) for tables
\usepackage{microtype} % improves typography for PDF
\usepackage{tabls}
\usepackage{afterpage}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage[mathcal]{euscript}

\usepackage[breaklinks=true,colorlinks=true,linkcolor=black,citecolor=black]{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{A Multiple-Set Overlapping-Domain Decomposed Monte Carlo
  Synthetic Acceleration Method for Linear Systems}

\author[1]{Stuart R. Slattery}
\author[2]{Thomas M. Evans}
\author[1]{Paul P.H. Wilson}

\affil[1]{University of Wisconsin - Madison, Engineering Physics
  Department, 1500 Engineering Dr., Madison, WI 53716}
\affil[2]{Oak Ridge National Laboratory, Reactor and Nuclear Systems
  Division, 1 Bethel Valley Rd., Oak Ridge, TN 37831}

\abstract{We present a novel multiple-set overlapping-domain
  decomposed strategy for parallelizing the Monte Carlo Synthetic
  Acceleration (MCSA) method. MCSA methods use the Neumann-Ulam class
  of Monte Carlo solvers for linear systems to accelerate the fixed
  point method on which the Neumann-Ulam solvers are based. To
  effectively parallelize MCSA methods requires the parallelization of
  the underlying Neumann-Ulam solvers. To do this in a domain
  decomposed environment, we borrow strategies traditionally
  implemented in Monte Carlo particle transport to parallelize the
  problem. The multiple-set overlapping-domain decomposition algorithm
  is presented along with parallel scaling data for the resulting
  implementation using the Titan Cray XK7 machine at Oak Ridge
  National Laboratory.}

\keywords{MCSA, Monte Carlo, domain decomposition, linear solvers,
  parallel computing}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

For some time, the particle transport community has utilized Monte
Carlo methods for the solution of transport problems
\cite{lewis_computational_1993}. The partial differential equation
(PDE) community has focused on various deterministic methods for
solutions to linear problems \cite{saad_iterative_2003,
  kelley_iterative_1995}. In between these two areas are a not widely
known group of Monte Carlo methods for solving sparse linear systems
\cite{forsythe_matrix_1950, hammersley_monte_1964,
  halton_sequential_1962, halton_sequential_1994}. In recent years,
these methods have been further developed for radiation transport
problems in the form of Monte Carlo Synthetic Acceleration (MCSA)
\cite{evans_monte_2009, evans_monte_2012} but have yet to be applied
to more general sparse linear systems commonly generated by the
computational physics community. Compared to other methods in this
regime, MCSA offers three attractive qualities; (1) the physics
operator need not be symmetric or positive-definite, (2) the
stochastic nature of the solution method provides a natural solution
to some aspects of the issue of resiliency, and (3) is amenable to
parallelization using modern methods developed by the transport
community \cite{wagner_hybrid_2010}. The development a parallel MCSA
algorithm using techniques is the primary contribution of this work.

As leadership class machines move beyond the petascale, new algorithms
must be developed that leverage their strengths and adapt to their
shortcomings. Basic research is required now to advance methods in
time for these new machines to become operational. As machines begin
to operate at hundreds of petaflops peak performance and beyond,
trends toward reduced energy consumption will require incredibly high
levels of concurrency to achieve the desired computation rates
\cite{kogge_using_2011}. The end result of these hardware changes is
that the larger number of low-powered processors will be prone to both
soft failures such as bit errors in floating point operations and hard
failures where the data owned by that processor cannot be
recovered. Because these failures are predicted to be common,
resilient solver technologies are required to overcome these events at
the application level. With linear solvers based on Monte Carlo
techniques, such issues are potentially alleviated by statistical
arguments. In the case of soft failures, isolated floating point
errors in the Monte Carlo simulation are absorbed within tally
statistics. Completely losing memory during a hard failure is treated
as a high variance event where some portion of the Monte Carlo
histories and subsequently the solution are lost with other histories
maintained by replicating the problem and combining the results
through superposition.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Monte Carlo Methods}
Monte Carlo Synthetic Acceleration (MCSA) methods rely the
Neumann-Ulam class of linear solver to accelerate the stationary
method. These Monte Carlo methods work by sampling a distribution with
an expectation value equivalent to that of the inverted
operator. Neumann and Ulam's work was first published in 1950 by
Forsythe and Leibler \cite{forsythe_matrix_1950} with a time frame for
the creation of the method some years earlier than its publication. In
the following decade, the books of Hammersley and Handscomb
\cite{hammersley_monte_1964} and Spanier and Gelbard
\cite{spanier_monte_1969} present additional detail on these solvers.
In this section we briefly present the Neumann-Ulam Monte Carlo method
for solving linear systems and then present the Monte Carlo Synthetic
Acceleration method.

\subsection{Neumann-Ulam Method}
We seek solutions of the general linear problem in the following form:
\begin{equation}
  \mathbf{A} \mathbf{x} = \mathbf{b}\:,
  \label{eq:linear_problem}
\end{equation}
where $\mathbf{A} \in \mathbb{R}^{N \times N}$ is a matrix operator
such that $\mathbf{A} : \mathbb{R}^{N} \rightarrow \mathbb{R}^{N}$,
$\mathbf{x} \in \mathbb{R}^N$ is the solution vector, and $\mathbf{b}
\in \mathbb{R}^N$ is the forcing term.  For a given linear operator
$\mathbf{A}$, we can use diagonal splitting to define the
\textit{iteration matrix}, $\mathbf{H}$:
\begin{equation}
  \mathbf{H} = \mathbf{I} - \mathbf{A}\:,
  \label{eq:linear_mc_iteration_matrix}
\end{equation}
such that we are solving the system:
\begin{equation}
  \mathbf{x} = \mathbf{H} \mathbf{x} + \mathbf{b}\:.
  \label{eq:richardson_split}
\end{equation}
We can then form an alternative representation for $\mathbf{A}^{-1}$
by generating the \textit{Neumann series} solution:
\begin{equation}
  \mathbf{A}^{-1}\mathbf{b} = \sum_{k=0}^{\infty}
  \mathbf{H}^k\mathbf{b} = \mathbf{x}\:,
  \label{eq:neumann_solution}
\end{equation}
which will converge if the spectral radius of $\mathbf{H}$ is less
than 1. If we expand the summation with a succession of matrix-vector
multiply operations, we arrive at an alternative perspective of this
summation by considering the $i^{th}$ component of the solution
vector:
\begin{equation}
  x_i = \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
  \sum_{i_k}^{N}h_{i,i_1}h_{i_1,i_2}\ldots h_{i_{k-1},i_k}b_{i_k}\:,
  \label{eq:expanded_neumann_solution}
\end{equation}
which can interpreted as a series of transitions between states,
\begin{equation}
 \nu = i \rightarrow i_1 \rightarrow \cdots \rightarrow i_{k-1}
 \rightarrow i_{k}\:,
  \label{eq:mc_walk_permutation}
\end{equation}
in $\mathbf{H}$ where $\nu$ is interpreted as a particular sequence
permutation. We can generate these sequences of transitions through
Monte Carlo random walks by assigning them both a probability and
weight. Using the adjoint form \cite{spanier_monte_1969},
probabilities are column-scaled:
\begin{equation}
  p_{ij} = \frac{|h_{ji}|}{\sum_j |h_{ji}|}\:,
  \label{eq:adjoint_probability}
\end{equation}
such that we expect to select a new state, $j$, from the current state
in the random walk, $i$, by sampling column-wise (or row-wise if an
adjoint probability matrix is formed). The transition weight is then
defined as:
\begin{equation}
  w_{ij} = \frac{h_{ji}}{p_{ij}}\:.
  \label{eq:adjoint_weight}
\end{equation}
The initial state $i_0$ of the random walk is determined by sampling
the source vector $\mathbf{b}$ with probabilities:
\begin{equation}
  P_{(i_0=i)}(\nu) = \frac{|b_i|}{||\mathbf{b}||_1}\:,
  \label{eq:adjoint_source_probability}
\end{equation}
with a random walk starting weight of:
\begin{equation}
  W_0 = ||\mathbf{b}||_1 \frac{b_i}{|b_i|}\:.
  \label{eq:adjoint_starting_weight}
\end{equation}
The contribution to the solution in state $j$ from a particular random
walk permutation of $k$ events is then the \textit{collision
  estimator}:
\begin{equation}
  X_{j}(\nu) = \sum_{m=0}^k W_{m} \delta_{i_m,j}\:,
  \label{eq:adjoint_permutation_contribution}
\end{equation}
where the Kronecker delta indicates that the tally contributes only in
the current state, $i_m$, of the random walk and 
\begin{equation}
  W_{m} = W_0 w_{i_0,i_1} w_{i_1,i_2} \cdots w_{i_{m-1},i_m}\:.
  \label{eq:adjoint_permutation_weight}
\end{equation}
Finally, the expectation value using all permutations is:
\begin{equation}
  E\{X_j\} = \sum_{\nu} P_{\nu} X_{j}(\nu)\:,
  \label{eq:adjoint_expectation_value}
\end{equation}
with
\begin{equation}
  P_{\nu} = P_{(i_0=i)} p_{i,i_1} p_{i_1,i_2} \cdots p_{i_{k-1},i_k}\:.
  \label{eq:adjoint_permutation_probability}
\end{equation}

\subsection{Monte Carlo Synthetic Acceleration}
Using the ideas of Halton's residual method
\cite{halton_sequential_1994}, Evans and Mosher recently developed a
Monte Carlo solution method that was not prohibited severely by the
quality of the initial guess for the system \cite{evans_monte_2009}
and later applied it more rigorously as a solution mechanism for the
radiation diffusion equation \cite{evans_monte_2012}. With their new
methods, they achieved identical numerical results as and marginally
better performance than conventional Krylov solvers. Their approach
was instead to use residual Monte Carlo as a synthetic acceleration
for a stationary method. 

The \textit{Fixed-Point Monte Carlo Synthetic Acceleration} (MCSA)
method is defined as:
\begin{subequations}
  \begin{gather}
    \mathbf{r}^{k} = \mathbf{b} - \mathbf{A}\mathbf{x}^{k}\:,\\
    \mathbf{x}^{k+1/2} = \mathbf{x}^k + \mathbf{r}^k\:,\\
    \mathbf{r}^{k+1/2} = \mathbf{b} - \mathbf{A}\mathbf{x}^{k+1/2}\:,\\
    \label{eq:mcsa_mc_solve}
    \mathbf{A}\delta\mathbf{x}^{k+1/2} = \mathbf{r}^{k+1/2}\:,\\
    \mathbf{x}^{k+1} = \mathbf{x}^{k+1/2} + \delta \mathbf{x}^{k+1/2}\:,
  \end{gather}
  \label{eq:mcsa}
\end{subequations}
where $\mathbf{r}$ is the residual vector, $\delta\mathbf{x}$ is the
Monte Carlo correction vector, and $k$ indicates the iteration
index. Here, a Neumann-Ulam Monte Carlo method is used to generate the
solution correction in Eq~\ref{eq:mcsa_mc_solve} from the residual and
Richardson's iteration in the first step has been rewritten as a
residual correction. Using Monte Carlo in this way achieves the same
effect as Halton's method, decoupling its convergence rate from the
overall convergence rate of the method. Here, the approximate Monte
Carlo solution is not driven to a particular convergence as it merely
supplies a correction for the initial guess generated by Richardson's
iteration. Rather, only a set number of random walk permuations are
required using the Neumann-Ulam method to generate the correction. In
addition to the Monte Carlo solver parameters dictating the number of
histories and weight cutoff, the outer MCSA iterations also have the
following stopping criteria:
\begin{equation}
  ||\mathbf{r}||_\infty < \epsilon \ ||\mathbf{b}||_\infty\:,
  \label{eq:mcsa_stopping_criteria}
\end{equation}
where $\epsilon$ is a user-defined parameter. We refer the reader to
\cite{evans_monte_2012} and \cite{evans_monte_2009} for a more
detailed explanation and analysis of MCSA and the Neumann-Ulam
methods.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Parallel MCSA Algorithm}

\subsection{Parallel Neumann-Ulam Algorithm}
In the literature, current implementations of parallel Neumann-Ulam
methods have been limited to full domain replication with parallelism
exploited through individual histories
\cite{alexandrov_efficient_1998}. For high performance computing
environments, domain decomposition strategies have been identified as
important for Monte Carlo applications
\cite{brunner_comparison_2006,siegel_analysis_2012}. In a domain
decomposed Monte Carlo implementation, stochastic histories must be
communicated between domains as the simulation progresses and they
transition to locations outside of the local domain. In order to
implement domain decomposition strategy for Monte Carlo solvers in a
parallel environment, communication of these histories must occur
between compute nodes owning neighboring pieces of the global domain.


\subsection{MSOD Algorithm}
At the 2010 SNA+MC meeting, Wagner and colleagues presented the
\textit{multiple-set overlapping-domain} (MSOD) decomposition method
for parallel Monte Carlo applications for full-core light water
reactor analysis \cite{wagner_hybrid_2010}. In their work, overlap
between adjacent domains in the decomposition was used to decrease the
number of particles leaving the local domain. In addition, Wagner
utilized a level of replication of the domain such that the domain was
only decomposed on $O(100)$ processors and if replicated $O(1,000)$
times achieves simulation on $O(100,000)$ processors, thus providing
spatial and particle parallelism. Each collection of processors that
constitutes a representation of the entire domain is referred to as a
set, and within a set overlap occurs among its sub-domains. The
original motivation was to decompose the domain in a way that it
remained in a physical cabinet in a large distributed machine, thus
reducing latency costs during communication. A multiple set scheme is
also motivated by the fact that communication during particle
transport only occurs within a set, limiting communications during the
transport procedure to a group of $O(100)$ processors, a number that
was shown to have excellent parallel efficiencies in Brunner's work
\cite{brunner_efficient_2009} and therefore will scale well in this
algorithm. The overlapping domains within each set also demonstrated
reduced communication costs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Parallel Scaling Studies}

\subsection{Overlap Scaling}

\subsection{Multiple Sets Scaling}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}

It was found the MCSA can indeed be effectively parallelized using the
multiple-set overlapping-domain decomposition algorithm borrowed from
the reactor physics community.  The new algorithm was tested in a wide
variety of parallel scaling studies on the Titan Cray XK7 machine at
the Oak Ridge Leadership Computing Facility. To test the algorithm at
high levels of concurrency, up to 65,356 cores were used in strong
scaling exercises and 131,072 cores used in weak scaling exercises
using the neutron diffusion problem.

Scaling studies showed that in the strong case overlap in small
quantities on the order of the mean-free-path of a stochastic history
in the simulation could boost parallel efficiencies by up to 10\% in
isolated cases. However, it was found that this additional overlap was
not effective in boosting weak scaling efficiencies. In general,
overlap was not very effective due to the fact that the parallel
communication saved during the Monte Carlo transport sequence is
simply deferred until after transport is complete when it manifests
itself as an overlapping parallel vector reduction operation. As
compared to transport calculations where this overlap procedure was
very effective, in the context of MCSA the Monte Carlo calculations
are significantly shorter with $O(10,000)$ histories used in this
work. These shorter calculations and more frequent overlapping tally
vector reductions create an overhead that is not observed in the
literature for transport calculations.

Applying multiple sets in the parallel algorithm was found to not
enhance the weak scaling of the problem as an additional parallel
overhead is introduced when the calculations from the set are combined
in superposition. For the strong scaling case, improvements were not
noted until after the strong scaling wall was hit. At this point,
multiple sets were observed to increase parallel efficiencies from
38\% to 58\% at 16,384 cores. Perhaps more important here is the fact
that although the parallel efficiency was reduced, multiple sets were
observed to actually improve the time to solution. Unlike a
traditional Krylov method that we might apply to solve a neutron
transport problem, using MCSA means that we can actually make a
physical copy of the problem on the machine and can combine separate
Monte Carlo solutions for each copy through superposition. Time to
solution is then improved because fewer histories were run in each
copy and therefore each MCSA iteration is faster or more global
histories are computed and fewer MCSA iterations are required to
converge.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments}

This work was performed under appointment to the Nuclear Regulatory
Commission Fellowship program at the University of Wisconsin - Madison
Department of Engineering Physics.

This research used resources of the Oak Ridge Leadership Computing
Facility at the Oak Ridge National Laboratory, which is supported by
the Office of Science of the U.S. Department of Energy under Contract
No. DE-AC05-00OR22725.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ans}
\bibliography{references}
\end{document}
