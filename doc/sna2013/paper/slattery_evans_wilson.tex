\documentclass{snamc2013}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\usepackage{graphicx}  % allows inclusion of graphics
\usepackage{booktabs}  % nice rules (thick lines) for tables
\usepackage{microtype} % improves typography for PDF

\usepackage[breaklinks=true,colorlinks=true,linkcolor=black,citecolor=black]{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title{A Multiple-Set Overlapping-Domain Decomposed Monte Carlo
  Synthetic Acceleration Method for Linear Systems}

\author[1]{Stuart R. Slattery}
\author[2]{Thomas M. Evans}
\author[1]{Paul P.H. Wilson}

\affil[1]{University of Wisconsin - Madison, Engineering Physics
  Department, 1500 Engineering Dr., Madison, WI 53716}
\affil[2]{Oak Ridge National Laboratory, Reactor and Nuclear Systems
  Division, 1 Bethel Valley Rd., Oak Ridge, TN 37831}

\abstract{We present a novel multiple-set overlapping-domain
  decomposed strategy for parallelizing the Monte Carlo Synthetic
  Acceleration (MCSA) method. MCSA methods use the Neumann-Ulam class
  of Monte Carlo solvers for linear systems to accelerate the fixed
  point method on which the Neumann-Ulam solvers are based. To
  effectively parallelize MCSA methods requires the parallelization of
  the underlying Neumann-Ulam solvers. To do this in a domain
  decomposed environment, we borrow strategies traditionally
  implemented in Monte Carlo particle transport to parallelize the
  problem. The multiple-set overlapping-domain decomposition algorithm
  is presented along with parallel scaling data for the resulting
  implementation using the Titan Cray XK7 machine at Oak Ridge
  National Laboratory.}

\keywords{MCSA, Monte Carlo, domain decomposition, linear solvers,
  parallel computing}

\begin{document}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

For some time, the particle transport community has been utilizing
Monte Carlo methods for the solution of transport problems
\cite{lewis_computational_1993}. The partial differential equation
(PDE) community has focused on various deterministic methods for
solutions to linear problems \cite{saad_iterative_2003}. In between
these two areas are a not widely known group of Monte Carlo methods
for solving sparse linear systems \cite{forsythe_matrix_1950,
  hammersley_monte_1964, halton_sequential_1962,
  halton_sequential_1994}. In recent years, these methods have been
further developed for radiation transport problems in the form of
Monte Carlo Synthetic-Acceleration (MCSA) \cite{evans_monte_2009,
  evans_monte_2012} but have yet to be applied to more general sparse
linear systems commonly generated by the computational physics
community. Compared to other methods in this regime, MCSA offers three
attractive qualities; (1) the linear problem operator need not be
symmetric or positive-definite, thereby reducing preconditioning
complexity and widening applicability, (2) the stochastic nature of
the solution method provides a natural solution to the issue of
resiliency, and (3) is amenable to parallelization using modern
methods developed by the transport community
\cite{wagner_hybrid_2010}. The development of MCSA as a general linear
solver and the development of a parallel MCSA method will be new and
unique features of this work, providing a framework with which other
issues such as resiliency may be addressed in the future.

As leadership class machines move towards the exascale, new algorithms
must be developed that leverage their strengths and adapt to their
shortcomings. Looking towards machines operating at hundreds of
petaflops peak performance and beyond, trends toward reduced energy
consumption will require incredibly high levels of concurrency to
achieve the desired computation rates \cite{kogge_using_2011}. The end
result of these hardware changes is that the larger numbers of
low-powered processors will be prone to both soft and hard failures
with resilient solver technologies are required to overcome these
events. With linear solvers based on Monte Carlo techniques, such
issues are alleviated by statistical arguments. In the case of soft
failures, isolated floating point errors in Monte Carlo simulation are
absorbed within tally statistics while completely losing hardware
during a hard failure is manifested as a high variance event where
some portion of the Monte Carlo histories are lost.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Monte Carlo Synthetic Acceleration}

Using the ideas of Halton's residual method
\cite{halton_sequential_1994}, Evans and Mosher recently developed a
Monte Carlo solution method that was not prohibited severely by the
quality of the initial guess for the system \cite{evans_monte_2009}
and later applied it more rigorously as a solution mechanism for the
radiation diffusion equation \cite{evans_monte_2012}. With their new
methods, they achieved identical numerical results as and marginally
better performance than conventional Krylov solvers. Their approach
was instead to use residual Monte Carlo as a synthetic acceleration
for a stationary method. Using Monte Carlo in this way achieves the
same effect as Halton's method, decoupling its convergence rate from
the overall convergence rate of the method. Here, the approximate
Monte Carlo solution is not driven to a particular convergence as it
merely supplies a correction for the initial guess generated by
Richardson's iteration. Rather, only a set number of histories are
required using the adjoint method to generate the correction.

Monte Carlo Synthetic Acceleration (MCSA) methods rely the
Neumann-Ulam class of linear solver to accelerate the stationary
method. These Monte Carlo methods work by sampling a distribution with
an expectation value equivalent to that of the inverted
operator. Neumann and Ulam's work was first published in 1950 by
Forsythe and Leibler \cite{forsythe_matrix_1950} with a time frame for
the creation of the method some years earlier than its publication. In
the following decade, the books of Hammersley and Handscomb
\cite{hammersley_monte_1964} and Spanier and Gelbard
\cite{spanier_monte_1969} present additional detail on these solvers.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Parallel Neumann-Ulam Algorithm}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Multiple-Set Overlapping-Domain Decomposition}

In the literature, current implementations of parallel Neumann-Ulam
methods have been limited to full domain replication with parallelism
exploited through individual histories
\cite{alexandrov_efficient_1998}. For high performance computing
environments, domain decomposition strategies have been identified as
important for Monte Carlo applications
\cite{brunner_comparison_2006,siegel_analysis_2012}. In a domain
decomposed Monte Carlo implementation, stochastic histories must be
communicated between domains as the simulation progresses and they
transition to locations outside of the local domain. In order to
implement domain decomposition strategy for Monte Carlo solvers in a
parallel environment, communication of these histories must occur
between compute nodes owning neighboring pieces of the global domain.

At the 2010 SNA+MC meeting, Wagner and colleagues presented the
\textit{multiple-set overlapping-domain} (MSOD) decomposition method
for parallel Monte Carlo applications for full-core light water
reactor analysis \cite{wagner_hybrid_2010}. In their work, overlap
between adjacent domains in the decomposition was used to decrease the
number of particles leaving the local domain. In addition, Wagner
utilized a level of replication of the domain such that the domain was
only decomposed on $O(100)$ processors and if replicated $O(1,000)$
times achieves simulation on $O(100,000)$ processors, thus providing
spatial and particle parallelism. Each collection of processors that
constitutes a representation of the entire domain is referred to as a
set, and within a set overlap occurs among its sub-domains. The
original motivation was to decompose the domain in a way that it
remained in a physical cabinet in a large distributed machine, thus
reducing latency costs during communication. A multiple set scheme is
also motivated by the fact that communication during particle
transport only occurs within a set, limiting communications during the
transport procedure to a group of $O(100)$ processors, a number that
was shown to have excellent parallel efficiencies in Brunner's work
\cite{brunner_efficient_2009} and therefore will scale well in this
algorithm. The overlapping domains within each set also demonstrated
reduced communication costs.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Parallel Scaling Studies}

\subsection{Overlap Scaling}

\subsection{Multiple Sets Scaling}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusions}

It was found the MCSA can indeed be effectively parallelized using the
multiple-set overlapping-domain decomposition algorithm borrowed from
the reactor physics community.  The new algorithm was tested in a wide
variety of parallel scaling studies on the Titan Cray XK7 machine at
the Oak Ridge Leadership Computing Facility. To test the algorithm at
high levels of concurrency, up to 65,356 cores were used in strong
scaling exercises and 131,072 cores used in weak scaling exercises
using the neutron diffusion problem.

Scaling studies showed that in the strong case overlap in small
quantities on the order of the mean-free-path of a stochastic history
in the simulation could boost parallel efficiencies by up to 10\% in
isolated cases. However, it was found that this additional overlap was
not effective in boosting weak scaling efficiencies. In general,
overlap was not very effective due to the fact that the parallel
communication saved during the Monte Carlo transport sequence is
simply deferred until after transport is complete when it manifests
itself as an overlapping parallel vector reduction operation. As
compared to transport calculations where this overlap procedure was
very effective, in the context of MCSA the Monte Carlo calculations
are significantly shorter with $O(10,000)$ histories used in this
work. These shorter calculations and more frequent overlapping tally
vector reductions create an overhead that is not observed in the
literature for transport calculations.

Applying multiple sets in the parallel algorithm was found to not
enhance the weak scaling of the problem as an additional parallel
overhead is introduced when the calculations from the set are combined
in superposition. For the strong scaling case, improvements were not
noted until after the strong scaling wall was hit. At this point,
multiple sets were observed to increase parallel efficiencies from
38\% to 58\% at 16,384 cores. Perhaps more important here is the fact
that although the parallel efficiency was reduced, multiple sets were
observed to actually improve the time to solution. Unlike a
traditional Krylov method that we might apply to solve a neutron
transport problem, using MCSA means that we can actually make a
physical copy of the problem on the machine and can combine separate
Monte Carlo solutions for each copy through superposition. Time to
solution is then improved because fewer histories were run in each
copy and therefore each MCSA iteration is faster or more global
histories are computed and fewer MCSA iterations are required to
converge.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgments}

This work was performed under appointment to the Nuclear Regulatory
Commission Fellowship program at the University of Wisconsin - Madison
Department of Engineering Physics.

This research used resources of the Oak Ridge Leadership Computing
Facility at the Oak Ridge National Laboratory, which is supported by
the Office of Science of the U.S. Department of Energy under Contract
No. DE-AC05-00OR22725.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\bibliographystyle{ans}
\bibliography{references}
\end{document}
