\chapter{Introduction}
\label{ch:introduction}
In nearly all high-fidelity nuclear reactor simulations, linear and
nonlinear transport problems are a primary focus of study. Neutronics,
fluid flow, and heat transfer are among the predominant physics that
fall into this category and simulation technologies to solve these
problems make up much of the analysis suite used for modern
engineering calculations. Recent focus on multiple physics systems in
the nuclear reactor modeling and simulation community adds a new level
of complexity to common linear and nonlinear systems as solution
strategies change when they are coupled to other problems
\cite{u.s._department_of_energy_casl_2011}. Furthermore, a desire for
predictive simulations to enhance the safety and performance of
nuclear systems creates a need for extremely high fidelity
computations to be performed for these transport systems as a means to
capture effects not modeled by coarser methods.

In order to achieve this high fidelity, state-of-the-art computing
\index{facilities} must be leveraged in a way that is both efficient
and considerate of hardware-related issues. As scientific computing
moves beyond petascale facilities with machines of $O(1,000,000)$
cores already coming on-line, new algorithms to solve these complex
problems must be developed to utilize this new hardware
\cite{kogge_using_2011}. Issues such as resiliency to node failure,
limited growth of memory available per node, and scaling to large
numbers of cores will be pertinent to robust algorithms aimed at the
next generation of machines.

Considering these physics and hardware issues, this goal of this work
is to research and develop Monte Carlo Synthetic Acceleration methods
for neutron transport problems and a new method leveraging the
synthetic acceleration techniques to advance solution algorithms for
nonlinear problems in fluid flow. These methods are based on using the
Monte Carlo method to directly accelerate the convergence of
traditional fixed-point iterative schemes for these problems. We aim
to address both their benefits and their shortcomings in the context
of the physics of interest and desire to identify areas in which
improvements can be made. Once the linear and nonlinear methods have
been developed, we look forward to parallelizing them with the goal
that they may be leveraged competitively on leadership-class computing
platforms.

To achieve these goals, three complementary research and development
activities are performed. First, Monte Carlo Synthetic Acceleration
(MCSA) is applied to the neutron transport problem in a light water
reactor calculation to develop the necessary preconditioning
techniques and understanding required to solve difficult
problems. Second, using these new techniques, a series of benchmarks
for the Navier-Stokes equations are solved in different flow regimes
to research the performance of the Monte Carlo algorithm for nonlinear
problems using the new Forward-Automated Newton-MCSA (FANM) algorithm
developed by this work. Third, a novel parallel algorithm based on
domain decomposed Monte Carlo methods for particle transport is
developed to fully parallelize the new solution techniques on
leadership class hardware with scaling studies performed in this work
using a neutron diffusion problem.

We discuss in this chapter physics-based motivation for advancing
Monte Carlo Synthetic Acceleration methods and studying their
application to transport phenomena by providing problems of interest
in nuclear reactor analysis. Hardware-based motivation is also
provided by considering the potential impact of these methods on
forthcoming high performance computing architectures. In addition,
background on the current solver techniques for these physics problems
and a brief comparison to the proposed methods are provided to further
motivate this work. Finally, the statement of work is given and the
organization of the document is then reviewed.

%%---------------------------------------------------------------------------%%
\section{Physics-Based Motivation}
\label{sec:physics_motivation}
Predictive modeling and simulation capability requires the combination
of high fidelity models, high performance computing hardware that can
handle the intense computational loads required by these models, and
modern algorithms for solving these problems that leverage this high
performance hardware. For nuclear reactor analysis, this predictive
capability can enable tighter design tolerances for improved thermal
performance and efficiency, higher fuel burn-up and therefore
reduction in generated waste, and high confidence in accident scenario
models. The physics that dominate these types of analysis include
neutronics, thermal hydraulics, computational fluid dynamics, and
structural mechanics.

Although solution techniques in each of these individual categories
has advanced over the last few decades and in fact leveraged modern
algorithms and computer architectures, true predictive capability for
engineered systems can only be achieved through a coupled, multiple
physics analysis where the effects of feedback between physics are
modeled. For example, consider the safety analysis of a departure from
nucleate boiling scenario in the subchannel of a nuclear fuel
assembly as shown in Figure~\ref{fig:dnb_example}.

\begin{figure}[t!]
  \begin{center}
    \scalebox{1.5}{
      \input{chapters/introduction/dnb_example.pdftex_t} }
  \end{center}
  \caption{\textbf{Multiphysics dependency analysis of departure from
      nucleate boiling.} \textit{A neutronics solution is required to
      compute power generation in the fuel pins, fluid dynamics is
      required to characterize boiling and fluid temperature and
      density, heat transfer is required to compute the fuel and
      cladding temperature, and the nuclear data modified with the
      temperature and density data. Strong coupling among the
      variables creates strong nonlinearities.}}
  \label{fig:dnb_example}
\end{figure}

When this event occurs, heat transfer is greatly reduced between the
fuel and the coolant due to the vapor layer generated by boiling,
causing the fuel center-line temperature to rapidly rise. To
characterize this boiling phenomena and how it affects fuel failure we
must consider a neutronics analysis in order to compute power
generation in the fuel pins, fluid dynamics analysis to characterize
coolant boiling, temperature, and density, solid material heat
transfer to characterize fuel and cladding temperature and heat
transfer with the coolant, and nuclear data processing to characterize
how changing material temperatures and densities changes the cross
sections needed for the neutronics calculation.

As shown in Figure~\ref{fig:dnb_example}, many couplings are required
among individual physics components in order to accurately model this
situation with each physics generating and receiving many
responses. Those variables that are very tightly coupled, such as the
temperatures generated by the fluid dynamics and heat transfer
components, will have strong nonlinearities in their behavior and
would therefore benefit from fully implicit nonlinear solution schemes
such as that developed by this work instead of fixed-point type
iterations between physics\footnote{Fixed-point iterations between
  physics are commonly referred to as Picard iterations in the
  multiphysics community.}. To leverage such a method for analysis
such as a departure from nucleate boiling calculation, we also require
effective solutions for each of the physics involved including the
neutronics problem and the fluid problem, both of which we discuss
next.

\subsection{Solutions for the $SP_N$ Equations}
\label{subsec:spn_motiviation}
The neutron transport problem is complicated. Solutions cover a large
phase space and the problems of interest are often geometrically
complex, contain large numbers of degrees of freedom, or both,
requiring tremendous computational resources to generate an adequate
solution. Modern high fidelity deterministic methods for large scale
problems are often variants on the discrete ordinates ($S_N$) method
\cite{evans_denovo:_2010}. For fission reactor neutronics simulations,
the $S_N$ method requires potentially trillions of unknown angular
flux moments to be computed to achieve good accuracy for the responses
of interest \cite{slaybaugh_acceleration_2011}. Other forms of the
transport problem, including the $P_N$ method, take on a simpler form
than the more common $S_N$ methods, but lack in accuracy when compared
while still requiring considerable computational resources for
solutions in multiple dimensions.

In the 1960's, Gelbard developed an ad-hoc, multidimensional extension
of the simple single dimension planar $P_N$ equations that created a
system of coupled, diffusion-like equations known as the simplified
$P_N$ ($SP_N$) equations. Up until around the 1990's, the $SP_N$
method was either widely unknown, widely unused, or combination of
both even though numerical studies showed promising results with
better solutions than diffusion theory and a significant reduction in
computational time over more accurate methods such as discrete
ordinates. Why did this happen? A significant problem, pointed out by
Brantley and Larsen \cite{brantley_simplified_2000}, was that little
rigor had been applied to the formulation of the $SP_N$ equations
since their derivation through primarily heuristic arguments. Instead,
studies at that time focused on simply comparing the results of the
method to other contemporary transport solution strategies. In
addition, many problems of interest from the literature at the time
were either solved using nodal-type methods for reactor-sized problems
or $S_N$-type methods for benchmark problems with intricate material
configurations and potentially large flux gradients over small spatial
domains.

So why reconsider the $SP_N$ equations? Starting in the 1990's and
primarily due to Larsen and his colleagues, the $SP_N$ equations have
been given a more rigorous treatment with both variational and
asymptotic derivations performed as a means of verification
\cite{olbrant_asymptotic_2013}. In addition, these equations have been
more rigorously studied as solution methods to MOX fuel problems and
have been shown to provide accurate solutions
\cite{brantley_simplified_2000}. With this mathematical literature to
provide a solid numerical footing for the method, we look at its
application to today's challenge problems in neutron transport for
fission reactor analysis. The reduction in numerical complexity
compared to current deterministic solution methods using the $S_N$
approximation could mean significant savings in both compute time and
memory required.

In order to leverage Monte Carlo Synthetic Acceleration as a solution
technique for neutron transport problems, its current formulation
requires the physics operator and all preconditioners to be explicitly
formed. Recent developments in the Exnihilo neutronics package at Oak
Ridge National Laboratory have permitted generation of the $SP_N$
system of equations for detailed neutronics models of fission
reactor-based systems \cite{evans_simplified_2013}. By fully forming
these equations and formulating them as a linear algebra problem
instead of using the explicit iterative methods of the past, we now
have access to all of the modern advancements in computational linear
algebra including the use of Krylov solvers for asymmetric systems
without the need to implement the action of the physics operator on a
vector and easy application of algebraic preconditioning methods for
improved convergence properties and time to solution.

This leads us to then research the applicability of Monte Carlo
Synthetic Acceleration methods as a possible solution method for the
$SP_N$ equations. In addition, solving the $SP_N$ equations in this
way also breaks away from the $S_N$ forms of parallelism where spatial
parallelism is achieved by an efficient parallel sweep, angular
efficiency achieved by pipe-lining, and energy parallelism achieved by
decoupling the groups. With the $SP_N$ equations as a full matrix
system, we now can parallelize the problem as prescribed by the Monte
Carlo algorithm, which may be significantly more scalable than current
$S_N$ transport practices. In this work we apply Monte Carlo Synthetic
Acceleration to the $SP_N$ equations and research its applicability,
performance, and convergence properties in the context of a light
water reactor system.

\subsection{Solutions for the Navier-Stokes Equations}
\label{subsec:ns_motiviation}

Nonlinear transport problems are a common occurrence in single and
multiple physics problems in nuclear engineering. Systems of partial
differential equations, such as the Navier-Stokes equations that
describe fluid flow, yield discrete sets of stiff equations with
nonlinearities present in the variables when discretized by
conventional methods. These sets of equations characterize momentum
and energy transport through diffusion, viscous forces and convection,
and inertial forces. Traditionally, such systems have been solved by
linearizing them in a form where the nonlinearities in the variables
are eliminated and more traditional linear methods can be used for
solutions. Often characterized as segregated methods where physics
operators are split and their action on the system approximated in
steps, such methods lack consistency and accuracy in resolving the
nonlinear component of the solution. In the last 30 years, fully
implicit nonlinear methods based on Newton's method have become more
popular and many advances have been made in the nuclear engineering
field to employ these methods \cite{gaston_parallel_2009}.

In the context of solving standalone linear problems, Monte Carlo
methods do not provide significant merit over subspace methods due to
the fact that the physics operator must be explicitly formed. For many
applications including higher fidelity neutron transport
discretizations beyond the $SP_N$ equations discussed in the previous
section, such a requirement is prohibitive and perhaps not even
feasible to implement. Therefore, a discrete Monte Carlo solution
method is best suited for situations in which the operator is readily,
if not naturally, formed. Modern nonlinear methods meet this
requirement with Newton methods used in conjunction with Krylov
methods operating on a fully formed matrix for a robust solution
strategy. Furthermore, modern techniques exist that permit the
automatic construction of the Jacobian operator generated within a
Newton method based on the nonlinear residual evaluations, giving all
of the components necessary for a Monte Carlo solver to provide
value. In this work we devise a new nonlinear method in this work
based on the Monte Carlo Synthetic Acceleration algorithm and Newton's
method and research its properties, applicability, and performance in
the context of fluid flow problems.

\subsection{Domain Decomposed Monte Carlo Synthetic Acceleration}
\label{subsec:parallel_motivation}

The computational resources required to solve the neutronics and fluid
dynamics problems can be tremendous. Recent work in modeling coupled
fluid flow and solid material heat and mass transfer in a reactor
subsystem, similar to the same components of the departure from
nucleate boiling example, was performed as part of analysis for the
Department of Energy's Consortium for Advanced Simulation of Light
Water Reactors (CASL) modeling and simulation hub
\cite{u.s._department_of_energy_casl_2011}. CASL used the Drekar
multiphysics code developed at Sandia National Laboratories
\cite{pawlowski_drekar_2012} for modeling goals in
grid-to-rod-fretting analysis and will use a similar coupled physics
structure for future departure from nucleate boiling analysis with
comparison to experimental data. Using Drekar, multiphysics
simulations have been performed with fully implicit methods for the
solution of nonlinear systems using meshes of $O(\sn{1}{9})$ elements
leveraging $O(100,000)$ cores on leadership class machines. Neutronics
components to be implemented in CASL for multiphysics analysis, such
as the Exnihilo radiation transport suite developed at Oak Ridge
National Laboratory \cite{evans_denovo:_2010}, compute trillions of
unknowns for full core reactor analysis on $O(\sn{1}{9})$ element
meshes and $O(100,000)$ cores as well. Given the large scale and
complexity of these problems, if we aim to advance solution techniques
in neutronics and fluid flow for reactor analysis, then we are
motivated to advance the solution of complex physics problems
exploiting leadership class levels of parallelism.

For Monte Carlo Synthetic Acceleration methods to be viable at the
production scale for nuclear engineering applications, scalable
parallel implementations of the algorithm are required. Reviewing the
literature, Monte Carlo Synthetic Acceleration has yet to be
parallelized and the underlying Neumann-Ulam Monte Carlo method has
only been parallelized through history-level parallelism with full
domain replication \cite{alexandrov_efficient_1998}. In order to solve
large linear physics systems with Monte Carlo Synthetic Acceleration,
a domain decomposed parallel strategy is required. In the formulation
of a parallel Monte Carlo Synthetic Acceleration algorithm, we
recognize that the algorithm occurs in two stages, an initial step
performing a fixed point iteration and a secondary step leveraging a
Monte Carlo solver that is providing the acceleration. The parallel
aspects of both these components must be considered. Therefore, in
this work we will develop and implement parallel algorithms for the
fundamental random walk sequence and Monte Carlo Synthetic
Acceleration methods leveraging both the knowledge gained from the
general parallel implementations of subspace methods reviewed in
Appendix~\ref{ch:linear_problem} and modern parallel strategies for
domain decomposed Monte Carlo as developed by the reactor physics
community.

%%---------------------------------------------------------------------------%%
\section{Hardware-Based Motivation}
\label{sec:hardware_motivation}
As leadership class machines move beyond the petascale, new algorithms
must be developed that leverage their strengths and adapt to their
shortcomings. Basic research is required now to advance methods in
time for these new machines to become operational. Organized work is
already moving forward in this area with the Department of Energy's
Advanced Scientific Computing Research office specifically allocating
funding for the next several years to research resilient solver
technologies for next generation facilities
\cite{u.s._department_of_energy_resilient_2012}. Based on the language
in this call for proposals, we can identify key issues for which a set
of robust, massively parallel Monte Carlo solvers could provide a
solution. As machines begin to operate at hundreds of petaflops peak
performance and beyond, trends toward reduced energy consumption will
require incredibly high levels of concurrency to achieve the desired
computation rates. Furthermore, this drop in power consumption will
mean increased pressure on memory as memory per node is expected to
stagnate while cores per node is expected to increase. As the number
of cores increases, their clock speed is expected to stagnate or even
decrease to further reduce power consumption and manufacturing costs.

The end result of these hardware changes is that the larger number of
low-powered processors will be prone to both soft failures such as bit
errors in floating point operations and hard failures where the data
owned by that processor cannot be recovered. Because these failures
are predicted to be common, resilient solver technologies are required
to overcome these events at the application level. With linear and
nonlinear solution schemes based on Monte Carlo techniques, such
issues are potentially alleviated by statistical arguments. In the
case of soft failures, isolated floating point errors in the Monte
Carlo simulation are absorbed within tally statistics. Completely
losing memory during a hard failure is treated as a high variance
event where some portion of the Monte Carlo histories and subsequently
the solution are lost with other histories maintained by replicating
the problem and combining the results through superposition. These
stochastic methods are a paradigm shift from modern deterministic
solver techniques that will, in their current form, potentially suffer
greatly from the non-deterministic behavior expected from the next
generation of machines.

%%---------------------------------------------------------------------------%%
\section{Research and Development Outline}
\label{sec:research_outline}
For some time, the particle transport community has utilized Monte
Carlo methods for the solution of transport problems
\cite{lewis_computational_1993}. The partial differential equation
(PDE) community has focused on various deterministic methods for
solutions to linear problems \cite{saad_iterative_2003,
  kelley_iterative_1995}. In between these two areas are a not widely
known group of Monte Carlo methods for solving sparse linear systems
\cite{forsythe_matrix_1950, hammersley_monte_1964,
  halton_sequential_1962, halton_sequential_1994}. In recent years,
these methods have been further developed for radiation transport
problems in the form of Monte Carlo Synthetic Acceleration (MCSA)
\cite{evans_monte_2009, evans_monte_2012} but have yet to be applied
to more general sparse linear systems commonly generated by the
computational physics community. Compared to other methods in this
regime, MCSA offers three attractive qualities; (1) the physics
operator need not be symmetric or positive-definite, (2) the
stochastic nature of the solution method provides a natural solution
to some aspects of the issue of resiliency, and (3) is amenable to
parallelization using modern methods developed by the transport
community \cite{wagner_hybrid_2010}. The development of MCSA as a
general solution technique and the development of a parallel MCSA
method are new and unique features of this work, providing a framework
with which other issues such as resiliency or performance may be
addressed in the future.

In addition to advancements in the parallel solution of linear
problems, nonlinear problems may also benefit from a general and
parallel MCSA scheme. In the nuclear engineering community, nonlinear
problems are often addressed by either linearizing the problem or
building a segregated scheme and using traditionally iterative or
direct methods to solve the resulting system
\cite{pletcher_computational_1997}. In the mathematics community,
various Newton methods have been popular
\cite{kelley_iterative_1995}. Recently, Jacobian-Free Newton-Krylov
(JFNK) schemes \cite{knoll_jacobian-free_2004} have been utilized in
multiple physics architectures and advanced single physics codes
\cite{gaston_parallel_2009}. The benefits of JFNK schemes are that the
Jacobian is never formed, simplifying the implementation, and a Krylov
solver is leveraged (typically GMRES or a method based on Conjugate
Gradient), providing excellent convergence properties for
well-conditioned and well-scaled systems. However, there are two
potential drawbacks to these methods for high fidelity predictive
simulations: (1) the Jacobian is approximated by a first-order
differencing method on the order of machine precision such that this
error can grow beyond that of those in a poorly-scaled system
\cite{kelley_iterative_1995} and (2) for systems that are not
symmetric positive-definite (which will be the case for most
multiphysics systems and certainly for most preconditioned systems)
the Krylov subspace generated by the GMRES solver may become
prohibitively large \cite{knoll_newton-krylov_1995}.

In this work, the Forward-Automated Newton-MCSA (FANM) method is
developed as new nonlinear solution method. The key features of FANM
are: full Jacobian generation using modern Forward Automated
Differentiation (FAD) methods, and MCSA as the inner linear
solver. This method has several attractive properties. First, the
first-order approximation to the Jacobian used in JFNK type methods is
eliminated with the Jacobian fully formed. Second, the Jacobian need
not be explicitly formed by the user but is instead automated through
FAD; this eliminates the complexity of hand-coding derivatives and has
also been demonstrated to be more efficient computationally than
evaluating difference derivatives
\cite{bartlett_automatic_2006}. Third, unlike GMRES, MCSA does not
build a subspace during iterations. Although the Jacobian must be
explicitly formed to use MCSA, for problems that take more than a few
GMRES iterations to converge the size of the Krylov subspace will
typically grow beyond that of the Jacobian. Finally, using MCSA to
solve the linear model provides its benefits of potential parallelism
and iterative performance.

%%---------------------------------------------------------------------------%%
\section{Statement of Work}
\label{sec:statement_of_work}

The goal of this work is to improve the iterative performance and
parallel scalability of solutions to discrete linear and nonlinear
transport problems by researching and developing a new set of domain
decomposed Monte Carlo Synthetic Acceleration methods. Improvements in
iterative performance and parallel scalability will be demonstrated in
a wide variety of numerical experiments using both simple model
transport problems and neutron transport and fluid flow problems
generated by production physics codes in both simple and complex
geometries.

%%---------------------------------------------------------------------------%%
\section{Outline of the Document}
\label{sec:doc_outline}

To present the research and development required to meet the goals of
this work this document is arranged in the following manner. First, in
Chapter~\ref{ch:stochastic_methods}, the fundamentals of the Monte
Carlo method for linear systems are presented. Using this background
on Monte Carlo, synthetic acceleration methods are then presented and
new analysis is provided using a simple model transport problem. Next,
in Chapter~\ref{ch:spn_equations}, the Monte Carlo methods developed
in Chapter~\ref{ch:stochastic_methods} are applied to the neutron
transport problem. Specifically, the $SP_N$ form of the Boltzmann
neutron transport equation is developed and solved using the Monte
Carlo methods. Using a difficult light water reactor fuel assembly
criticality calculation to drive research and development for these
Monte Carlo methods, several important issues regarding Monte Carlo
solver applicability, performance, and preconditioning will be
discussed along with solutions to these problems. Using these
solutions, the Monte Carlo methods are then verified against modern
solution techniques for the $SP_N$ equations in order verify
correctness for the fuel assembly criticality calculation. In
Chapter~\ref{ch:nonlinear_problem}, the Monte Carlo methods are
applied to the Navier-Stokes equations as a model nonlinear fluid flow
system. A new nonlinear solution technique is developed based on
Newton's method and both verified against and compared to conventional
solution techniques. In Chapter~\ref{ch:parallel_methods}, the Monte
Carlo methods are parallelized using modern reactor physics techniques
for domain decomposed particle transport with a full parallel scaling
analysis provided using a leadership-class computing
facility. Finally, the work is summarized in
Chapter~\ref{ch:conclusion} and topics of future work derived from the
results of this research presented.
