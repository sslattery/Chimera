\chapter{Introduction}
\label{ch:introduction}
In nearly all high-fidelity nuclear reactor simulations, linear and
nonlinear transport problems are a primary focus of study. Neutronics,
fluid flow, and heat transfer are among the predominate physics that
fall into this category and simulation technologies to solve these
problems make up much of the analysis suite used for modern
analysis. Recent focus on multiple physics systems in the nuclear
reactor modeling and simulation community adds a new level of
complexity to common linear and nonlinear systems as solution
strategies change when they are coupled to other problems
\citep{u.s._department_of_energy_casl_2011}. Furthermore, a desire for
predictive simulations to enhance the safety and performance of
nuclear systems creates a need for extremely high fidelity
computations to be performed for these transport systems as a means to
capture effects not modeled by coarser methods.

In order to achieve this high fidelity, state-of-the-art computing
\index{facilities} must be leveraged in a way that is both efficient
and considerate of hardware-related issues. As scientific computing
moves beyond petascale facilities with machines of $O(1,000,000)$
cores already coming on-line, new algorithms to solve these complex
problems must be developed to leverage this new hardware
\citep{kogge_using_2011}. Issues such as resiliency to node failure,
limited growth of memory available per node, and scaling to large
numbers of cores will be pertinent to robust algorithms aimed at this
new hardware. Considering these issues, this dissertation develops a
massively parallel Monte Carlo method for linear problems and a novel
Monte Carlo method to advance solution techniques for nonlinear
problems.

This goal of this work is to research and develop parallel solutions
for discrete linear and nonlinear transport problems that improve
performance and scalabilty using a novel set of Monte Carlo synthetic
acceleration methods.

We discuss in this chapter physics-based motivation for advancing
Monte Carlo synthetic acceleration methods and studying their
application to transport systems by providing problems of interest in
nuclear reactor analysis. Hardware-based motivations are also provided
by considering the impact of forthcoming computing architectures. In
addition, background on the current solver techniques for these
physics problems and a brief comparison to the proposed methods are
provided to further motivate this work. The organization of the
document is then reviewed.

%%---------------------------------------------------------------------------%%
\section{Physics-Based Motivation}
\label{sec:physics_motivation}
Predictive modeling and simulation capability requires the combination
of high fidelity models, high performance computing hardware that can
handle the intense computational loads required by these models, and
modern algorithms for solving these problems that leverage this high
performance hardware. For nuclear reactor analysis, this predictive
capability can enable tighter design tolerances for improved thermal
performance and efficiency, higher fuel burn-up and therefore reduction
in generated waste, and high confidence in accident scenario
models. The physics that dominate these types of analysis include
neutronics, thermal hydraulics, computational fluid dynamics, and
structural mechanics.

Although solution techniques in each of these individual categories
has advanced over the last few decades and in fact leveraged modern
algorithms and computer architectures, true predictive capability for
engineered systems can only be achieved through a coupled, multiple
physics analysis where the effects of feedback between physics are
modeled. For example, consider the safety analysis of a departure from
nucleate boiling scenario in the subchannel of a nuclear fuel
assembly.
\begin{figure}[t!]
  \begin{center}
    \scalebox{1.5}{
      \input{chapters/introduction/dnb_example.pdftex_t} }
  \end{center}
  \caption{\textbf{Multiphysics dependency analysis of departure from
      nucleate boiling.} \textit{A neutronics solution is required to
      compute power generation in the fuel pins, fluid dynamics is
      required to characterize boiling and fluid temperature and
      density, heat transfer is required to compute the fuel and
      cladding temperature, and the nuclear data modified with the
      temperature and density data. Strong coupling among the
      variables creates strong nonlinearities.}}
  \label{fig:dnb_example}
\end{figure}
When this event occurs, heat transfer is greatly reduced between the
fuel and the coolant due to the vapor layer generated by boiling,
causing the fuel center-line temperature to rapidly rise. To
characterize this boiling phenomena and how it affects fuel failure we
must consider a neutronics analysis in order to compute power
generation in the fuel pins, fluid dynamics analysis to characterize
coolant boiling, temperature, and density, solid material heat
transfer to characterize fuel and cladding temperature and heat
transfer with the coolant, and nuclear data processing to characterize
how changing material temperatures and densities changes the cross
sections needed for the neutronics calculation. As shown in
Figure~\ref{fig:dnb_example}, many couplings are required among
individual physics components in order to accurately model this
situation with each physics generating and receiving many
responses. Those variables that are very tightly coupled, such as the
temperatures generated by the fluid dynamics and heat transfer
components, will have strong nonlinearities in their behavior and
would therefore benefit from fully consistent nonlinear solution
schemes instead of fixed-point type iterations between
physics\footnote{Fixed-point iterations between physics are commonly
  referred to as Picard iterations.}. Furthermore, the space and time
scales over which these effects occur will also vary greatly.

The computational resources required to solve such problems are
tremendous. Recent work in modeling coupled fluid flow and solid
material heat and mass transfer in a reactor subsystem, similar to the
same components of the departure from nucleate boiling example above,
was performed as part of analysis of the Department of Energy's
Consortium for Advanced Simulation of Light Water Reactors (CASL)
modeling and simulation hub. CASL used the Drekar multiphysics code
developed at Sandia National Laboratories
\citep{pawlowski_drekar_2012} for modeling goals in
grid-to-rod-fretting analysis and will use a similar coupled physics
structure for future departure from nucleate boiling analysis with
comparison to experimental data. Using Drekar, multiphysics
simulations have been performed with fully consistent methods for the
solution of nonlinear systems using meshes of $O(\sn{1}{9})$ elements
leveraging $O(100,000)$ cores on leadership class machines. Neutronics
components to be implemented in CASL for multiphysics analysis, such
as the Exnihilo radiation transport suite developed at Oak Ridge
National Laboratory \citep{evans_denovo:_2010}, compute trillions of
unknowns for full core reactor analysis on $O(\sn{1}{9})$ element
meshes and $O(100,000)$ cores as well. Given the large scale and
complexity of these problems, if we aim to advance multiphysics
solution techniques, then we are motivated to advance the solution of
complex and general nonlinear problems exploiting leadership class
levels of parallelism.

\subsection{Solutions for the $SP_N$ Equations}
\label{subsec:spn_motiviation}
The neutron transport problem is complicated. Solutions cover a large
phase space and the problems of interest are often geometrically
complex, very large, or both, requiring tremendous computational
resources to generate an adequate solution. Modern deterministic
methods for large scale problems are commonly variants on the discrete
ordinates ($S_N$) method \citep{evans_denovo:_2010}. For fission
reactor neutronics simulations, the $S_N$ method requires potentially
trillions of unknown angular flux moments to be computed to achieve
good accuracy for the responses of interest
\citep{slaybaugh_acceleration_2011}. Other forms of the transport
problem, including the $P_N$ method, take on a simpler form than the
more common $S_N$ methods but lack in accuracy when compared while
still requiring considerable computational resources for solutions in
multiple dimensions.

In the 1960's, Gelbard developed an ad-hoc multidimensional extension
of the simple single dimension planar $P_N$ equations that created a
system of coupled, diffusion-like equations known as the simplified
$P_N$ ($SP_N$) equations. Up until around the 1990's, the $SP_N$
method was either widely unknown, widely unused, or combination of
both even though numerical studies showed promising results with
better solutions than diffusion theory and a significant reduction in
computational time over more accurate methods such as discrete
ordinates. Why did this happen? A significant problem, pointed out by
Brantley and Larsen \citep{brantley_simplified_2000}, was that little
rigor had been applied to the formulation of the $SP_N$ equations
since their derivation through primarily heuristic arguments. Instead,
studies at that time focused on simply comparing the results of the
method to other contemporary transport solution strategies. In
addition, many problems of interest from the literature at the time
were either solved using nodal-type methods for reactor-sized problems
or $S_N$-type methods for benchmark problems with intricate material
configurations and potentially large flux gradients over small spatial
domains.

So why reconsider the $SP_N$ equations? Starting in the 1990's and
primarily due to Larsen and his colleagues, the $SP_N$ equations have
been given a more rigorous treatment with both variational and
asymptotic derivations performed as a means of verification. In
addition, these equations have been more rigorously studied as
solution methods to MOX fuel problems and have been shown to provide
accurate solutions. With this mathematical literature to provide a
solid numerical footing for the method, we look at its application to
today's challenge problems in neutron transport for fission reactor
analysis. The reduction in numerical complexity of current
deterministic solution methods using the $S_N$ approximation could
mean significant savings in both compute time and memory required. In
addition, the characteristics of the solution to the transport problem
for a steady state reactor core permit diffusion theory to be used; a
staple of the nuclear industry since its inception. Therefore, if
diffusion theory is applicable, then finer grained solutions that
capture more of the physics contained in the transport equation should
be possible with the $SP_N$ method. In doing so, we also expect from
the literature to obtain computed responses on the order of accuracy
we would expect from an appropriately discretized $S_N$ method at a
fraction of the cost.

In order to leverage MCSA as a solution technique for physics
problems, its current formulation requires the linear operator and all
preconditioners to be explicitly formed. Recent developments in the
Exnihilo neutronics package at Oak Ridge National Laboratory have
permitted generation of the $SP_N$ system of equations for detailed
neutronics models of fission reactor-based
systems\citep{evans_simpli_2013}. By fully forming these equations and
formulating them as a linear algebra problem instead of using the
explicit iterative methods of the past, we now have access to all of
the modern advancements in computational linear algebra including
Krylov solvers for asymmetric systems and algebraic preconditioning
methods. This leads us to then explore the applicability of our work
in discrete Monte Carlo methods for linear systems as a possible
solution method for the $SP_N$ equations. In addition, solving the
$SP_N$ equations in this way also breaks away from the $S_N$ forms of
parallelism where spatial parallelism is achieved by an efficient
parallel sweep, angular efficiency achieved by pipe-lining, and energy
parallelism achieved by decoupling the groups. With the $SP_N$
equations as a full matrix system, we now can parallelize the problem
as prescribed by the linear solver, which may be significantly more
scalable than current $S_N$ transport practices.

\subsection{Solutions for the Navier-Stokes Equations}
\label{subsec:ns_motiviation}

%%---------------------------------------------------------------------------%%
\section{Hardware-Based Motivation}
\label{sec:hardware_motivation}
As leadership class machines move beyond the petascale, new algorithms
must be developed that leverage their strengths and adapt to their
shortcomings. Basic research is required now to advance methods in
time for these new machines to become operational. Organized work is
already moving forward in this area with the Department of Energy's
Advanced Scientific Computing Research office specifically allocating
funding for the next several years to research resilient solver
technologies for extreme scale facilities
\citep{u.s._department_of_energy_resilient_2012}. Based on the
language in this call for proposals, we can identify key issues for
which a set of robust, massively parallel Monte Carlo solvers could
provide a solution. As machines begin to operate at hundreds of
petaflops peak performance and beyond, trends toward reduced energy
consumption will require incredibly high levels of concurrency to
achieve the desired computation rates. Furthermore, this drop in power
consumption will mean increased pressure on memory as memory per node
is expected to stagnate while cores per node is expected to
increase. As the number of cores increases, their clock speed is
expected to stagnate or even decrease to further reduce power
consumption and manufacturing costs.

The end result of these hardware changes is that the larger numbers of
low-powered processors will be prone to both soft failures such as bit
errors in floating point operations and hard failures where the data
owned by that processor cannot be recovered. Because these failures
are predicted to be common, resilient solver technologies are required
to overcome these events. With linear and nonlinear solvers based on
Monte Carlo techniques, such issues are alleviated by statistical
arguments. In the case of soft failures, isolated floating point
errors in Monte Carlo simulation are absorbed within tally statistics
while completely losing hardware during a hard failure is manifested
as a high variance event where some portion of the Monte Carlo
histories are lost. These stochastic methods are a paradigm shift from
current deterministic solver techniques that will suffer greatly from
the non-deterministic behavior expected from the next generation of
machines.

In addition to resiliency concerns, the memory restrictions on future
hardware will hinder modern solvers that derive their robustness from
using large amounts of memory. Stochastic methods that are formulated
to use less memory than conventional methods will serve to alleviate
some of this pressure. In addition, new parallel strategies that may
be implemented with stochastic methods could offer a new avenue for
leveraging the expected levels of high concurrency in extreme scale
machines.

%%---------------------------------------------------------------------------%%
\section{Research Outline}
\label{sec:research_outline}
For some time, the particle transport community has been utilizing
Monte Carlo methods for the solution of transport problems
\citep{lewis_computational_1993}. The partial differential equation
(PDE) community has focused on various deterministic methods for
solutions to linear problems \citep{saad_iterative_2003,
  kelley_iterative_1995}. In between these two areas are a not widely
known group of Monte Carlo methods for solving sparse linear systems
\citep{forsythe_matrix_1950, hammersley_monte_1964,
  halton_sequential_1962, halton_sequential_1994}. In recent years,
these methods have been further developed for radiation transport
problems in the form of Monte Carlo Synthetic-Acceleration (MCSA)
\citep{evans_monte_2009, evans_monte_2012} but have yet to be applied
to more general sparse linear systems commonly generated by the
computational physics community. Compared to other methods in this
regime, MCSA offers three attractive qualities; (1) the linear problem
operator need not be symmetric or positive-definite, thereby reducing
preconditioning complexity, (2) the stochastic nature of the solution
method provides a natural solution to the issue of resiliency, and (3)
is amenable to parallelization using modern methods developed by the
transport community \citep{wagner_hybrid_2010}. The development of
MCSA as a general linear solver and the development of a parallel MCSA
method are new and unique features of this work, providing a
framework with which other issues such as resiliency may be addressed
in the future.

In addition to linear solver advancements, nonlinear solvers may also
benefit from a general and parallel MCSA scheme. In the nuclear
engineering community, nonlinear problems are often addressed by
either linearizing the problem or building a segregated scheme and
using traditionally iterative or direct methods to solve the resulting
system \citep{pletcher_computational_1997}. In the mathematics
community, various Newton methods have been popular
\citep{kelley_iterative_1995}. Recently, Jacobian-Free Newton-Krylov
(JFNK) schemes \citep{knoll_jacobian-free_2004} have been utilized in
multiple physics architectures and advanced single physics codes
\citep{gaston_parallel_2009}. The benefits of JFNK schemes are that
the Jacobian is never formed, simplifying the implementation, and a
Krylov solver is leveraged (typically GMRES or Conjugate Gradient),
providing excellent convergence properties for well-conditioned and
well-scaled systems. However, there are two potential drawbacks to
these methods for high fidelity predictive simulations: (1) the
Jacobian is approximated by a first-order differencing method on the
order of machine precision such that this error can grow beyond that
of those in a fine-grained system \citep{kelley_iterative_1995} and
(2) for systems that are not symmetric positive-definite (which will
be the case for most multiphysics systems and certainly for most
preconditioned systems) the Krylov subspace generated by the GMRES
solver may become prohibitively large
\citep{knoll_newton-krylov_1995}. To address these issues, this work
develops a new and novel method for nonlinear systems based on the
MCSA method.

The Forward-Automated Newton-MCSA (FANM) method is developed as new
nonlinear solution method. The key features of FANM are: full Jacobian
generation using modern Forward Automated Differentiation (FAD)
methods \citep{bartlett_automatic_2006}, and MCSA as the inner linear
solver. This method has several attractive properties. First, the
first-order approximation to the Jacobian used in JFNK type methods is
eliminated by generating the Jacobian explicitly with the model
equations through FAD. Second, the Jacobian need not be explicitly
formed by the user but is instead automated through FAD; this
eliminates the complexity of hand-coding derivatives and has also been
demonstrated to be more efficient computationally than evaluating
difference derivatives. Third, unlike GMRES, MCSA does not build a
subspace during iterations. Although the Jacobian must be explicitly
formed to use MCSA, for problems that take more than a few GMRES
iterations to converge the size of the Krylov subspace will grow
beyond that of the Jacobian. Finally, using MCSA for the linear solve
provides its benefits for preconditioning, potential resiliency, and
parallelism.

%%---------------------------------------------------------------------------%%
\section{Outline}

To present these new developments this document is arranged in the
following manner. First, in Chapter~\ref{ch:stochastic_methods}, the
fundamentals of the Monte Carlo method for linear systems are
presented. Using this background on Monte Carlo, synthetic
acceleration methods are then presented and analyzed using a simple
model transport problem. Next, in Chapter~\ref{ch:spn_equations}, the
Monte Carlo methods developed in Chapter~\ref{ch:stochastic_methods}
are applied to the neutron transport problem. Specifically, the $SP_N$
form of the Boltzmann neutron transport equation is developed and
solved using the Monte Carlo methods. Using a difficult fission
reactor fuel assembly criticality calculation to drive research and
development for these Monte Carlo methods, several important issues
regarding Monte Carlo solver applicability and performance will be
discussed along with solutions to these problems. Using these
solutions, the Monte Carlo methods are then verified against modern
solution techniques for the $SP_N$ equations in order verify
correctness for the fuel assembly criticality calculation. In
Chapter~\ref{ch:nonlinear_problem}, the Monte Carlo methods are
applied to the Navier-Stokes equations as a model nonlinear energy and
momentum transport system. Additional difficulties that arise when
using Monte Carlo methods in these types of systems will be presented
along with the subsequently developed solutions. In
Chapter~\ref{ch:parallel_methods}, the Monte Carlo methods are
parallelized using modern reactor physics techniques for particle
transport with a full parallel scaling analysis provided using a
leadership-class computing facility. Finally, the work is summarized
in Chapter~\ref{ch:conclusion} and topics of future work derived from
the results of this research presented.
