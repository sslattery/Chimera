\chapter{Conclusions and Analysis\ }
\label{ch:conclusion}

For high fidelity simulations of nuclear reactors, physics solutions
are required with speed and accuracy. When the problems become large
enough, such as the simulation of an entire reactor core,
leadership-class computing facilities must be leveraged on the grounds
of requirements for both time to solution and the amount of memory
required to contain the description of the entire problem and the
solution. Looking forward to the next generation of machines,
concurrency will go up and available memory will go down, putting
pressure on physics application developers to research and develop
solution techniques that can efficiently leverage this hardware. In
nuclear reactor simulation, both neutron transport and fluid flow
calculations consume a vast amount of computational time in order to
properly characterize both steady state operational characteristics
and transient accident scenarios. In both cases, we desire solution
techniques that are aware of coming changes in hardware.

In this work, we have presented Monte Carlo Synthetic Acceleration as
a viable solution technique for both neutron transport and fluid flow
problems on future hardware. To do this, we carried out three research
and developement activities. First, we applied MCSA to the $SP_N$ form
of the neutron transport equation and analyzed the preconditioning
requirements and subsequent performance of the method when compared to
conventional practices. Second, we used the knowledge gained from the
research on neutron transport to develop the FANM method for nonlinear
problems and studied its performance on three different benchmarks for
the Navier-Stokes equations to demonstrate its applicability. Finally,
we parallelized MCSA such that it may be applied to physics problems
in a leadership-class computing environment.

In this chapter, we review the work presented in this document and
describe how this work met the goals of the research. We then
reiterate the important issues discovered during the course of this
work and develop a strategy for future work to potentially alleviate
them. Finally, we close with some final remarks regarding Monte Carlo
Synthetic Acceleration.

%%---------------------------------------------------------------------------%%
\section{Monte Carlo Synthetic Acceleration Solutions for the $SP_N$ Equations\ }
\label{sec:spn_conclusion}

This work demonstrates the first application of MCSA to the neutron
transport problem. To do this, we used the $SP_N$ form of the
Boltzmann transport equation. In this form, the transport equation
takes on a diffusion-like form where the angular character of the flux
is accounted for in moment terms much like those found in the $P_N$
equations. To meet the goals of this work and drive the research and
development of MCSA for application to light water reactor problems, a
difficult nuclear fuel assembly criticality calculation was used in a
set of numerical experiments. These calculations were enabled by
incorporating MCSA as a solution scheme into the k-eigenvalue solver
in the Exnihilo production neutronics code base at Oak Ridge National
Laboratory.

When applying the new technique to the fuel assembly problem, it was
initially found that MCSA could not converge the problem with basic
Jacobi-based preconditioning. This was discovered to be due to the
fact that the transport operator generated in the eigenvalue
calculation was very ill-conditioned due to the large amount of
neutron scattering in the light water moderator. The more scattering
present in the system, the longer a random walk will take and thus a
spectral radius approaching unity was observed. A simpler neutron
diffusion problem was used to demonstrate the breakdown of MCSA when
spectral radii this large are generated.

As a result of the breakdown observation, a suite of advanced
preconditioning techniques was applied to MCSA for the fuel assembly
problem in order to reduce the spectral radius to a level below where
breakdown occurs. From the results of this analysis, ILUT
preconditioning was chosen for subsequent investigations. Using this
preconditioning, it was verified that MCSA is indeed general enough to
solve the asymmetric system generated by the $SP_N$
equations. However, the explicit MCSA preconditioning strategy
developed for this work generated very dense systems that consumed
tremendous amounts of memory to store and compute time to
generate. The memory problem was partially alleviated by applying the
reduced domain approximation, however a significant memory overhead
remained along with prohibitive time for construction.

Using the developed preconditioners and the reduced domain
approximation, a set of $SP_N$ calculations using up to 4 energy
groups were enabled for the fuel assembly problem. To verify MCSA, the
fuel assembly problem was solved with different energy groups using
both MCSA and two production Krylov methods. MCSA was observed to
produce the same scalar flux in all groups at all spatial locations
and generate the same k-eigenvalue in the same number of eigenvalue
iterations. 

For the same calculations, MCSA had qualitatively similar iterative
performance to the production Krylov methods, showing improved
performance over GMRES while a Conjugate Gradient-based method
performed better using the same preconditioining. Improved performance
over GMRES meets the goal of improving iterative performance to a
certain extent but this was not the true for the Conjugate
Gradient-based method. However, although the $SP_N$ equations are
asymmetric for multigroup calculations, they are symmetric at the
block level and therefore we expect the Conjugate Gradient-based
method to perform better as this structure can be more readily
utilized than the more general GMRES and MCSA methods. In terms of CPU
time, MCSA was observed to perform $O(100)$ times slower than the
Krylov methods due to both lack of optimization in the random walk
sequence and the explicit preconditioning strategy.

%%---------------------------------------------------------------------------%%
\section{Monte Carlo Synthetic Acceleration Solutions for Navier-Stokes Equations\ }
\label{sec:nonlinear_conclusions}

This work presents the FANM method, a new nonlinear solution scheme
based on an inexact Newton method. To meet the goals of this work the
FANM method was characterized by applying it to the Navier-Stokes
equations. This research was enabled by implementing the FANM method
within the nonlinear solver sequence leveraged by the Drekar production
multiphysics code base being developed at Sandia National
Laboratories. In both convection and driven flow regimes we solved
three difficult benchmark problems for the Navier-Stokes
equations. Using the work in preconditioning from the research on the
$SP_N$ equations, it was found that the same preconditioning strategy
could be used to achieve convergence of the linear models generated at
each FANM iteration by applying an algebraic multigrid method.

For each benchmark problem, FANM solutions were verified against
Newton-Krylov solutions leveraging GMRES as the linear solver. The
FANM solutions were observed to be numerically identical to those
generated by the Newton-Krylov method. In addition, the benchmark
problems also served as a vehicle to compare the performance of FANM
with the Newton-Krylov method. For the thermal convection cavity
problem, FANM was observed to converge in fewer linear solver
iterations than Newton-Krylov at all Rayleigh numbers tested when the
same preconditioning was applied to both methods. This means that FANM
demonstrated superior iterative performance for problems dominated by
natural convection, meeting the goal of improved iterative performance
in this case.

Iterative performance for the problems dominated by intertial driven
flow varied depending on the situation. For the lid driven cavity
problem, FANM converged in more linear solver iterations for 3 out of
4 cases. However, for each of these cases it was observed that the
extra MCSA iterations were generated by a smaller forcing term at each
Newton iteration when compared to the Newton-Krylov solver. Given that
a smaller forcing term is equivalent to requesting convergence of the
linear solver to a smaller residual, we expect these extra
iterations. For the lid driven cavity case where FANM converged in
fewer iterations, it was observed that increasing the number of
stochastic histories used at every MCSA iteration enabled convergence
in fewer iterations, again meeting the goal of improved iterative
performance.

The backward facing step problem at low Reynolds number gave better
performance with FANM convergining in fewer linear solver
iterations. However, as the Reynolds number was increased so did the
number of MCSA iterations required to converge the linear model at
each FANM iteration. Unlike the lid driven cavity problem, this was
discovered to occur due to the inability of MCSA to quickly converge
the ill-conditioned linear model rather than the introduction of
smaller forcing terms.

Timing performance for all benchmarks favored the Newton-Krylov solver
with FANM observed to be $O(100)$ slower for the thermal convection
cavity and lid driven cavity problems and $O(1,000)$ times for the
backward facing step problem. For the first two cases, the timing
differences were observed to be qualititavely the same as those
observed for the $SP_N$ performance analysis. Again, this comes from
both lack of optimization of the Monte Carlo sequence and the
introduction of explicit preconditioning. For the backward facing step
problem, the ill-conditioning of the system adds the extra order of
magnitude slow down.

%%---------------------------------------------------------------------------%%
\section{Parallel Monte Carlo Synthetic Acceleration\ }
\label{sec:parallel_mc_conclusions}

A new parallel MCSA algorithm was developed for this work to meet the
goal of demonstrating the improved scalability of MCSA on
leadership-class hardware. It was found the MCSA can indeed be
effectively parallelized using the multiple-set overlapping-domain
decomposition algorithm borrowed from the reactor physics
community. Using a neutron diffusion problem, the parallel algorithm
was verified to produce the same results as two production Krylov
methods.

The new algorithm was tested in a wide variety of parallel scaling
studies on the Titan Cray XK7 machine at the Oak Ridge Leadership
Computing Facility. To test the algorithm at high levels of
concurrency, up to 65,356 cores were used in strong scaling exercises
and 131,072 cores used in weak scaling exercises using the neutron
diffusion problem. In general, the new parallel MCSA algorithm was
observed to produce better parallel scaling results when compared to a
production GMRES and Conjugate Gradient method. We note here that
these scaling studies should be reconsidered if arithmetic
optimization of the code has been completed.

It was found that the leakage of histories from domain to domain in
the parallel Monte Carlo algorithm could in fact be quantified
analytically using the algebraic properties of the system. These
relationships were then used to determine the amount of overlap one
may require in the parallel algorithm to reduce communication costs
and increase parallel efficiencies. Scaling studies showed that in the
strong case overlap in small quanities on the order of the
mean-free-path of a stochastic history in the simulation could boost
parallel efficiencies by a few percent. However, it was found that
this additional overal was not effective in boosting strong scaling
efficiencies. It was found that overall overlap was not very effective
due to the fact that the parallel communication saved during the Monte
Carlo transport sequence is simply deferred until after transport is
complete when it manifests itself as an overlapping parallel vector
reduction operation.

Applying multiple sets in the parallel algorithm was found to not
enhance the weak scaling of the problem as an additional parallel
overhead is introduced when the calculations from the set are combined
in superposition. For the strong scaling case, improvements were not
noted until after the strong scaling wall was hit. At this point,
multiple sets were observed to increase parallel efficiencies from
38\% to 58\% at 16,384 cores. Perhaps more important here is the fact
that although the parallel efficiency was reduced, multiple sets were
observed to actually improve the time to solution. Unlike a
traditional Krylov method that we might apply to solve a neutron
transport problem, using MCSA means that we can actually make a
physical copy of the problem on the machine and can combine seperate
Monte Carlo solutions for each copy through superposition to enhance
time to solution. Time to solution is then improved because fewer
histories were run in each copy and therefore each MCSA iteration is
faster or more global histories are computed and fewer MCSA iterations
are required to converge.

Finally, given that overlap was not very constructive in boosting
parallel efficiencies, it was postulated that very little
domain-to-domain communication of histories was occuring in the first
place and then subsequently verified using the analytic relationships
for domain leakage. Using this idea, we implemented a subdomain
Neumann-Ulam method with MCSA such that MCSA now takes the form of a
stochastic realization of an additive Schwarz method. Scaling studies
using this technique showed significant improvements in parallel
scalability even when compared to the MCSA results when
domain-to-domain communication was present, further enhancing the
method and meeting the goal of improved scalability.

%%---------------------------------------------------------------------------%%
\section{Future Work\ }
\label{sec:future_work}

\subsection{Preconditioning}
\label{subsec:future_preconditioning}

Standalone Monte Carlo as a preconditioner? (e.g. for flex-GMRES)

Stochastic variants of conventional preconditioners?

Variance reduction for preconditioning?

\subsection{Breaking away from $\rho(H) < 1$}
\label{subsec:future_spec_rad}

Monte Carlo methods of the 2nd Degree?

Stochastic projection methods?

\subsection{Performance}
\label{subsec:future_performance}

Implementation optimization - can we approach Krylov performance?

Reduction in memory footprint

Multiple sets parallel overhead reduction

Controling MCSA histories as a function of nonlinear iteration/forcing
term?

%%---------------------------------------------------------------------------%%
\section{Closing Remarks\ }
\label{sec:closing}
