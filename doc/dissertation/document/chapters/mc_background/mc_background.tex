\chapter{Monte Carlo Solution Methods for Linear Systems}
\label{ch:stochastic_methods}
An alternative approach to approximate matrix inversion is to employ
Monte Carlo methods that sample a distribution with an expectation
value equivalent to that of the inverted operator. Such methods have
been in existence for decades with the earliest reference noted here a
manuscript published in 1950 by Forsythe and Leibler
\citep{forsythe_matrix_1950}. In their outline, Forsythe and Liebler
in fact credit the creation of this technique to J. Von Neumann and
S.M. Ulam some years earlier than its publication. In 1952 Wasow
provided a more formal explanation of Von Neumann and Ulam's method
\citep{wasow_note_1952} and Hammersley and Handscomb's 1964 monograph
\citep{hammersley_monte_1964} and Spanier and Gelbard's 1969 book
\citep{spanier_monte_1969} present additional detail on this topic
using a collection of references from the 1950's and early 1960's.

In this chapter, we will present the fundamentals of the Monte Carlo
method for discrete linear systems. Both the forward and adjoint
methods will be presented and analyzed including a brief variance
analysis of several Monte Carlo estimators. The Sequential Monte Carlo
and Monte Carlo Synthetic Acceleration methods will then be presented
as a means of leveraging the basic Monte Carlo methods in an iterative
refinement scheme that accelerates their convergence. Using these
iterative schemes, a set of modest variance reduction techniques will
be introduced and their effects on the Monte Carlo methods explored.

\section{Preliminaries}
\label{sec:linear_preliminaries}
We seek solutions of the general linear problem in the following form:
\begin{equation}
  \ve{A} \ve{x} = \ve{b}\:,
  \label{eq:linear_problem}
\end{equation}
where $\ve{A} \in \mathbb{R}^{N \times N}$ is a matrix operator such
that $\ve{A} : \mathbb{R}^{N} \rightarrow \mathbb{R}^{N}$, $\ve{x} \in
\mathbb{R}^N$ is the solution vector, and $\ve{b} \in \mathbb{R}^N$ is
the forcing term. The solutions to Eq~(\ref{eq:linear_problem}) will
be generated by inverting $\ve{A}$ either directly or indirectly:
\begin{equation}
  \ve{x} = \ve{A}^{-1} \ve{b}
  \label{eq:linear_problem_solution}\:.
\end{equation}
In addition we can define the residual:
\begin{equation}
  \ve{r} = \ve{b} - \ve{A}\ve{x}\:,
  \label{eq:linear_residual}
\end{equation}
such that an exact solution $\ve{x}$ has been found when
$\ve{r}=\ve{0}$.  From the statement in
Eq~(\ref{eq:linear_problem_solution}) we can already place a
restriction on $\ve{A}$ by requiring that it be \textit{nonsingular},
meaning that we can in fact compute $\ve{A}^{-1}$. In this work we
will focus our efforts on approximately inverting the operator through
various means.

In a discussion of methods for solving linear systems, several
mathematical tools are useful in characterizing the qualities of the
linear system. Among the most useful are the \textit{eigenvalues} of
the matrix, $\sigma(\ve{A})$. We find these by solving the eigenvalue
problem:
\begin{equation}
  \ve{A} \ve{x} = \lambda \ve{x},\ \lambda \in \sigma(\ve{A})\:.
  \label{eq:eigenvalue_problem}
\end{equation}
By writing Eq~(\ref{eq:eigenvalue_problem}) in a different form,
\begin{equation}
  (\ve{A} - \lambda \ve{I})\ve{x} = 0 \:,
  \label{eq:eigenvalue_problem_2}
\end{equation}
and demanding that non-trivial solutions for $\ve{x}$ exist, it is
then required that $|\ve{A} - \lambda \ve{I}| = 0$. Expanding this
determinant yields a characteristic polynomial in terms of $\lambda$
with roots that form the set of eigenvalues, $\sigma(\ve{A})$. Each
component of $\sigma(\ve{A})$ can then be used to solve
Eq~(\ref{eq:eigenvalue_problem_2}) for a particular permutation of
$\ve{x}$. The set of all permutations form the \textit{eigenvectors}
of $\ve{A}$. A quantity of particular interest that is computable from
the eigenvalues of a matrix $\ve{A}$ is the \textit{spectral radius},
$\rho(\ve{A})$, defined by Saad \citep{saad_iterative_2003} as:
\begin{equation}
  \rho(\ve{A}) = \max_{\lambda \in \sigma(\ve{A})} |\lambda| \:.
  \label{eq:spectral_radius}
\end{equation}

%%---------------------------------------------------------------------------%%
\section{Neumann-Ulam Method}
\label{sec:mc_preliminaries}
We begin our discussion of Monte Carlo methods by seeking a solution
to Eq~(\ref{eq:linear_problem}). For a given linear operator $\ve{A}$,
we can use diagonal splitting in a similar manner as the stationary
method in Eq~(\ref{eq:linear_split_equation2}) to define the following
operator\footnote{It should be noted that non-diagonal splittings have
  been recently explored \citep{srinivasan_monte_2010} and have the
  potential to improve efficiency. However, it was observed in this
  work that this type of splitting did not improve performance in the
  asymptotic limit of $\rho(\ve{H}) \rightarrow 1$ for non-trivial
  problems.}:
\begin{equation}
  \ve{H} = \ve{I} - \ve{A}\:,
  \label{eq:linear_mc_iteration_matrix}
\end{equation}
such that we are solving the system:
\begin{equation}
  \ve{x} = \ve{H} \ve{x} + \ve{b}\:.
  \label{eq:richardson_split}
\end{equation}
We can then form an alternative representation for $\ve{A}^{-1}$ by
generating the \textit{Neumann series}:
\begin{equation}
  \ve{A}^{-1} = (\ve{I}-\ve{H})^{-1} = \sum_{k=0}^{\infty} \ve{H}^k\:,
  \label{eq:neumann_series}
\end{equation}
which will converge if the spectral radius of $\ve{H}$ is less than
1. If we then apply this Neumann series to the right hand side of
Eq~(\ref{eq:linear_problem}) we acquire the solution to the linear
problem:
\begin{equation}
  \ve{A}^{-1}\ve{b} = \sum_{k=0}^{\infty} \ve{H}^k\ve{b} = \ve{x}\:.
  \label{eq:neumann_solution}
\end{equation}
An approximation of this summation by truncation will therefore lead
to an approximation of the solution. If we expand the summation with a
succession of matrix-vector multiply operations, we arrive at an
alternative perspective of this summation by considering the $i^{th}$
component of the solution vector:
\begin{equation}
  x_i = \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
  \sum_{i_k}^{N}h_{i,i_1}h_{i_1,i_2}\ldots h_{i_{k-1},i_k}b_{i_k}\:,
  \label{eq:expanded_neumann_solution}
\end{equation}
which can interpreted as a series of transitions between states,
\begin{equation}
 \nu = i \rightarrow i_1 \rightarrow \cdots \rightarrow i_{k-1}
 \rightarrow i_{k}\:,
  \label{eq:mc_walk_permutation}
\end{equation}
in $\ve{H}$ where $\nu$ is interpreted as a particular random walk
sequence permutation. We can generate these sequences of transitions
through Monte Carlo random walks by assigning them both a probability
and weight. As a reinterpretation of the iteration matrix, we then
form the \textit{Neumann-Ulam decomposition} of \ve{H}:
\begin{equation}
  \ve{H} = \ve{P} \circ \ve{W}\:,
  \label{eq:neumann_ulam_decomposition}
\end{equation}
where $\circ$ denotes the Hadamard product operation\footnote{The
  Hadamard product $\ve{A} = \ve{B} \circ \ve{C}$ is defined
  element-wise as $a_{ij} = b_{ij} c_{ij}$.}, $\ve{P}$ denotes the
transition probability matrix, and $\ve{W}$ denotes the transition
weight matrix. This decomposition, a generalization of Dimov's work
\citep{dimov_new_1998}, is an extension of the original Neumann-Ulam
scheme in that now a weight cutoff can be used to terminate a random
walk sequence and therefore truncate the Neumann series it is
approximating. The formulation of $\ve{P}$ and $\ve{W}$ will be
dependent on whether we choose a direct or adjoint Monte Carlo
sequence to estimate the state transitions in
Eq~(\ref{eq:expanded_neumann_solution}). In the direct method, we will
use the provided linear operator $\ve{A}$ to form the Neumann Ulam
decomposition while the adjoint method will use the adjoint linear
operator ($\ve{A}^T$ for real-valued systems) to form the
decomposition.

%%---------------------------------------------------------------------------%%
\section{Direct Monte Carlo Method}
\label{sec:direct_mc}
In the context of matrix inversion, a direct (forward) method resembles an
adjoint Monte Carlo method in the reactor physics community where the
solution state is sampled and the source terms that contribute to it
are assembled. To achieve this, we build the direct method
Neumann-Ulam decomposition per Dimov's approach by first choosing a
probability matrix that is a row scaling of $\ve{H}$ such that its
components are:
\begin{equation}
  p_{ij} = \frac{|h_{ij}|}{\sum_j |h_{ij}|}\:.
  \label{eq:direct_probability}
\end{equation}
From this, we then see that the probability of transitioning from a
state $i$ to a state $j$ is implicitly linked to the original operator
$\ve{A}$ in that those terms with large values, and therefore those
that make the greatest contribution to the numerical solution, will be
sampled with a higher probability than smaller terms. In addition, the
row scaling provides a normalization over the state to which we are
transitioning such that $\sum_j p_{ij} = 1$, meaning that we sample
the probabilities over the rows of the matrix. The components of
the weight matrix are then defined by
Eq~(\ref{eq:neumann_ulam_decomposition}) as:
\begin{equation}
  w_{ij} = \frac{h_{ij}}{p_{ij}}\:.
  \label{eq:direct_weight}
\end{equation}
It should be noted here that if $\ve{A}$ is sparse, then $\ve{H}$,
$\ve{P}$, and $\ve{W}$ must be sparse as well by
definition. Additionally, we only compute $\ve{P}$ and $\ve{W}$ from
the non-zero elements of $\ve{H}$ as those components that are zero
will not participate in the random walk and thus produce identical
sparsity patterns for all matrices.

Using these matrices, we can then form the expectation value of the
direct solution. For a given random walk permutation $\nu$, we define
the weight of that permutation on the $m^{th}$ step to be:
\begin{equation}
  W_{m} = w_{i_0,i_1} w_{i_1,i_2} \cdots w_{i_{m-1},i_m}\:,
  \label{eq:direct_permutation_weight}
\end{equation}
such that the weight of each transition event contributes to the total
through multiplication with $W_0 = 1$ as the starting weight. The
contribution to the solution from a particular random walk permutation
with $k$ total events is then the \textit{forward estimator}:
\begin{equation}
  X_{i_0 = i}(\nu) = \sum_{m=0}^k W_{m} b_{i_m}\:,
  \label{eq:direct_permutation_contribution}
\end{equation}
where $X_{i_0 = i}(\nu)$ signifies that the solution state, $i_0$, in
which the random walk $\nu$ started is also the state, $i$, in which
we are tallying. We then define the probability that a particular
random walk permutation of $k$ events will occur:
\begin{equation}
  P_{\nu} = p_{i,i_1} p_{i_1,i_2} \cdots p_{i_{k-1},i_k}\:.
  \label{eq:direct_permutation_probability}
\end{equation}
Finally, we define the expectation value of $X$ to be the collection
of all random walk permutations and their probabilities:
\begin{equation}
  E\{X_i\} = \sum_{\nu} P_{\nu} X_{i}(\nu)\:,
  \label{eq:direct_expectation_value}
\end{equation}
which, if expanded, directly recovers the exact solution by forming
the Neumann series:
\begin{equation}
  \begin{split}
    E\{X_i\}
    &=\sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
    \sum_{i_k}^{N} p_{i,i_1}p_{i_1,i_2}\ldots p_{i_{k-1},i_k}
    w_{i,i_1}w_{i_1,i_2}\ldots w_{i_{k-1},i_k} b_{i_k}\\ &= x_i\:,
  \end{split}
  \label{eq:direct_expectation_expansion}
\end{equation}
therefore providing an unbiased Monte Carlo estimator. 

In cases where we seek only approximate solutions, we need only to
perform a predetermined number of random walks in order to generate an
approximation for $\ve{x}$. If we are only to approximate the
solution, we also need conditions by which we may terminate a random
walk as the Neumann Ulam decomposition defined by
Eqs~(\ref{eq:direct_probability}) and (\ref{eq:direct_weight}) will
create a random walk weight in Eq~(\ref{eq:direct_permutation_weight})
that approaches, but never reaches zero. We do this by noticing that
the factors added to Eq~(\ref{eq:direct_permutation_weight}) will
become diminishingly small due to their definition in
Eq~(\ref{eq:direct_weight}) and therefore their contributions to the
solution estimate will become negligible. Using this, we choose
terminate a random walk sequence with a \textit{weight cutoff}, $W_c$,
that is enforced when $W_m < W_c$ for a particular random walk
permutation.

\subsection{Forward Estimator Variance}
\label{subsec:forward_variance}
We can compute the variance of the forward estimator through traditional
methods by defining the variance, $\sigma_i$, for each component in
the solution:
\begin{equation}
  {\sigma_i}^2 = E\{X_i - (\ve{A}^{-1}\ve{b})_i\}^2 = E\{X_i^2\} - x_i^2\:,
  \label{eq:direct_variance_1}
\end{equation}
where the vector exponentials are computed element-wise. Inserting
Eq~(\ref{eq:direct_expectation_value}) gives:
\begin{equation}
  \sigma_i^2 = \sum_{\nu} P_{\nu} X_{i}(\nu)^2 - x_i^2\:,
  \label{eq:direct_variance_2}
\end{equation}
and applying Eq~(\ref{eq:direct_permutation_contribution}):
\begin{equation}
  \sigma_i^2 = \sum_{\nu} P_{\nu} \Big(\sum_{m=0}^k W_{m}^2 b_{i_m}^2
  + 2 \sum_{\substack{ j=0 \\ m<j}}^k W_m W_j b_{i_m} b_{i_j} \Big)-
  x_i^2\:.
  \label{eq:direct_variance_3}
\end{equation}
We can distribute the random walk probability to yield an expanded
form of the variance:
\begin{equation}
  \sigma_i^2 = \sum_{\nu} P_{\nu} \sum_{m=0}^k W_{m}^2 b_{i_m}^2 + 2
  \sum_{\nu} P_{\nu} \sum_{\substack{ j=0 \\ m<j}}^k W_m W_j b_{i_m}
  b_{i_j} - x_i^2\:.
  \label{eq:direct_variance_3_2}
\end{equation}
In particular, we will isolate the first summation of the variance by
expanding it:
\begin{equation}
  \sum_{\nu} P_{\nu} \sum_{m=0}^k W_{m}^2 b_{i_m}^2 =
  \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots \sum_{i_k}^{N}
  p_{i,i_1}p_{i_1,i_2}\ldots p_{i_{k-1},i_k}
  w^2_{i,i_1}w^2_{i_1,i_2}\ldots w^2_{i_{k-1},i_k} b_{i_k}^2\:.
  \label{eq:direct_variance_4}
\end{equation}
Using this expansion, we can arrive at a more natural
reason for enforcing $\rho(\ve{H}) < 1$ for our Monte Carlo method to
converge. Per the Hadamard product, we can concatenate the summation
in Eq~(\ref{eq:direct_variance_4}):
\begin{equation}
  (\ve{P} \circ \ve{W} \circ \ve{W})^k =
  \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots \sum_{i_k}^{N}
  p_{i,i_1}p_{i_1,i_2}\ldots p_{i_{k-1},i_k}
  w^2_{i,i_1}w^2_{i_1,i_2}\ldots w^2_{i_{k-1},i_k}\:.
  \label{eq:double_weighted_decomposition}
\end{equation}
If we assign $\ve{G} = \ve{P} \circ \ve{W} \circ \ve{W}$ as in
Eq~(\ref{eq:neumann_ulam_decomposition}), we then have:
\begin{equation}
   (\ve{P} \circ \ve{W} \circ \ve{W})^k =
  \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
  \sum_{i_k}^{N}g_{i,i_1}g_{i_1,i_2}\ldots g_{i_{k-1},i_k}\:,
  \label{eq:direct_variance_6}
\end{equation}
which is the general Neumann series for $\ve{G}$,
\begin{equation}
  \ve{T} = \sum_{k=0}^{\infty} \ve{G}^k\:,
  \label{eq:variance_neumann_series}
\end{equation}
where $\ve{T} = (\ve{I}-\ve{G})^{-1}$. We can then insert $T$ back
into the variance formulation for a more concise definition:
\begin{equation}
  \sigma^2_i = (\ve{T}\ve{b}^2)_i + 2 \sum_{\nu} P_{\nu}
  \sum_{\substack{ j=0 \\ m<j}}^k W_m W_j b_{i_m} b_{i_j} - x_i^2\:.
  \label{eq:direct_variance_5}
\end{equation}
We can relate $\ve{G}$ to $\ve{H}$ by noting that $\ve{G}$ simply
contains an additional Hadamard product with the weight matrix. The
Hadamard product has the property that:
\begin{equation}
  |\ve{H} \circ \ve{W}| \geq |\ve{H}|\ |\ve{W}|\:.
  \label{eq:hadamard_inequality}
\end{equation}
Using the norm property of the Hadamard product and
Eq~(\ref{eq:neumann_ulam_decomposition}), we can define the norm of
$\ve{W}$ as:
\begin{equation}
  \frac{|\ve{H}|}{|\ve{P}|} \geq |\ve{W}|\:.
  \label{eq:weight_norm}
\end{equation}
Choosing the infinity norm of the operator as defined in
Eq~(\ref{eq:matrix_infinity_norm}), the row normalized probability
matrix will yield a norm of 1 giving the following inequality for
relating $\ve{G}$ and $\ve{H}$:
\begin{equation}
  |\ve{G}| \geq |\ve{H}|^2
  \label{eq:variance_norm_inequality}
\end{equation}
Using these relations to analyze Eq~(\ref{eq:direct_variance_5}), we
see that if $\rho(\ve{G}) > 1$, then the first sum in
Eq~(\ref{eq:variance_neumann_series}) will not converge and an
infinite variance will arise as the elements of $\ve{T}$ become
infinite in Eq~(\ref{eq:direct_variance_5}). We must restrict $\ve{G}$
to alleviate this and therefore restrict $\ve{H}$ due to
Eq~(\ref{eq:variance_norm_inequality}) with $\rho(\ve{H}) < 1$ so that
our expectation values for the solution may have a finite variance.

\subsection{Direct Method: Evolution of a Solution}
\label{subsec:direct_evolution}
As a means of visually demonstrating the direct Monte Carlo method,
consider a 2-dimensional thermal diffusion problem with sources on the
left and right hand sides of the domain and a uniform source
throughout the domain of 1/5 the strength of the boundary sources as
shown in Figure~\ref{fig:heat_setup}.
\begin{figure}[t!]
  \begin{center}
    \scalebox{1.2}{ \input{chapters/mc_background/heat_eq_setup.pdftex_t} }
  \end{center}
  \caption{\textbf{Problem setup for 2D heat equation.}
    \textit{Dirichlet conditions are set for the temperature on all 4
      boundaries of the Cartesian grid. Background source of 1/5 the
      value of the boundary sources present. $50 \times 50$ grid.}}
  \label{fig:heat_setup}
\end{figure}
For this problem, the number of histories used to compute the solution
at each grid point (state) in the domain was increased from 1 to 1000
in order to demonstrate the effects on the solution and the
statistical nature of the method. Figure~\ref{fig:direct_evolution}
gives these results.
\begin{figure}[t!]
  \begin{center}
    \includegraphics[width=6in]{chapters/mc_background/direct_evolution.png}
  \end{center}
  \caption{\textbf{Direct Monte Carlo solution to the heat equation
      with varying numbers of histories.} \textit{Top left: 1 history
      per state. Top right: 10 histories per state. Bottom left: 100
      histories per state. Bottom right: 1000 histories per state.}}
  \label{fig:direct_evolution}
\end{figure}
As the number of histories used per state is increased, the
statistical variance of the solutions is decreased as more tallies are
made. Starting with single history at each state in the
domain, the high variance prevents a precise solution from being
obtained although we begin to see the solution take shape as
expected. At 1000 histories per state, enough tallies have been made
to generate a reasonable estimate for the structure of the
solution. It is interesting to note here that as the statistical
uncertainty is reduced at each grid point in the domain, the solution
is resolved in a certain sense, analagous to the convergence of a
traditional iterative method.
\clearpage

%%---------------------------------------------------------------------------%%
\section{Adjoint Monte Carlo Method}
\label{sec:adjoint_mc}
Often a more useful form, an alternative to forward Monte Carlo matrix
inversion is the adjoint method. We begin by defining the linear
system adjoint to Eq~(\ref{eq:linear_problem}):
\begin{equation}
  \ve{A}^T \ve{y} = \ve{d}\:,
  \label{eq:adjoint_linear_problem}
\end{equation}
where $\ve{y}$ and $\ve{d}$ are the adjoint solution and source
vectors respectively and $\ve{A}^T$ is the adjoint operator for
$\ve{A} \in \mathbb{R}^{N \times N}$. We can split this equation to
mirror Eq~(\ref{eq:richardson_split}):
\begin{equation}
  \ve{y} = \ve{H}^T \ve{y} + \ve{d}\:.
  \label{eq:adjoint_split_system}
\end{equation}
As was required for convergence with the direct method using
Eq~(\ref{eq:richardson_split}), the spectral radius of $\ve{H}$ must
remain less than 1 as $\ve{H}^T$ contains the same eigenvalues and
therefore has the same spectral radius. By defining the following
inner product equivalence \citep{spanier_monte_1969}:
\begin{equation}
  \langle \ve{A}^T \ve{x}, \ve{y} \rangle = \langle \ve{x}, \ve{A}
  \ve{y} \rangle\:.
  \label{eq:adjoint_operator_product}
\end{equation}
it follows that:
\begin{equation}
  \langle \ve{x}, \ve{d} \rangle = \langle \ve{y}, \ve{b} \rangle\:.
  \label{eq:adjoint_vector_relation}
\end{equation}
Using these definitions, we can derive an estimator from the adjoint
method that will also give the solution vector, $\ve{x}$. As with the
direct method, we can acquire the adjoint solution by forming the
Neumann series by writing Eq~(\ref{eq:adjoint_split_system}) as:
\begin{equation}
  \ve{y} = (\ve{I} - \ve{H}^T)^{-1} \ve{d}\:,
  \label{eq:adjoint_split_system_2}
\end{equation}
which in turn yields the Neumann series using the adjoint operator:
\begin{equation}
  \ve{y} = \sum_{k=0}^{\infty} (\ve{H}^T)^k\ve{d}\:.
  \label{eq:adjoint_neumann_series}
\end{equation}
We expand this summation to again yield a series of transitions that
can be approximated by a Monte Carlo random walk sequence, this time
forming the Neumann series in reverse order:
\begin{equation}
  y_i = \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
  \sum_{i_k}^{N}h_{i_k,i_{k-1}}\ldots h_{i_2,i_1} h_{i_1,i} d_{i_k}\:.
  \label{eq:adjoint_neumann_solution}
\end{equation}
We can readily build an estimator for the adjoint solution from this
series expansion, but we instead desire the solution to
Eq~(\ref{eq:linear_problem}). Here we have 2 unknowns, $\ve{y}$ and
$\ve{d}$, and therefore we require two constraints to close the
system. We use Eq~(\ref{eq:adjoint_vector_relation}) as the first
constraint and as a second constraint we select:
\begin{equation}
  \ve{d} = \boldsymbol{\delta}_j\:,
  \label{eq:adjoint_second_constraint}
\end{equation}
where $\boldsymbol{\delta}_j$ is one of a set of vectors in which the
$j^{th}$ component is the Kronecker delta function $\delta_{i,j}$. If
we apply Eq~(\ref{eq:adjoint_second_constraint}) to our first
constraint Eq~(\ref{eq:adjoint_vector_relation}), we get the following
convenient outcome:
\begin{equation}
  \langle \ve{y}, \ve{b} \rangle = \langle \ve{x},
  \boldsymbol{\delta}_j \rangle = x_j \:,
  \label{eq:inner_product_constraint}
\end{equation}
meaning that if we compute the inner product of the original source
and the adjoint solution using a delta function source, we recover one
component of the original solution.

In terms of radiation transport, this adjoint method is equivalent to
a traditional forward method where the initial state $i_0$ of the
random walk is determined by sampling the source vector $\ve{b}$ with
probabilities:
\begin{equation}
  P_{i_0=i}(\nu) = \frac{|b_i|}{||\ve{b}||_1}\:.
  \label{eq:adjoint_source_probability}
\end{equation}
The random walk starting weight will then be $W_0 = b_{i_0}$.  As a
result of using the adjoint system, we modify our probabilities and
weights using the \textit{adjoint Neumann-Ulam decomposition} of
$\ve{H}$:
\begin{equation}
  \ve{H}^{T} = \ve{P} \circ \ve{W}\:,
  \label{eq:adjoint_neumann_ulam}
\end{equation}
where now we are forming the decomposition with respect to the
transpose of $\ve{H}$. We then follow the same procedure as the direct
method for forming the probability and weight matrices in the
decomposition. Using the adjoint form, probabilities should instead be
column-scaled:
\begin{equation}
  p_{ij} = \frac{|h_{ji}|}{\sum_j |h_{ji}|}\:,
  \label{eq:adjoint_probability}
\end{equation}
such that we expect to select a new state, $j$, from the current state
in the random walk, $i$, by sampling column-wise (or row-wise if an
adjoint probability matrix is formed). Per
Eq~(\ref{eq:adjoint_neumann_ulam}), the transition weight is then
defined as:
\begin{equation}
  w_{ij} = \frac{h_{ji}}{p_{ij}}\:.
  \label{eq:adjoint_weight}
\end{equation}
Using the decomposition we can then define an expectation value for
the adjoint method. Given Eq~(\ref{eq:direct_permutation_weight}) as
the weight generated for a particular random walk permutation as in
Eq~(\ref{eq:mc_walk_permutation}) and our result from
Eq~(\ref{eq:inner_product_constraint}) generated by applying the
adjoint constraints, the contribution to the solution in state $j$
from a particular random walk permutation of $k$ events is then the
\textit{collision estimator}:
\begin{equation}
  X_{j}(\nu) = \sum_{m=0}^k W_{m} \delta_{i_m,j}\:,
  \label{eq:adjoint_permutation_contribution}
\end{equation}
where the Kronecker delta indicates that the tally contributes only in
the current state, $i_m$, of the random walk.  Note here that the
estimator in Eq~(\ref{eq:adjoint_permutation_contribution}) does not
have a dependency on the source state as in
Eq~(\ref{eq:adjoint_permutation_contribution}), providing a remedy for
the situation in the direct method where we must start a random walk
in each source state for every permutation if we want to compute a
solution estimate for that state. In the adjoint method, we instead
tally in all states and those of lesser importance will not be visited
as frequently by the random walk. Finally, the expectation value using
all permutations is:
\begin{equation}
  E\{X_j\} = \sum_{\nu} P_{\nu} X_{j}(\nu)\:
  \label{eq:adjoint_expectation_value}
\end{equation}
which, if expanded in the same way as the direct method, directly
recovers the exact solution:
\begin{equation}
  \begin{split}
    E\{X_j\} &=\sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
    \sum_{i_k}^{N} b_{i_0} h_{i_0,i_1}h_{i_1,i_2}\ldots
    h_{i_{k-1},i_k} \delta_{i_k,j} \\ &= x_{j}\:,
  \end{split}
  \label{eq:adjoint_expectation_expansion}
\end{equation}
therefore also providing an unbiased Monte Carlo estimate of the
solution. Note that this expansion produces the effective sequence of
matrix-vector multiplications with the $b_{i_0}$ component of the
source vector which will be selected at random for each walk
permutation and the unbiasedness of the estimator relies on an
unbiased sampling of the source. It should also be noted here that
Eq~(\ref{eq:adjoint_expectation_expansion}) only computes a single
component of our desired solution vector when really what we desire is
the entire solution vector. In an adjoint Monte Carlo simulation using
this estimator, the $w_{ij}$ elements that are added into the tally
for each state are only selected if the random walk currently resides
in that state. Much like a mesh tally in a particle transport
simulation, we have $N$ simultaneous tallies for $\ve{A} \in
\mathbb{R}^{N \times N}$ that will yield the entire solution
vector. Based on their current state in the system, the random walks
will contribute tally $j$ in this group.

Like the direct method, we also desire a criteria for random walk
termination for problems where only an approximate solution is
necessary. For the adjoint method, we utilize a \textit{relative
  weight cutoff}:
\begin{equation}
  W_f = W_c b_{i_0}\:,
  \label{eq:relative_weight_cutoff}
\end{equation}
where $W_c$ is defined as in the direct method. The adjoint random
walk will then be terminated after $m$ steps if $W_m < W_f$ as tally
contributions become increasingly small.

\subsection{Collision Estimator Variance}
\label{subsec:forward_variance}
We can compute the variance of the collision estimator in the same way
as the direct estimator for each component in the solution where now:
\begin{equation}
  \sigma_j^2 = \sum_{\nu} P_{\nu} \sum_{m=0}^k W_{m}^2 \delta_{i_m,j} + 2
  \sum_{\nu} P_{\nu} \sum_{\substack{ l=0 \\ m<l}}^k W_m W_l
  \delta_{i_m,j} \delta_{i_l,j} - x_j^2\:.
  \label{eq:collision_variance_1}
\end{equation}
In this case, in the second summation $m \neq l$ for all states due to
the form of the summation and therefore the delta functions,
$\delta_{i_m,j}$ or $\delta_{i_l,j}$, will only be nonzero for random
walks that are in the current solution state (when $i_m = i_l = j$)
and other states visited do not contribute to the variance of the
current state (when $i_m \neq i_l$). This is important as it shows a
decoupling of the variance among the solution vector states, meaning
that the variance in solution state $i$ does not depend on the
variance in solution state $j$.

Expanding the transition probabilities in the first sum again yields a
Neumman series in the same form as that explored for the forward
estimator, this time with the terms in reverse order and the
introduction of the Kronecker delta:
\begin{multline}
  \sigma_j^2 = \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
  \sum_{i_k}^{N} p_{i_k,i_{k-1}}\ldots p_{i_2,i_1} p_{i_1,i_0}
  w^2_{i_k,i_{k-1}}\ldots w^2_{i_2,i_1} w^2_{i_1,i_0}
  b^2_{i_0}\delta_{i_k,j} + \\ 2 \sum_{\nu} P_{\nu} \sum_{\substack{
      l=0 \\ m<l}}^k W_m W_l \delta_{i_m,j} \delta_{i_l,j} - x_j^2\:.
  \label{eq:collision_variance_2}
\end{multline}
If we again define $\ve{G} = \ve{P} \circ \ve{W} \circ \ve{W}$, we
then have:
\begin{multline}
  \sigma^2_j = \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
  \sum_{i_k}^{N}g_{i_{k},i_{k-1}} \ldots
  g_{i_2,i_1}g_{i_1,i_0}b_{i_0}\delta_{i_k,j} + \\ 2 \sum_{\nu}
  P_{\nu} \sum_{\substack{ l=0 \\ m<l}}^k W_m W_l \delta_{i_m,j}
  \delta_{i_l,j} - x_j^2\:,
\label{eq:collision_variance_3}
\end{multline}
where now $\ve{G}$ in this case is the transpose of that used in
Eq~(\ref{eq:direct_variance_6}). The Kronecker delta again implies
that the variance contribution from each random walk will only be in
its current state and for many random walks, many starting weights of
$b_{i_0}$ will contribute to the variance in the same way as they
contribute to the solution tally. As the transpose is formed and the
Neumann series of $\ve{G}$ is in reverse order in
Eq~(\ref{eq:collision_variance_3}) relative to its formulation in the
forward estimator, then Eq~(\ref{eq:collision_variance_3}) and
Eq~(\ref{eq:direct_variance_6}) are equivalent and therefore the
collision estimator is bound by the same restrictions on
$\rho(\ve{G})$ and $\rho(\ve{H})$ to ensure that the variance is
finite.

\subsection{Expected Value Estimator}
\label{subsec:expected_value_estimator}
In addition to the collision estimator, an additional estimator is
available due to the work of Okten \citep{okten_solving_2005} that
uses the method of expected values as a means to improve the Monte
Carlo estimate. As outlined by Spanier and Gelbard
\citep{spanier_monte_1969}, the method of expected values is a
deterministic averaging of events that may potentially occur in the
Monte Carlo random walk sequence. Okten applied this principle
directly to discrete Monte Carlo by forming the \textit{expected value
  estimator} for a random walk of $k$ events:
\begin{equation}
  X_{j}(\nu) = b_j + \sum_{m=0}^k W_m h_{j,i_m}\,
  \label{eq:expected_value_estimator}
\end{equation}
where now the contribution of the iteration matrix is
deterministically averaged at step $m$ over all potential states $j$
that may be reached from the current state $i_m$. Via Okten, the
estimator can be shown to be unbiased through a comparison to
the expected value estimator. We can first rewrite the summation in
Eq~(\ref{eq:expected_value_estimator}):
\begin{equation}
  X_{j}(\nu) = b_j + \sum_{m=0}^k \sum_{i=1}^N W_m
  \delta_{i_m,i} h_{ji}\,
  \label{eq:unbiased_eval_1}
\end{equation}
where $N$ is the number of states in the system. Immediately, we see
the collision estimator as defined by
Eq~(\ref{eq:adjoint_permutation_contribution}) and can therefore write
the expectation value as:
\begin{equation}
  E\{X_{j}\} = b_j + \sum_{i=1}^N E\{X_{i}\} h_{ji}\,
  \label{eq:unbiased_eval_2}
\end{equation}
which is equivalently is the $j^{th}$ component of
Eq~(\ref{eq:richardson_split}):
\begin{equation}
  E\{X_{j}\} = b_j + \sum_{i=1}^N x_{i} h_{ji}\,
  \label{eq:unbiased_eval_2}
\end{equation}
and is therefore and unbiased estimate. Compared to the collision
estimator, the expected value estimator provides additional
information at every step of the random walk, yielding potentially
better statistics with the same amount of transport
work. Conveniently, even if no Monte Carlo histories are computed, the
expected value estimator still deterministically computes the first
term of the Neumann Series, $\ve{H}^0\ve{b}$, whereas the collision
estimator will provide no information.

\subsubsection{Expected Value Estimator Variance}
\label{subsubsec:expected_value_estimator_variance}
Following the collision estimator variance, the expected value
estimator variance is given as:
\begin{multline}
  \sigma_j^2 = \sum_{\nu} P_{\nu} b_j^2 + 2 \sum_{\nu} P_{\nu} b_j
  \sum_{m=0}^k W_{m} h_{j,i_m} +\\ \sum_{\nu} P_{\nu} \sum_{m=0}^k
  W_{m}^2 h_{j,i_m}^2 + 2 \sum_{\nu} P_{\nu} \sum_{\substack{ l=0
      \\ m<l}}^k W_m W_l h_{j,i_m} h_{j,i_l} - x_j^2\:.
  \label{eq:expected_value_variance_1}
\end{multline}
As the delta functions are no longer present, the final summation in
Eq~(\ref{eq:expected_value_variance_1}) contains contributions for all
valid state combinations in the same row of the iteration matrix and
therefore the variance of each state in the solution tally is coupled
to a group of other states as defined by the sparsity pattern of the
iteration matrix. This coupling of variances is expected due to the
deterministic averaging used to generate the expected value estimator.

\subsection{Adjoint Method: Evolution of a Solution}
\label{subsec:adjoint_evolution}
As a means of visually demonstrating the adjoint Monte Carlo method,
again consider the 2-dimensional thermal diffusion problem with
sources on the left and right hand sides of the domain and a smaller
uniform source as shown in Figure~\ref{fig:heat_setup}. Using the
adjoint method with the collision estimator, the number of histories
sampled from the source was increased from 10 to 10,000,000 in order
to show its effects on the solution and the statistical nature of the
method. Figure~\ref{fig:adjoint_evolution} gives these results.
\begin{figure}[t!]
  \begin{center}
    \includegraphics[width=6in]{chapters/mc_background/adjoint_evolution.png}
  \end{center}
  \caption{\textbf{Adjoint Monte Carlo solution to the heat equation
      with varying numbers of histories.} \textit{Top left: 10
      histories per state. Top right: 1,000 histories per
      state. Bottom left: 100,000 histories per state. Bottom right:
      10,000,000 histories per state.}}
  \label{fig:adjoint_evolution}
\end{figure}
As the number of histories used per state is increased, the
statistical variance of the solutions is decreased as more tally
contributions are made. At 10,000,000 histories per state, enough
information has been tallied to generate a reasonable estimate for the
structure of the solution. The visual difference between
Figures~\ref{fig:direct_evolution} and \ref{fig:adjoint_evolution} is
precisely that determined by their mathematics. As the adjoint
solution evolves with the addition of histories, more histories
emanate from the boundary and smaller uniform source with more
penetrating from the boundary into the domain and making contributions
to the tallies in those states.

%%---------------------------------------------------------------------------%%
\section{Sequential Monte Carlo}
\label{sec:sequential_mc}
The direct and adjoint Neumann-Ulam methods described are limited by a
convergence rate of $1/\sqrt{N}$ by the Central Limit Theorem where
$N$ is the number of random walk permutations. In 1962, Halton
presented a residual Monte Carlo method that moves towards exponential
convergence rates \citep{halton_sequential_1962} and further refined
his work some years later \citep{halton_sequential_1994}. Applications
of his work by the transport community have confirmed convergence
rates on the order of of $e^{-N}$ \citep{evans_residual_2003}. In
much the same way as projection methods, Halton's method, sequential
Monte Carlo, utilizes the adjoint Monte Carlo solver as a means of
directly reducing the elements residual vector. He proposed the
following iterative scheme as a solution to
Eq~(\ref{eq:linear_problem})\:
\begin{subequations}
  \begin{gather}
    \ve{r}^k = \ve{b} - \ve{A}\ve{x}^k\:,\\  
    \ve{A}\boldsymbol{\delta}^{k} = \ve{r}^{k}\:,\\
    \ve{x}^{k+1} = \ve{x}^k + \boldsymbol{\delta}^{k}\:,
  \end{gather}
  \label{eq:sequential_monte_carlo}
\end{subequations}
where the correction $\boldsymbol{\delta}^k$ is computed by the
adjoint Monte Carlo method at each iteration. The merits of Halton's
approach are immediately visible in that we have now broken the
binding of the convergence rate to the Central Limit Theorem. Here,
the Monte Carlo solver is used to produce a correction from the
residual, analogous to using the residual to extract a correction from
the search subspace in a projection method. By doing this, the Monte
Carlo error is bound in the correction used to update the solution and
therefore does not explicitly manifest itself in the overall
convergence of the solution. The downside of such a method is that if
the solution guess is poor, then many iterations are required in order
to reach exponential converge as the Monte Carlo error (and therefore
the Central Limit Theorem) does dominate in this situation.

%%---------------------------------------------------------------------------%%
\section{Monte Carlo Synthetic Acceleration}
\label{sec:mcsa}
Using the ideas of Halton, Evans and Mosher recently developed a Monte
Carlo solution method that was not prohibited severely by the quality
of the initial guess for the system \citep{evans_monte_2009} and later
applied it more rigorously as a solution mechanism for the radiation
diffusion equation \citep{evans_monte_2012}. With their new methods,
they achieved identical numerical results as conventional Krylov
solvers well as comparable performance in both number of iterations
and CPU time. Their approach was instead to use residual Monte Carlo
as a synthetic acceleration for a stationary method. To derive this
method, we begin by splitting the operator in
Eq~(\ref{eq:linear_problem})
\begin{equation}
  \ve{x} = (\ve{I} - \ve{A})\ve{x} + \ve{b}\:.
  \label{eq:linear_split}
\end{equation}
With this we can then define the stationary method
\textit{Richardson's iteration} as:
\begin{equation}
  \ve{x}^{k+1} = (\ve{I} - \ve{A})\ve{x}^k + \ve{b}\:,
  \label{eq:richardsons_iteration}
\end{equation}
which will converge if $\rho(\ve{I} - \ve{A}) < 1$. We then define the
solution error at the $k^{th}$ iterate relative to the true solution:
\begin{equation}
  \delta \ve{x}^k = \ve{x} - \ve{x}^k\:.
  \label{eq:mcsa_error}
\end{equation}
Subtracting Eq~(\ref{eq:richardsons_iteration}) from
Eq~(\ref{eq:linear_split}) we get:
\begin{equation}
  \delta \ve{x}^{k+1} = (\ve{I} - \ve{A})\delta \ve{x}^k\:.
  \label{eq:mcsa_setup_1}
\end{equation}
Subtracting from this $(\ve{I} - \ve{A})\delta \ve{x}^{k+1}$ yields:
\begin{equation}
  \begin{split}
    \ve{A}\delta \ve{x}^{k+1} &= (\ve{I} -
    \ve{A})(\ve{x}^{k+1}-\ve{x}^{k}) \\ &= \ve{r}^{k+1}\:.
    \label{eq:mcsa_setup_2}
  \end{split}
\end{equation}
Using this, we define the following scheme that will converge in one
iteration if $\ve{A}$ is inverted exactly:
\begin{subequations}
  \begin{gather}
    \ve{x}^{k+1} = (\ve{I} - \ve{A})\ve{x}^k + \ve{b}\:,\\
    \ve{A} \delta \ve{x}^{k+1} = \ve{r}^{k+1}\:,\\
    \ve{x} = \ve{x}^{k+1} + \delta \ve{x}^{k+1}\:.
  \end{gather}
  \label{eq:mcsa_setup_3}
\end{subequations}
However, $\ve{A}$ is only approximately inverted by our numerical
methods and therefore we instead pose an iterative scheme in which the
Monte Carlo solvers are used to invert the operator. The
\textit{Fixed-Point Monte Carlo Synthetic-Acceleration} (MCSA) method
is defined as:
\begin{subequations}
  \begin{gather}
    \ve{x}^{k+1/2} = \ve{x}^k + \ve{r}^k\:,\\
    \ve{r}^{k+1/2} = \ve{b} - \ve{A}\ve{x}^{k+1/2}\:,\\
    \ve{A}\delta\ve{x}^{k+1/2} = \ve{r}^{k+1/2}\:,\\
    \ve{x}^{k+1} = \ve{x}^{k+1/2} + \delta \ve{x}^{k+1/2}\:,\\
    \ve{r}^{k+1} = \ve{b} - \ve{A}\ve{x}^{k+1}\:,
  \end{gather}
  \label{eq:mcsa}
\end{subequations}
where the adjoint Monte Carlo method is used to generate the solution
correction from the residual and Richardson's iteration in the first
step has been rewritten as a residual correction. Using Monte Carlo in
this way achieves the same effect as Halton's method, decoupling its
convergence rate from the overall convergence rate of the
method. Here, the approximate Monte Carlo solution is not driven to a
particular convergence as it merely supplies a correction for the
initial guess generated by Richardson's iteration. Rather, only a set
number of histories are required using the adjoint method to generate
the correction. In addition, the fact that the scheme in
Eq~(\ref{eq:mcsa_setup_3}) will converge in one iteration if $\ve{A}$
is inverted exactly means that as more and more stochastic histories
are used to compute the correction and the error is reduced towards
zero, the number of iterations required for MCSA to converge should
decrease accordingly, thus accelerating the solution.

In addition to the Monte Carlo solver parameters dictating the number
of histories and weight cutoff, the outer MCSA iterations also have
the following stopping criteria:
\begin{equation}
  ||\ve{r}||_\infty < \epsilon \ ||\ve{b}||_\infty\:,
  \label{eq:mcsa_stopping_criteria}
\end{equation}
where $\epsilon$ is a user-defined parameter. As with any iterative
method, other stopping criteria using other vector norms could be
computed, however, for this work we will only use
Eq~(\ref{eq:mcsa_stopping_criteria}). We therefore have 3 parameters
to tune in an MCSA implementation: the number of Monte Carlo histories
computed in the adjoint solve during each MCSA iteration, the weight
cutoff for those histories, and the total MCSA convergence tolerance
as specified by $\epsilon$.

\subsubsection{Alternative Fixed Point Iterations}
\label{subsubsec:alternative_fixed_point}


\subsection{Preconditioning MCSA}
\label{subsec:stochastic_preconditioning}
In most cases, at least a minimal amount of \textit{preconditioning}
of the linear system will be required in order to use the class of
stochastic methods described. Although these methods have no symmetry
requirements for convergence, they do require that the spectral radius
of the iteration matrix be less than one. Preconditioning serves as a
means of achieving this by altering the eigenvalue spectrum of the
iteration matrix.

\subsubsection{Basic Preconditioning}
\label{subsubsec:basic_mcsa_preconditioning}
As an example, to achieve a spectral radius of less than one for
diagonally dominant matrices point Jacobi preconditioning can be used
such that the preconditioning matrix $\ve{M}$ is:
\begin{equation}
  \ve{M} = diag(\ve{A})\:,
  \label{eq:jacobi_preconditioner}
\end{equation}
which may be trivially inverted. With the application of this
preconditioner we are instead solving the following scaled linear
system:
\begin{equation}
  \ve{M}^{-1}\ve{A}\ve{x} = \ve{M}^{-1}\ve{b}\:.
  \label{eq:jacobi_precond_linear_problem}
\end{equation}
Next, we can apply MCSA to solve
Eq~(\ref{eq:jacobi_precond_linear_problem}): 
\begin{subequations}
  \begin{gather}
    \ve{x}^{k+1/2} = \ve{x}^k +
    \ve{M}^{-1}\ve{r}^k\:,\\ \ve{r}^{k+1/2} =
    \ve{b}-\ve{A}\ve{x}^{k+1/2}\:,\\ \ve{M}^{-1}\ve{A}\delta\ve{x}^{k+1/2}
    = \ve{M}^{-1}\ve{r}^{k+1/2}\:,\\ \ve{x}^{k+1} = \ve{x}^{k+1/2} +
    \delta \ve{x}^{k+1/2}\:,\\
    \ve{r}^{k+1} = \ve{b} - \ve{A}\ve{x}^{k+1}\:,
    \label{eq:jacobi_preconditioned_mcsa}
  \end{gather}
\end{subequations}
where the adjoint Monte Carlo solve now has a preconditioned operator
from which to build weights and probabilities for transport and a
preconditioned source vector to sample. 

Choosing point Jacobi preconditioning with MCSA is advantageous for
several reasons. First, $\rho(\ve{I} - \ve{M}^{-1}\ve{A}) < 1$ is true
for all $\ve{A}$ that is diagonally dominant and is easy to formulate
because the inversion of $\ve{M}$ is trivial. Second, because the
adjoint Monte Carlo method used within MCSA to compute the correction
operates on a linear problem with the preconditioned operator, then
$\ve{H}$ in the adjoint solver will have a zero term in each of its
diagonal elements, thereby eliminating all in-state transitions during
the random walk sequence. Because of this, point Jacobi
preconditioning should be considered for many classes of problems,
regardless of any other preconditioning that is applied to the
system.

\subsubsection{General Preconditioning Strategies}
\label{subsubsec:general_mcsa_preconditioning}
It is possible to use general left, right, and left/right
preconditioning with MCSA by carefully considering the underlying
Monte Carlo problem that will be solved with the Neumann-Ulam
method. We consider here the general left/right preconditioned method
as the left or right preconditioned methods can be inferred from its
formulation. We consider a left preconditioner $\ve{M_L}$ and a right
preconditioner $\ve{M_R}$. The left/right preconditioned linear
problem is then:
\begin{equation}
  \ve{M}_L^{-1}\ve{A}\ve{M}_R^{-1}\ve{M}_R\ve{x} = \ve{M}_L^{-1}\ve{b}\:.
  \label{eq:left_right_linear_problem}
\end{equation}
To handle the right preconditioning, the system is written with a
substitution of variables:
\begin{equation}
  \ve{M}_L^{-1}\ve{A}\ve{M}_R^{-1}\ve{u} = \ve{M}_L^{-1}\ve{b}\:,
  \label{eq:left_right_subs_problem}
\end{equation}
with
\begin{equation}
  \ve{x} = \ve{M}_R^{-1}\ve{u}\:.
  \label{eq:left_right_recover}
\end{equation}
To apply such a method to MCSA, we solve for the substituted variable
$\ve{u}$ during the iteration sequence:
\begin{subequations}
  \begin{gather}
    \ve{u}^{k+1/2} = \ve{u}^k + \ve{r}^k\:,\\
    \ve{r}^{k+1/2} = \ve{M}_L^{-1}(\ve{b}-\ve{A}\ve{M}_R^{-1}\ve{u}^{k+1/2})\:,\\ 
    \ve{M}_L^{-1}\ve{A}\ve{M}_R^{-1}\delta\ve{u}^{k+1/2} = \ve{r}^{k+1/2}\:,\\ 
    \ve{u}^{k+1} = \ve{u}^{k+1/2} + \delta \ve{u}^{k+1/2}\:,\\
    \ve{r}^{k+1} = \ve{M}_L^{-1}(\ve{b}-\ve{A}\ve{M}_R^{-1}\ve{u}^{k+1})\:,
  \end{gather}
  \label{eq:left_right_mcsa}
\end{subequations}
and then recover the original solution vector with
Eq~(\ref{eq:left_right_recover}). For the Monte Carlo problem, we
isolate the generation of the correction:
\begin{equation}
  \ve{M}_L^{-1}\ve{A}\ve{M}_R^{-1}\delta\ve{u}^{k+1/2} = \ve{r}^{k+1/2}\:,
  \label{eq:left_right_correction}
\end{equation}
and note that the precondtioned residual of the substituted variable
is now serving as the source and the new iteration matrix is:
\begin{equation}
  \ve{H} = \ve{I} - \ve{M}_L^{-1}\ve{A}\ve{M}_R^{-1}\:.
  \label{eq:left_right_iteration_matrix}
\end{equation}
As we require $(i,j)$ element-wise access to the iteration matrix in
order to construct probabilities and weights for the Monte Carlo
procedure from the Neumann-Ulam decomposition, the \textit{composite
  operator}, $\ve{M}_L^{-1}\ve{A}\ve{M}_R^{-1}$, must be formed via
matrix-matrix multiplication. 

Several possible shortcomings of this preconditioning approach are
readily observed. First, the matrix-matrix multiplication operation
for sparse, parallel distributed matrices is significantly more
expensive than a matrix-vector multiplication operation. Second, each
preconditioner must be explicitly inverted, an operation in itself
that may be expensive and which prohibits the use of any
preconditioners which provide no mechanism to extract their
inverse. Third, for many modern preconditioning methods, this
inversion may yield dense matrices, destroying sparsity and further
impeding the performance of a matrix-matrix multiplication
operation. It is also interesting to note that the Monte Carlo problem
in the general left/right preconditioned scheme given by
Eq~(\ref{eq:left_right_correction}) is not fully left/right
preconditioned (meaning that we do not recover $\ve{x}$), but instead
part of a sequence for finding the substituted variable $\ve{u}$. We
do, however, gain the benefits of this general preconditioning by
building the iteration matrix in
Eq~(\ref{eq:left_right_iteration_matrix}) from the fully
preconditioned linear operator. In addition, for MCSA to apply to
increasingly difficult problems, more advanced preconditioning
techniques that require the generation of the composite operator may
be necessary for convergence.

%%---------------------------------------------------------------------------%%
\section{Monte Carlo Method Selection}
\label{sec:mc_method_selection}p
The MCSA method defined in Eq.~(\ref{eq:mcsa}) uses the adjoint method
to estimate the error in a residual Monte Carlo solve instead of the
direct method outlined in \S\ref{sec:direct_mc}. To demonstrate the
effectiveness of the adjoint method over the direct method within the
context of MCSA, we choose the two-dimensional time-dependent Poisson
equation as a simple model problem:
\begin{equation}
  \frac{\partial \ve{u}}{\partial t} = \nabla^2 \ve{u}\:.
  \label{eq:poisson_equation}
\end{equation}
For all comparisons, a single time step is computed with backwards Euler time
integration. The Laplacian is differenced on a square Cartesian grid with a
second-order five-point stencil,
\begin{equation}
  \nabla^2_5 = \frac{1}{\Delta^2}[u_{i-1,j} + u_{i+1,j} + u_{i,j-1} +
    u_{i,j+1} - 4 u_{i,j}]\:,
  \label{eq:five_point_stencil}
\end{equation}
and a fourth-order nine-point stencil,
\begin{multline}
  \nabla^2_9 = \frac{1}{6\Delta^2}[4 u_{i-1,j} + 4 u_{i+1,j} + 4
    u_{i,j-1} + 4 u_{i,j+1} + u_{i-1,j-1}\\ + u_{i-1,j+1} +
    u_{i+1,j-1} + u_{i+1,j+1} - 20 u_{i,j}]\:,
  \label{eq:nine_point_stencil}
\end{multline}
both assuming a grid size of $\Delta$ in both the $i$ and $j$ directions. For
a single time step solution, we then have the following sparse linear system
to be solved with the MCSA method:
\begin{equation}
  \ve{A} \ve{u}^{n+1} = \ve{u}^n\:.
  \label{eq:poisson_eq_lin_sys}
\end{equation}
Both the stencils will be used to vary the size and density of the sparse
linear system in Eq.~(\ref{eq:poisson_eq_lin_sys}).

A timing and convergence study is used to demonstrate the
effectiveness of the adjoint method with the collision estimator as
compared to the direct method. To assess both the CPU time and number
of iterations required to converge to a solution, a problem of
constant $\Delta$ was used with varying values of the number of mesh
elements, fixing the spectral radius of the system at a constant value
for each variation. Both the five-point and nine-point stencils were
used with both the direct and adjoint solvers. For each case, $N
\times N$ total random walk permutations were computed per MCSA
iteration where $N \times N$ is the number of discrete grid points in
the system. Solver parameters were set to a weight cutoff of
\sn{1}{-4} for the stochastic linear solver and a convergence
tolerance of \sn{1}{-8} for the MCSA iterative solver.
Figure~\ref{fig:poisson_cpu_time} gives the CPU time needed for each
case to converge in seconds and Figure~\ref{fig:poisson_iterations}
gives the number of iterations needed for each case to converge to the
specified tolerance as a function of the problem size. All
computations presented in this section and
\S\ref{subsec:sequential_comparison} were completed on a 3.0 GHz Intel
Core 2 Quad Q9650 CPU machine with 16 GB 1067 MHz DDR3 memory.
\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/dir_adj_cpu.pdf}
  \caption{\textbf{CPU Time (s) to converge vs. Problem Size ($N$ for
      an $N \times N$ square mesh).} \textit{Both the adjoint and
      direct solvers are used with the five point and nine point
      stencils. A CPU time speedup is noted with the adjoint method
      due to the higher density of random walk events in regions with
      a large residual.}}
  \label{fig:poisson_cpu_time}
\end{figure}

\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/dir_adj_iterations.pdf}
  \caption{\textbf{Iterations to converge vs. Problem Size ($N$ for an
      $N \times N$ square mesh).} \textit{Both the adjoint and direct
      solvers are used with the five-point and nine-point stencils.}}
  \label{fig:poisson_iterations}
\end{figure}

We see clearly in Figure~\ref{fig:poisson_cpu_time} that the using the
adjoint solver with MCSA results in a speedup over the direct solver
while the number of iterations required to converge is also reduced as
shown in Figure~\ref{fig:poisson_iterations}. We expect this for several
reasons. First, with an equivalent number of histories specified for
both solvers per MCSA iteration and a system of size $N \times N$, the
direct solver will compute a single random walk for each state in the
system per iteration to acquire a solution in that state, regardless
of the size of the residual in that state. This is necessary in the
direct method to ensure a contribution from each state as the random
walk sequence will only contribute to the starting state. For the
adjoint method, a total of $N \times N$ random walk events will have
their starting state determined by sampling the residual
vector. Because the random walk sequence contributes to the state in
which it currently resides, sampling the residual vector as the Monte
Carlo source gives a higher density of random walk events in regions
with a high residual, thus giving a more accurate correction in that
region due to reduced statistical error. From an iteration
perspective, Figure~\ref{fig:poisson_iterations} shows that using the
direct method yields a roughly unchanging number of iterations
required to converge as the problem size increases. Again, if we
desire a correction value for all states in the problem, then we must
start a random walk in each state in the system which does not reduce
the number of iterations need as the problem size grows. Conversely,
as the problem size grows in the adjoint method, the additional
stochastic histories that will be computed are concentrated in regions
with a large residual, further reducing the stochastic error in the
correction in those regions and subsequently reducing the required
number of iterations to converge.

As an additional comparison, the convergence behavior of MCSA can be
analyzed using both the adjoint and direct solvers to detect any
performance benefits. To assess the convergence properties of MCSA
using each solver and stencil, the infinity norm of the residual
computed in Eq.~(\ref{eq:mcsa}) was collected at each iteration for a
fixed problem size of $N=500$. Figure~\ref{fig:poisson_convergence}
gives the results of these computations. First, it is worthy to note
on the semilog plot that we are indeed achieving the expected
exponential convergence from MCSA with both Monte Carlo
solvers. Second, we note that using the adjoint method with the same
number of stochastic histores per MCSA iteration gives a faster rate
of converge for the same reasons as above. We also note here that
fewer iterations are required for convergence when the 9-point stencil
is used to discretize the Laplacian operator (although at no gain in
speed as given by the results in
Figure~\ref{fig:poisson_cpu_time}). This is due to the fact that the
smaller discretization error directly corresponds to a more well
defined residual source generated by the Richardson extrapolation for
the Monte Carlo calculation. In addition, the better defined source is
transported through a domain described more accurately by the 9-point
stencil, thus yielding a more accuracte correction vector from the
Monte Carlo calculation.
\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/dir_adj_conv.pdf}
  \caption{\textbf{Infinity norm of the solution residual
      vs. iteration number for a problem of size $N=500$.}
    \textit{Both the adjoint and direct solvers are used with the five
      point and nine point stencils. A higher rate of convergence is
      observed for MCSA using the adjoint Monte Carlo solver as
      compared to the direct method when both solvers compute the same
      number of random walks per iteration.}}
  \label{fig:poisson_convergence}
\end{figure}

\clearpage

%%---------------------------------------------------------------------------%%
\section{MCSA Comparison to Sequential Monte Carlo}
\label{subsec:sequential_comparison}
To further motivate using Monte Carlo Synthetic Acceleration, we
compare its performance to Halton's Sequential Monte Carlo method on
which previous work in this area was based. For this comparison, we
use the same transient Poisson problem as described in the previous
section and choose only the 5-point stencil to discretize the
Laplacian operator as the previous results yielded little qualitative
difference between the discretizations. Both MCSA and Halton's method
are used with the adjoint Monte Carlo solver and the collision
estimator. In order to complete the same study as in the previous
section, the number of histories computed by the Monte Carlo solver at
each iteration had to be doubled to $2 \times N \times N$ in order to
ensure convergence in Sequential Monte Carlo Method. For the majority
of the problems in the previous section, the Sequential method used
with $N \times N$ histories would not
converge. Figure~\ref{fig:seq_cpu_time} gives the CPU time results for
this comparison as a function of problem size while
Figure~\ref{fig:seq_iterations} gives the number of iterations to
converge as a function of problem size with a convergence tolerance of
\sn{1}{-8}. In both cases, using the Monte Carlo solver as a synthetic
acceleration rather than in a pure residual Monte Carlo scheme
resulted in a reduction in both CPU time and iterations required to
converge. The additional Richardson extrapolation between each Monte
Carlo solve in the MCSA method gives a better converged residual
source to use with the Monte Carlo calculation while the Sequential
method requires more iterations to achieve the same level of
convergence in the residual.

\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/seq_cpu.pdf}
  \caption{\textbf{CPU Time (s) to converge vs. Problem Size ($N$ for
      an $N \times N$ square mesh).} \textit{Both the Sequential Monte
      Carlo and MCSA solvers are used with the five point stencils and
      the adjoint Monte Carlo solver. The number of random walks was
      twice the number of discrete states in the system in order to
      ensure convergence in the Sequential Monte Carlo method.}}
  \label{fig:seq_cpu_time}
\end{figure}

\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/seq_iterations.pdf}
  \caption{\textbf{Iterations to converge vs. Problem Size ($N$ for an
      $N \times N$ square mesh).} \textit{Both the Sequential Monte
      Carlo and MCSA solvers are used with the five point stencils and
      the adjoint Monte Carlo solver.}}
  \label{fig:seq_iterations}
\end{figure}

The benefits of using a synthetic acceleration scheme are also noted
when the infinity norm of the residual computed at each iteration for
both methods was collected at each iteration for a fixed problem sizes
of $N=100$ and $N=500$ as shown in figures Figure~\ref{fig:seq_100}
and \ref{fig:seq_500} respectively. In both cases, the Sequential
method is subject to two regimes of exponential convergence with high
frequency error modes removed in the first regime leaving lower
frequency and slower converging error modes in the second. Using MCSA
we a see a single rate of exponential convergence observed to be much
higher than that computed by Halton's method due to the fact that the
extra Richardson iteration is providing a smoothing effect to
alleviate the error mode variations. Even with the doubling of the
number of stochastic histories computed per time step in order to
ensure convergence for the Sequential method, we still see robustness
issues with a non-monotonically decreasing residual observed for the
$N=100$ case. In both cases the MCSA solver is observed to be robust
with a monotonically decreasing residual.

\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/seq_conv_100.pdf}
  \caption{\textbf{Infinity norm of the solution residual
      vs. iteration number for a problem of size $N=100$.}
    \textit{Both the Sequential Monte Carlo and MCSA solvers are used
      with the five point stencils and the adjoint Monte Carlo
      solver.}}
  \label{fig:seq_100}
\end{figure}

\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/seq_conv_500.pdf}
  \caption{\textbf{Infinity norm of the solution residual
      vs. iteration number for a problem of size $N=500$.}
    \textit{Both the Sequential Monte Carlo and MCSA solvers are used
      with the five point stencils and the adjoint Monte Carlo
      solver.}}
  \label{fig:seq_500}
\end{figure}

\clearpage

%%---------------------------------------------------------------------------%%
\section{Monte Carlo Parameter and Estimator Analysis}
\label{sec:parameter_estimator_analysis}
With the adjoint method shown to be more effective than the direct
method and MCSA to have better iterative and timing performance than
sequential Monte Carlo, we now aim to study the effects of the adjoint
Monte Carlo parameters, weight cutoff and number of histories, on MCSA
performance with both the collision and expected value
estimators. With the same Poisson problem, we will use a $200 \times
200$ grid and a convergence tolerance of \sn{1}{-8} for all
calculations. To study the effects of the number of Monte Carlo
histories per MCSA iteration, the weight cutoff was fixed at
\sn{1}{-4} while the number of histories per iteration was varied from
6,000 to 100,000. It was observed that MCSA would not converge for
this problem using the collision estimator with less than 6,000
histories while the expected value estimator permitted convergence
with only 2,000 histories. Figure~\ref{fig:estimator_nh_iters} gives
the number of iterations required to converge for both estimators as a
function of the number of histories per iteration. For smaller numbers
of histories, the performance of the expected value estimator is
significantly better than the collision estimator. This result is
valuable in that less transport is required to achieve the same MCSA
iterative performance with the expected value estimator, important for
situations where transport is expensive (i.e. in domain decomposed
calculations). Interstingly, as the number of histories per iteration
are increased, the iterative performance with the collision estimator
approaches that of the expected value estimator. However, given the
performance of the expected value estimator at a fractional number of
histories, one should strongly consider its use over using the collision
estimator with more histories. The CPU time required to converge is
presented in Figure~\ref{fig:estimator_nh_time} and reflects the
results of the iterative performance. In general, using the collision
estimator is slightly slower overall, but the time per iteration is
faster due to the fact that the estimator does not have to cycle
through multiple states during the tally procedure.

\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/estimator_nh_iters.pdf}
  \caption{\textbf{Iterations (s) to converge vs. Monte Carlo
      histories per MCSA iteration for a $200 \times 200$ square mesh
      and a weight cutoff of \sn{1}{-4}.} \textit{For low numbers of
      histories, the expected value estimator performance is
      significantly better than the collision estimator. At higher
      numbers of histories, the estimators become roughly
      equivalent.}}
  \label{fig:estimator_nh_iters}
\end{figure}

\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/estimator_nh_time.pdf}
  \caption{\textbf{CPU Time (s) to converge vs. Monte Carlo histories
      per MCSA iteration for a $200 \times 200$ square mesh and a
      weight cutoff of \sn{1}{-4}.} \textit{For low numbers of
      histories, the expected value estimator performance is better
      than the collision estimator due to a lower iteration count
      while the actual compute time per iteration is higher.}}
  \label{fig:estimator_nh_time}
\end{figure}

For the weight cutoff study, the number of histories per iteration was
fixed at 40,000 and the weight cutoff varied from \sn{5}{-1} down to
\sn{1}{-10}. Surprisingly, the number of iterations to converge given
by Figure~\ref{fig:estimator_wc_iters} is effectively invariant to the
weight cutoff, only seeing detrimental effects on the number of
iterations at a very large weight cutoff. This suggests that a fairly
large weight cutoff can be used in practice with both estimators and
that the preliminary components of the random walk are more important
to MCSA convergence than those that occur later and with lower weight
contributions. To further motivate using a larger weight cutoff,
Figure~\ref{fig:estimator_wc_time} gives the CPU time need to converge
as a function of weight cutoff. As expected, lowering the weight
cutoff lengthens the random walk lengths and increases CPU time at no
gain of iterative performance. In general, these results suggest using
the expected value estimator over the collision estimator with MCSA as
well as using a larger weight cutoff.

\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/estimator_wc_iters.pdf}
  \caption{\textbf{Iterations (s) to converge vs. history weight
      cutoff for a $200 \times 200$ square mesh and 40,000 histories.}
    \textit{For low numbers of histories, the expected value estimator
      performance is significantly better than the collision
      estimator. At higher numbers of histories, the estimators become
      roughly equivalent.}}
  \label{fig:estimator_wc_iters}
\end{figure}

\begin{figure}[t!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/estimator_wc_time.pdf}
  \caption{\textbf{CPU Time (s) to converge vs. history weight cutoff
      for a $200 \times 200$ square mesh and 40,000 histories.}
    \textit{For low numbers of histories, the expected value estimator
      performance is better than the collision estimator due to a
      lower iteration count while the actual compute time per
      iteration is higher.}}
  \label{fig:estimator_wc_time}
\end{figure}

\clearpage

%%---------------------------------------------------------------------------%%
\section{Variance Reduction Techniques}
\label{sec:variance_reduction}
Variance reduction is a mechanism by which the probabilities and
weights of the Monte Carlo problem are modified to improve the
performance of a given estimator. In many cases, such modifications
will introduce bias into the system. However, using Monte Carlo within
an MCSA iterative scheme provides a potential buffer for the solution
from this bias as the correction generated by the Monte Carlo solve
will contain large statistical error even without variance
reduction. For this work, any method that alters the weights and
probabilities of the Monte Carlo method with the aim of improving
either iterative performance or time to convergence will be defined as
a variance reduction scheme.

\subsection{Artificial Absorption}
\label{subsec:artificial_absorption}
The random walk sequences generated by the adjoint Neumann Ulam
decomposition in Eqs~(\ref{eq:adjoint_probability}) and
(\ref{eq:adjoint_weight}) will continue on indefinitely without the
implementation of a weight cutoff procedure (which in itself is
effectively a form of biased variance reduction). This is due to the
fact that all states to which a stochastic history may move in a given
transition exist within the system and have a non-zero weight. A
preliminary variance reduction scheme is to introduce
\textit{artifical absorption} into the system such that at each
transition event, a stochastic history will now have some finite
probability of being terminated through absorption as well as
transition to other states in the system. This probability, $p_{abs}$,
modifies the probabilities and weights in the adjoint random walk
sequence as:
\begin{equation}
  p_{ij} = \frac{|h_{ji}|}{\sum_j|h_{ji}|}(1-p_{abs})\:,
  \label{eq:absorption_probabilities}
\end{equation}
and
\begin{equation}
  w_{ij} = \frac{sign(h_{ji})\sum_j|h_{ji}|}{(1-p_{abs})}\:.
  \label{eq:absorption_weights}
\end{equation}
At each transition step, a history at state $i$ will then sample the
probability distribution function generated by
Eq~(\ref{eq:absorption_probabilities}) with an additional absorption
state added to the distribution. If the sampling procedure results in
a transition to the absorption state, the history is immediately
terminated. The advantages of this for residual Monte Carlo are that
increasing the absorption probability decreases the length of each
random walk (resulting in speedup), while the random walk has a higher
weight contribution at every step. This higher weight means that each
history is depositing more information near its birth site which will
on average be located where the system residual is the largest. An
additional advantage of this formulation is that the full Neumann Ulam
decomposition is maintained.

To observe the effects of this variance reduction on MCSA solutions,
the transient Poisson problem was again solved with the adjoint
method, this time with varying values of artificial absorption. A $200
\times 200$ grid was used with 40,000 histories at every iteration
with the expected value estimator converged to a tolerance of
\sn{1}{-8}. To reduce the effect of the weight cutoff on this study,
the weight cutoff was set to \sn{1}{-12} such that it is signicantly
more likely that a history will be terminated by absorption rather
than weight cutoff. Figure~\ref{fig:absorption_iters} gives the number
of iterations to converge as a function of the artificial absorption
probability. Up to a probability of roughly 0.5, the iterative
performance is not significanltly affected with the information lost
due to shortened random walks causing a small increase in the number
of iterations. At a probability of 0.6, the number of iterations
required grows rapidly as the bias creates an MCSA correction that
pushes the solution in the wrong direction. Convergence was observed
to be lost at probabilities of 0.7 and higher. The random walk length
has a strong effect on CPU time as
well. Figure~\ref{fig:absorption_time} gives the CPU time in seconds
required to converge as a function of artificial absorption
probability. Initially, small absorption probabilities not only
maintain iterative performance, but also drastically reduced the time
required to converge as absorption was more frequent than even a large
weight cutoff but the weights themselves were not significantly
modified. As the number of iterations grow rapidly, so does the time
required to converge to a solution. Based on these results, using a
small amount of artificial absorption should provide some CPU speedup
while maintaining iterative performance. For the problem presented
here, an absorption probability of around 0.25 may be the best choice
as it minimizes CPU time.

\begin{figure}[p!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/absorption_iters.pdf}
  \caption{\textbf{Iterations (s) to converge vs. artificial
      absorption probability for a $200 \times 200$ square mesh and
      40,000 histories.}  \textit{The addition of absorption is
      detrimental to iterative performance due to both the shortening
      of the random walks as well as the modification of the
      transition weight.}}
  \label{fig:absorption_iters}
\end{figure}

\begin{figure}[p!]
  \centering
  \includegraphics[width=6in,clip]{chapters/mc_background/absorption_time.pdf}
  \caption{\textbf{CPU Time (s) to converge vs. artificial absorption
      probability for a $200 \times 200$ square mesh and 40,000
      histories.}  \textit{The reduced random walk length speeds up
      the calculation with a fixed number of histories. Too much
      artificial absorption increases iterations rapidly giving an
      increasing CPU time.}}
  \label{fig:absorption_time}
\end{figure}
\clearpage

\subsection{Reduced Domain Approximation}
\label{subsec:reduced_domain_approximation}
For scalable parallel implementations and efficient Monte Carlo
transport, the domain is required to be sparse. We may find through
general preconditioning operations as outlined by the Monte Carlo
problem in Eq~(\ref{eq:left_right_correction}) that this sparsity is
lost. To alleviate this, we propose modifying the domain sampled by
the Monte Carlo method to generate the correction within MCSA by
removing terms in the iteration matrix through some predetermined
criteria in order to recover sparsity. As the Neumann-Ulam scheme is a
stochastic realization of multiple matrix-vector multiplies, the
criteria we choose should be based on maintaining those elements that
will make the largest contributions to the multiplication and
therefore recover as much of the original product as possible. For
each row in the preconditioned system, we can then apply the reduced
domain approximation to eliminate those elements that either fall
below a specified tolerance level, keep the $N$ largest elements in
each row, or both giving:
\begin{subequations}
  \begin{gather}
    \ve{x}^{k+1/2} = \ve{x}^k + \ve{r}^k\:,\\
    \ve{r}^{k+1/2} = \ve{b} - \ve{A}\ve{x}^{k+1/2}\:,\\
    \hat{\ve{A}}\delta\ve{x}^{k+1/2} = \ve{r}^{k+1/2}\:, 
    \label{eq:rda_correction}\\
    \ve{x}^{k+1} = \ve{x}^{k+1/2} + \delta \ve{x}^{k+1/2}\:,\\
    \ve{r}^{k+1} = \ve{b} - \ve{A}\ve{x}^{k+1}\:,
  \end{gather}
  \label{eq:rda_mcsa}
\end{subequations}
where $\hat{\ve{A}}$ in Eq~(\ref{eq:rda_correction}) means that the
reduced domain approximation has been applied to the iteration matrix
in the Monte Carlo method. If enough of the terms in the original
iteration matrix have been maintained, the character of the original
iteration matrix should be retained and continue to accelerate the
iterative scheme. The effects of the reduced domain approximation on
systems where it is required due to the explicit preconditioning
strategy chosen will be presented in Chapter~\ref{ch:spn_equations}.

\clearpage
