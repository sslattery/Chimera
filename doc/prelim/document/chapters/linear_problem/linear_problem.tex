\chapter{The Linear Problem}
\label{ch:linear_problem}
The discretization of partial differential equations (\textit{PDEs})
through common methods such as finite differences
\citep{leveque_finite_2007}, finite volumes
\citep{leveque_finite_2002}, and finite elements
\citep{zienkiewicz_finite_2005} ultimately generates sets of coupled
equations in the form of matrix problems.  In addition, these matrices
are typically sparse, meaning that the vast majority of their
constituent elements are zero. This sparsity is due to the fact that
the influence of a particular grid element only expands as far as a
few of its nearest neighbors depending on the order of discretization
used and therefore coupling among variables in a particular discrete
equation in the system leads to a few non-zero entries. Because of the
natural occurrence of sparse matrices in common numerical methods many
iterative techniques have been developed to solve such systems. We
discuss here conventional stationary and projection methods for
solving sparse systems to provide background and then give detail on a
reemerging stochastic class of methods. Details on the parallelization
of conventional methods are discussed and a novel proposal for the
parallelization of stochastic methods presented.\footnote{The contents
  of this chapter, particularly those sections relating to projection
  methods and matrix analysis, are heavily based on Saad's text
  \citep{saad_iterative_2003}.}

\section{Preliminaries}
\label{sec:linear_preliminaries}
We seek solutions of the general linear problem in the following form:
\begin{equation}
  \ve{A} \ve{x} = \ve{b}\:,
  \label{eq:linear_problem}
\end{equation}
where $\ve{A} \in \mathbb{C}^{N \times N}$ is a matrix operator such
that $\ve{A} : \mathbb{C}^{N} \rightarrow \mathbb{C}^{N}$, $\ve{x} \in
\mathbb{C}^N$ is the solution vector, and $\ve{b} \in \mathbb{C}^N$ is
the forcing term. The solutions to Eq~(\ref{eq:linear_problem}) will
be generated by inverting $\ve{A}$ either directly or indirectly:
\begin{equation}
  \ve{x} = \ve{A}^{-1} \ve{b}
  \label{eq:linear_problem_solution}\:.
\end{equation}
In addition we can define the residual:
\begin{equation}
  \ve{r} = \ve{b} - \ve{A}\ve{x}\:,
  \label{eq:linear_residual}
\end{equation}
such that an exact solution $\ve{x}$ has been found when
$\ve{r}=\ve{0}$.  From the statement in
Eq~(\ref{eq:linear_problem_solution}) we can already place a
restriction on $\ve{A}$ by requiring that it be \textit{nonsingular},
meaning that we can in fact compute $\ve{A}^{-1}$. In this work we
will focus our efforts on approximately inverting the operator through
various means.

In a discussion of methods for solving linear systems, several
mathematical tools are useful in characterizing the qualities of the
linear system. Among the most useful are the \textit{Eigenvalues} of
the matrix, $\sigma(\ve{A})$. We find these by solving the Eigenvalue
problem:
\begin{equation}
  \ve{A} \ve{x} = \lambda \ve{x},\ \lambda \in \sigma(\ve{A})\:.
  \label{eq:eigenvalue_problem}
\end{equation}
By writing Eq~(\ref{eq:eigenvalue_problem}) in a different form,
\begin{equation}
  (\ve{A} - \lambda \ve{I})\ve{x} = 0 \:,
  \label{eq:eigenvalue_problem_2}
\end{equation}
and demanding that non-trivial solutions for $\ve{x}$ exist, it is
then required that $|\ve{A} - \lambda \ve{I}| = 0$. Expanding this
determinant yields a characteristic polynomial in terms of $\lambda$
with roots that form the set of Eigenvalues, $\sigma(\ve{A})$. Each
component of $\sigma(\ve{A})$ can then be used to solve
Eq~(\ref{eq:eigenvalue_problem_2}) for a particular permutation of
$\ve{x}$. The set of all permutations form the \textit{Eigenvectors}
of $\ve{A}$. A quantity of particular interest that is computatable
from the eigenvalues of a matrix $\ve{A}$ is the \textit{spectral
  radius}, $\rho(\ve{A})$, defined by Saad \citep{saad_iterative_2003}
as:
\begin{equation}
  \rho(\ve{A}) = \max_{\lambda \in \sigma(\ve{A})} |\lambda| \:.
  \label{eq:spectral_radius}
\end{equation}
In addition, for problems that have a large scale over which the
independent variables may exist (e.g. a problem with events on
timescales ranging from nanoseconds to hours), a good measure of this
range is supplied by the \textit{stiffness ratio}:
\begin{equation}
  Stiffness Ratio = \frac{\max_{\lambda \in \sigma(\ve{A})}
    |\lambda|}{\min_{\lambda \in \sigma(\ve{A})} |\lambda|}
\end{equation}
Those problems that have a wide range of scales in their independent
variables, which will then be reflected in the operator, will then
have a large stiffness ratio. We will define such problems with large
stiffness ratios as \textit{stiff}.

General to both matrices and vectors, \textit{norms} are a mechanism
for collapsing objects of many elements to a single value. Per
LeVeque's text \citep{leveque_finite_2007}, the q-norm of a vector is defined
as:
\begin{equation}
  ||\ve{v}||_q = \Bigg[ \sum_{i=1}^N |v_i|^q \Bigg]^{1/q},\ \ve{v} \in
  \mathbb{C}^N\:,\ q \in \mathbb{Z}^+
  \label{eq:q_norm}
\end{equation}
where ${v_i}$ is the $i^{th}$ component of the vector. Depending on
the value chosen for $q$, local or global qualities of the vector may
be obtained. For example, $q=2$ provides the root of a quadrature sum
of all elements in the vector giving a global measure of the vector
while $q=\infty$ gives the maximum value in the vector, a local
quantity that does not give information regarding the other elements
in the vector.

We can also compute the norm of a matrix by inferring from the norm of
the vector on which it is operating. Per LeVeque, we search for a
constant that is equivalent to $||\ve{A}||$:
\begin{equation}
  ||\ve{A}\ve{x}|| \leq C ||\ve{x}||\:,
  \label{eq:matrix_norm_inequality}
\end{equation}
where the minimum value of $C$ that satisfies
Eq~(\ref{eq:matrix_norm_inequality}) is equivalent to $||\ve{A}||$
and is valid $\forall \ve{x} \in \mathbb{C}^N$. The general
definition in Eq~(\ref{eq:matrix_norm_inequality}) can be expanded in
simple terms for common norms including the infinity norm:
\begin{equation}
  ||\ve{A}||_{\infty} = \max_{1 \leq i \leq N} \sum^N_{j=1}|a_{ij}|\:,
  \label{eq:matrix_infinity_norm}
\end{equation}
and the 2-norm:
\begin{equation}
p  ||\ve{A}||_{2} = \sqrt{\rho(\ve{A}^T\ve{A})}\:,
  \label{eq:matrix_2_norm}
\end{equation}
where $\rho$ is the spectral radius as defined in
Eq~(\ref{eq:spectral_radius}).

Knowing this, we can then define several useful properties of matrices
including the \textit{condition number}:
\begin{equation}
  \kappa(\ve{A}) = ||\ve{A}||\ ||\ve{A}^{-1}||\:,
  \label{eq:condition_number}
\end{equation}
which gives as a metric on assessing how close to singular the system
is. This is due to the fact $||\ve{A}^{-1}||$ is large near
singularities (and undefined for a singular matrix) and thus a large
condition number will be generated. We define such matrices as
\textit{ill-conditioned}. 

\section{Stationary Methods}
\label{sec:stationary_methods}
Stationary methods arise from splitting the operator in
Eq~(\ref{eq:linear_problem})
\begin{equation}
  \ve{A} = \ve{M} - \ve{N}\:,
  \label{eq:split_linear_operator}
\end{equation}
where the choice of $\ve{M}$ and $\ve{N}$ will be dictated by the
particular method chosen. Using this split definition of the operator
we can then write:
\begin{equation}
  \ve{M}\ve{x} + \ve{N}\ve{x} = \ve{b}\:.
  \label{eq:linear_split_equation1}
\end{equation}
By rearranging, we can generate a form more useful for analysis:
\begin{equation}
  \ve{x} = \ve{H}\ve{x} + \ve{c}\:,
  \label{eq:linear_split_equation2}
\end{equation}
where $\ve{H}=\ve{M}^{-1}\ve{N}$ is defined as the \textit{iteration
  matrix} and $\ve{c}=\ve{M}^{-1}\ve{b}$. With the solution vector on
both the left and right hand sides, an iterative method can then be
formed:
\begin{equation}
    \ve{x}^{k+1} = \ve{H}\ve{x}^k + \ve{c}\:,
  \label{eq:linear_iterative_method}
\end{equation}
with $k \in \mathbb{Z}^+$ defined as the \textit{iteration index}. In
general, we will define methods in the form of
Eq~(\ref{eq:linear_iterative_method}) as \textit{stationary
  methods}. Given this, we can then generate a few statements
regarding the convergence of such stationary methods. Defining
$\ve{e}^k = \ve{u}^k - \ve{u}$ as the solution error at the
$k^{th}$ iterate, we can subtract Eq~(\ref{eq:linear_split_equation2})
from Eq~(\ref{eq:linear_iterative_method}) to arrive at an error form
of the linear problem:
\begin{equation}
  \ve{e}^{k+1} = \ve{H}\ve{e}^k\:. 
  \label{eq:linear_iterative_error}
\end{equation}
Our error after $k$ iterations is then:
\begin{equation}
  \ve{e}^{k} = \ve{H}^k\ve{e}^0\:. 
  \label{eq:linear_k_iter_error}
\end{equation}
In other words, successive application of the iteration matrix is the
mechanism driving down the error in a stationary method. We can then
place restrictions on the iteration matrix by using the tools
developed in \S~(\ref{sec:linear_preliminaries}). By assuming $\ve{H}$
is diagonalizable\footnote{We may generalize this to
  non-diagonalizable matrices with the Jordan canonical form of
  $\ve{H}$.} \citep{saad_iterative_2003}, we then have:
\begin{equation}
  \ve{e}^{k} =
  \ve{R}\boldsymbol{\Lambda}^k\ve{R}^{-1}\ve{e}^0\:,
  \label{eq:linear_k_iter_error_diag}
\end{equation}
where $\boldsymbol{\Lambda}$ contains the Eigenvalues of $\ve{H}$ on
its diagonal and the columns of $\ve{R}$ contain the Eigenvectors of
$\ve{H}$. Computing the 2-norm of the above form then gives:
\begin{equation}
  ||\ve{e}^{k}||_2 \leq ||\boldsymbol{\Lambda}^k||_2\ 
  ||\ve{R}||_2\ ||\ve{R}^{-1}||_2\ ||\ve{e}^0||_2\:,
  \label{eq:linear_k_iter_norm1}
\end{equation}
which gives:
\begin{equation}
  ||\ve{e}^{k}||_2 \leq \rho(\ve{H})^k \kappa(\ve{R})
  ||\ve{e}^0||_2\:.
  \label{eq:linear_k_iter_norm2}
\end{equation}
For iteration matrices where the Eigenvectors are orthogonal,
$\kappa(\ve{R})=1$ and the error bound reduces to:
\begin{equation}
  ||\ve{e}^{k}||_2 \leq \rho(\ve{H})^k
  ||\ve{e}^0||_2\:.
  \label{eq:linear_k_iter_norm3}
\end{equation}
We can now resrtict $\ve{H}$ by asserting that $\rho(\ve{H}) < 1$
for a stationary method to converge such that $k$ applications of the
iteration matrix will not cause the error to grow in
Eq~(\ref{eq:linear_k_iter_norm3}). 

\section{Projection Methods}
\label{sec:projection_methods}
Among the most common iterative methods used in scientific computing
today for sparse systems are of a broad class known as
\textit{projection methods}. These methods not only provide access to
more powerful means of reaching a solution, but also a powerful means
of encapsulating the majority of common iterative methods including
the stationary methods just discussed in a common mathematical
framework. All projection methods are built around a core structure
where the solution to Eq~(\ref{eq:linear_problem}) is extracted from a
\textit{search subspace} $\mathcal{K}$ and bound by a
\textit{constraint subspace} $\mathcal{L}$ that will vary in
definition depending on the iterative method selected. We build the
approximate solution $\tilde{\ve{x}}$ by starting with an initial
guess $\ve{x}_0$ and extracting a correction $\boldsymbol{\delta}$
from $\mathcal{K}$ such that:
\begin{equation}
  \tilde{\ve{x}} = \ve{x}_0 +
  \boldsymbol{\delta},\ \boldsymbol{\delta} \in \mathcal{K}\:.
  \label{eq:linear_projection_step}
\end{equation}
We bound this correction by asserting that the new residual,
$\tilde{\ve{r}}$, be orthogonal to $\mathcal{L}$:
\begin{equation}
  \langle \tilde{\ve{r}},\ve{w} \rangle = 0,\ \forall \ve{w} \in
  \mathcal{L}\:.
  \label{eq:linear_projection_constraint}
\end{equation}

We can generate a more physical and geometric-based understanding of
these constraints by writing the new residual as $\tilde{\ve{r}} =
\ve{r}_0 - \ve{A}\boldsymbol{\delta}$ and again asserting the residual
must be orthogonal to $\mathcal{L}$. If $\tilde{\ve{r}}$ is to be
orthogonal to $\mathcal{L}$, then $\ve{A}\boldsymbol{\delta}$ must be
the projection of $\ve{r}_0$ onto the subspace $\mathcal{L}$ that
eliminates the components of the residual that exist in
$\mathcal{L}$. This situation is geometrically presented in
Figure~\ref{fig:linear_projection_constraint}.

\begin{figure}[htpb!]
  \begin{center}
    \scalebox{1.75}{
      \input{chapters/linear_problem/orthogonal_residual.pdftex_t} }
  \end{center}
  \caption{\textbf{Orthogonality constraint of the new residual with
      respect to $\mathcal{L}$.} \textit{By projecting $\ve{r}_0$ onto
      the constraint subspace, we minimize the new residual by
      removing those components.}}
  \label{fig:linear_projection_constraint}
\end{figure}

From Figure~\ref{fig:linear_projection_constraint} we then note that
the following geometric condition must hold:
\begin{equation}
  ||\tilde{\ve{r}}||_2 \leq ||\ve{r}_0||_2,\ \forall \ve{r}_0 \in
  \mathbb{C}^N\:,
  \label{eq:linear_min_res}
\end{equation}
meaning that the residual of the system will always be
\textit{minimized} with respect to the constraints.

Given this minimization condition for the residual, we can form the
outline of an iterative projection method. Consider a matrix $\ve{V}$
to form a basis of $\mathcal{K}$ and a matrix $\ve{W}$ to form a basis
of $\mathcal{L}$. As $\boldsymbol{\delta} \in \mathcal{K}$ by
definition in Eq~(\ref{eq:linear_projection_step}), then
$\boldsymbol{\delta}$ can instead be rewritten as:
\begin{equation}
  \boldsymbol{\delta} = \ve{V}\ve{y},\ \forall \ve{y} \in \mathbb{C}^N:\,
  \label{eq:linear_delta_projection}
\end{equation}
where $\ve{V}$ \textit{projects} $\ve{y}$ onto $\mathcal{K}$. From the
orthogonality constraint in Eq~(\ref{eq:linear_projection_constraint})
it then follows that:
\begin{equation}
  \ve{y} = (\ve{W}^T\ve{A}\ve{V})^{-1}\ve{W}^T\ve{r}_0\:,
  \label{eq:linear_constraint_projection}
\end{equation}
where here the projection onto $\mathcal{K}$ is constrained by the
projection onto $\mathcal{L}$. Knowing this, we can then outline the
following iteration scheme for a projection method:
\begin{subequations}
  \begin{gather}
    \ve{r}^k = \ve{b} - \ve{A}\ve{x}^k\:,\\  
    \ve{y}^k = (\ve{W}^T\ve{A}\ve{V})^{-1}\ve{W}^T\ve{r}_0\:,\\
    \ve{x}^{k+1} = \ve{x}^k + \ve{V}\ve{y}^k\:,
  \end{gather}
  \label{eq:linear_projection_iteration}
\end{subequations}
where $\ve{V}$ and $\ve{W}$ are generated from the definitions of
$\mathcal{K}$ and $\mathcal{L}$ which are defined prior to each
iteration.

From an iteration standpoint, as we choose $\boldsymbol{\delta}$ from
$\mathcal{K}$ and constrain it with $\mathcal{L}$, each iteration
performs a projection that systematically anihilates the components of
the residual that exists in $\mathcal{L}$. This then means that if our
convergence criteria for an iterative method is bound to the residual
of the system, then Eq~(\ref{eq:linear_min_res}) tells us that each
projection step gaurantees us that the norm of the new residual will
never be worse than that of the previous step and will typically move
us towards convergence. Depending on the qualities of the system in
Eq~(\ref{eq:linear_problem}), the selection of the subspaces
$\mathcal{K}$ and $\mathcal{L}$ can serve to both gaurantee
convergence and optimize the rate at which the residual is decreased.

\subsection{Krylov Subspace Methods}
\label{subsec:krylov_methods}
Among the most common projection techniques used in practice are a
class of methods known as \textit{Krylov subspace methods}. Here, the
search subspace is defined as the \textit{Krylov subspace}:
\begin{equation}
  \mathcal{K}_m(\ve{A},\ve{r}_0) = span\{\ve{r}_0, \ve{A}\ve{r}_0,
  \ve{A}^2\ve{r}_0, \dots, \ve{A}^{m-1}\ve{r}_0\}\:,
  \label{eq:krylov_subspace}
\end{equation}
where $m$ denotes the dimensionality of the subspace. In order to
accomodate a more general structure for the operator in
Eq~(\ref{eq:linear_problem}), we often choose an \textit{oblique}
projection method where $\mathcal{K} \neq \mathcal{L}$. If we choose
$\mathcal{L} = \ve{A} \mathcal{K}_m(\ve{A},\ve{r}_0)$, then we are
ultimately solving the normal system $\ve{A}^T\ve{A}\ve{x} =
\ve{A}^T\ve{b}$ where $\ve{A}^T\ve{A}$ will be symmetric positive
definite if $\ve{A}$ is nonsingular, thereby expanding the range of
operators over which these methods are valid. This choice of
constraint subspace also then gives us the result via
Eq~(\ref{eq:linear_projection_constraint}) that the residual is
minimized for all $\boldsymbol{\delta} \in \mathcal{K}$, forming the
basis for the \textit{generalized minimum residual method} (GMRES)
\citep{saad_gmres:_1986}.

Choosing GMRES as our model Krylov method, we are first tasked with
finding a projector onto the subspace. We seek an orthonormal basis
for $\mathcal{K}_m(\ve{A},\ve{r}_0)$ by an orthogonalization procedure
that is commonly based on, but not limited to, the \textit{Arnoldi}
recurrence relation. The Arnoldi procedure will generate an
orthonormal basis, $\ve{V}_m \in \mathbb{C}^{N \times m}$, via a
variant of the Gram-Schmidt procedure that re-applies the operator for
each consecutive vector, thus forming a basis that spans the subspace
in Eq~(\ref{eq:krylov_subspace}). Due to its equivalent
dimensionality, $m$, to that of the subspace, we will refer to such
recurrence relations as \textit{long recurrence relations}. Those
orthogonal projection procedures that have a dimensionality less than
$m$ will be refferred to as \textit{short recurrence relations}.  Once
$\ve{V}_m$ is found, per the constraint subspace definition it then
follows that its basis is defined as $\ve{W}_m = \ve{A}
\ve{V}_m$. Knowing the projections onto the search and constraint
subspaces, the GMRES iteration may be formulated as follows:
\begin{algorithm}[htpb!]
  \caption{GMRES Iteration}
  \label{alg:gmres}
  \begin{algorithmic}
    \State $\ve{r}_0 := \ve{b}-\ve{A}\ve{x}_0$
    \State $\beta := ||\ve{r}_0||_2$
    \State $\ve{v}_1 := \ve{r}_0 / \beta$
    \Comment{Create the orthonormal basis for the Krylov subspace}
    \For{$j = 1, 2, \cdots, m$}
    \State $h_{ij} \leftarrow \langle w_j,v_j \rangle$
    \State $w_j \leftarrow w_j - h_{ij}v_i$
    \EndFor
    \State $h_{j+1,j} \leftarrow ||w_j||_2$
    \State $v_{j+1} \leftarrow w_j / h_{j+1,j}$
    \Comment{Apply the orthogonality constraints}
    \State $\ve{y}_m \leftarrow argmin_y ||\beta \ve{e}_1 - \ve{H}_m\
    \ve{y}||_2 $
    \State $\ve{x}_m \leftarrow \ve{x}_0 + \ve{V_m} \ve{y}_m$
  \end{algorithmic}
\end{algorithm}

We note here several properties of this formulation and how they may
facilitate or hinder the solution of large-scale, sparse linear
problems, also noting that these properties are common among many
Krylov methods. First, from a memory perspective GMRES is efficient in
that the operator $\ve{A}$ need not be explicitly stored. Rather, only
the ability to compute the action of that operator on a vector of
valid size is required. However, these savings in memory are balanced
by the fact that the long recurrence relations used in the Arnoldi
procedure require all vectors that span the Krylov space to be
stored. If the size of these vectors becomes prohibitive, the Arnoldi
procedure can be restarted at the cost of losing information in the
orthogonalization process, creating the potentitial to generate new
search directions that are not orthogonal to all previous search
directions (and therefore less than optimal). From an implementation
perspective, because the operator is not required to be formed, GMRES
is significantly more flexible in its usage in that there are many
instances where various processes serve to provide the action of that
operator (e.g. radiation transport sweeps \citep{evans_denovo:_2010})
that normally may not be amenable to its full construction. In
addition, the minimization problem is a straight-forward least-squares
problem where $\ve{H}$ is an upper-Hessenberg matrix.

\subsection{Parallel Projection Methods}
\label{subsec:parallel_krylov_methods}
Modern parallel implementations of projection methods on distributed
memory architectures rely heavily on capabilities provided by general
linear algebra frameworks. For methods like GMRES, this arises from
the fact that Krylov methods require only a handful of operation types
in their implementation that can be efficiently programmed on these
architectures. Per Saad's text \citep{saad_iterative_2003} and as
noted in Algorithm~\ref{alg:gmres}, these operations are
preconditioning, matrix-vector multiplications, vector updates, and
inner products. For the last three items, linear algebra libraries
such as PETSc \citep{gropp_scalable_1993} and Trilinos
\citep{heroux_overview_2005} provide efficient parallel
implementations for these operations. Depending on the type of
preconditioning used, efficient parallel implementations may also be
available for those operations. Due to their prevalence in modern
numerical methods, parallel formulations these operations have
warranted intense study \citep{tuminaro_parallel_1998}. In all cases, a series
of scatter/gather operations are required such that global
communication operations must occur. Although the relative performance
of such operations is bound to the implementation, asymptotically
perfomance should be the same across all implementations.

We will look at the three primary parallel matrix/vector operations as
preconditioning is not an immediate requirement for implementing the
algorithms. Furthermore, variants are available that reduce the number
of global communications required (consider
\cite{sosonkina_scalable_1998} as an example of reducing global
operation counts using a different orthogonalization procedure than
Arnoldi), however, we will only consider the basic algorithms here as
this handful operations can be generalized to fit more complicated
algorithms. In all of these cases, we assume a general matrix/vector
formulation that is distributed in parallel such that both local and
global knowledge of their decomposition is available on
request. Furthermore, it is assumed that these objects are partitioned
in such a way that the parallel formulation of the operator and
vectors in Eq~(\ref{eq:linear_problem}) will be such that each
parallel process contains only a subset of the global problem and that
subset forms a local set of complete equations. The form of this
partitioning is problem dependent and often has a geometric or
graph-based aspect to its construction in order to optimize
communication patterns. Libraries such as Zoltan
\citep{devine_zoltan_2002}, provide an implementations of such
algorithms.

\subsubsection{Parallel Vector Update}
\label{subsubsec:parallel_vec_update}
Parallel vector update operations arise from the construction of the
orthonormal basis and the application of the correction generated by
the constraints to the solution vector. Vector update operations are
embarassingly parallel in that they require no communication
operations to be successfully completed; all data operated on is
local. These operations are globally of the form:
\begin{equation}
  \ve{y}[n] \leftarrow \ve{y}[n] + a * \ve{x}[n],\ \forall n \in [1,N_g]
  \:,
  \label{eq:global_vector_update}
\end{equation}
and locally of the form:
\begin{equation}
  \ve{y}[n] \leftarrow \ve{y}[n] + a * \ve{x}[n],\ \forall n \in [1,N_l]
  \:,
  \label{eq:local_vector_update}
\end{equation}
where $\ve{y}$ and $\ve{x}$ are vectors of global size $N_g$, local
size $N_l$, and $a \in \mathbb{C}^N$. In order to avoid communcation,
the vectors $\ve{y}$ and $\ve{x}$ must have the same parallel
decomposition where each parallel process owns the same pieces of each
vector. 

\subsubsection{Parallel Vector Product}
\label{subsubsec:parallel_vector_product}
Vector product operations are used in several instances during a
Krylov iteration including vector norm computations and the
orthogonalization procedure. By definition, the vector product is a
global operation that effectively collapses two vectors to a single
value. Therefore, we cannot eliminate all global
communications. Instead, vector product operations are formulated as
\textit{global reduction operations} that are efficiently supported by
modern message passing libraries. For the dot product of two vectors
$\ve{y}$ and $\ve{x}$, a single reduction is required such that:
\begin{equation}
  d_l = \ve{y}_l \cdot \ve{x}_l,\ d_g = \sum_p d_l \:,  
  \label{eq:parallel_dot_product}
\end{equation}
where the $l$ subscript denotes a local quantity, $d_l$ is the local
vector dot product, and $d_g$ is the global dot product generated by
summing the local dot products over all $p$ processes. Parallel norm
operations can be conducted with the same single reduction. Consider
the infinity norm operation:
\begin{subequations}
  \begin{gather}
    ||x||_{\infty,l} = \max_n \ve{y}[n],\ \forall n \in [1,N_l]\:\\
    ||x||_{\infty,g} = \max_p ||x||_{\infty,l}\:.
  \end{gather}
  \label{eq:parallel_infinity_norm}
\end{subequations}
In this form, the local infinity norm is computed over the local piece
of the vector. The reduction operation is then formed over all $p$
processes such that the global max of the vector is computed and
distributed to all processes.

\subsubsection{Parallel Matrix-Vector Multiplications}
\label{subsubsec:parallel_mat_vec_mutliply}
We finally consider parallel matrix-vector multiplication operations
using sparse matrices in a compressed storage format by considering
Saad's outline as well as the more formal work of Tuminaro
\citep{tuminaro_parallel_1998}. For these operations, more complex
communication patterns will be required given that the entire global
vector is required in order to compute a single element of the local
product vector. Fortunately, the vast majority of the global vector
components will be multiplied by zero due to the sparsity of the
matrix and therefore much of the vector can be neglected. Instead we
only require data from a handful of other processes that can be
acquired through asynchronous/synchronous communications. Consider the
sparse matrix-vector multiply in
Figure~\ref{fig:partitioned_matvec_multiply} that is partitioned on 3
processors.
\begin{figure}[htpb!]
  \begin{center}
    \scalebox{1.5}{
      \input{chapters/linear_problem/partitioned_matrix.pdftex_t} }
  \end{center}
  \caption{\textbf{Sparse matrix-vector multiply $\ve{A}\ve{x}=\ve{y}$
      operation partitioned on 3 processors.} \textit{Each process
      owns a set of equations that correlates to its physical
      domain.}}
  \label{fig:partitioned_matvec_multiply}
\end{figure}
Each process owns a set of equations that correlate to the physical
domain of which it has ownership. We can break down the equations
owned by each process in order to devise an efficient scheme for the
multiplication. Consider the portion of the matrix-vector multiply
problem owned by process 1 in
Figure~\ref{fig:partitioned_matvec_multiply}. As shown in
Figure~\ref{fig:matvec_proc_1}, the components of the matrix will be
multiplied by pieces of the vector that are owned by all
processors. 
\begin{figure}[htpb!]
  \begin{center}
    \scalebox{1.5}{
      \input{chapters/linear_problem/matvec_proc_1.pdftex_t} }
  \end{center}
  \caption{\textbf{Components of sparse matrix-vector multiply
      operation owned by process 1.} \textit{The numbers above the
      matrix columns indicate the process that owns the piece of the
      global vector they are acting on. In order to compute its local
      components of the matrix-vector product, process 1 needs its
      matrix elements along with all elements of the global vector
      owned by processes 2 and 3. The piece of the matrix shown is
      $\ve{A}_1$ and it is acting locally on $\ve{x}_1$ to compute the
      local piece of the product, $\ve{y}_1$.}}
  \label{fig:matvec_proc_1}
\end{figure}
For those pieces of the matrix that are owned by process 1 that act on
the vector owned by process 1, we do these multiplications first as no
communication is required. Next, process one gathers the components of
the global vector that it requires to complete its part of the vector
product. For this example, the components of matrix that will operate
on the global vector are zero, and therefore no vector elements are
required to be scattered from process 3 to process 1. Those matrix
elements that will act on the piece of the vector owned by process 2
are not all non-zero, and therefore we must gather the entire process
2 vector components onto process 1 to complete the multiplication.
Conversely, processes 2 and 3 must scatter its vector components that
are required by other processes (such as process 1) in order to
complete their pieces of the product. This then implies that these
domain connections for proper gather and scatter combinations must be
constructed a priori. These data structures are typically generated by
a data partitioning library. Mathematically, if we are performing a
global matrix-vector multiply of the form $\ve{A}\ve{x} = \ve{y}$,
then for this example on process 1 we have a sequence of local
matrix-vector multiplications: $\ve{A}_1\ve{x}_1 + \ve{A}_1\ve{x}_2 =
\ve{y}_1$. Here, some of the data is intrinisically local, and some
must be gathered from other processes using the partitioning data
structures.

\subsubsection{Parallel Perfomance Implications for Krylov Methods}
\label{subsubsec:projection_method_performance}
Knowing the parallel characteristics of the key operations we must
perform in order to implement Krylov methods, we can make a few
statements about parallel perfomance and implications for operation on
machines of increasing size.  For very large distributed machines,
global reduction operations required at several levels of Krylov
algorithms stand to reduce scalablitity and perfomance. Furthermore,
communication between adjacent domains in matrix-vector multiply
operations may also cause a bottleneck as the number of domains used
in simulation grows. The end result is that global data must be
collected and communicated. For scaling improvement, we seek a
reduction in these types of operations. In addition, these issues
become more prominent as the Krylov iterations progress, causing the
Krylov subspace to grow and the total number of operations needed to
orthogonalize that subspace to increase.

\section{Stochastic Methods}
\label{sec:stochastic_methods}
An alternative approach to approximate matrix inversion is to employ
Monte Carlo methods that sample a distribution with an expectation
value equivalent to that of the inverted operator. Such methods have
been in existence for decades with the earliest reference noted here
an enjoyable manuscript published in 1950 by Forsythe and Leibler
\citep{forsythe_matrix_1950}. In their outline, Forsythe and Liebler
in fact credit the creation of this technique to J. Von Neumann and
S.M. Ulam some years earlier than its publication. In 1952 Wasow
provided a more formal explanation of Von Neumann and Ulam's method
\citep{wasow_note_1952} and Hammersley and Handscomb's 1964 monograph
\citep{hammersley_monte_1964} presents additional detail on this topic
using a collection of references from the 1950's and early 1960's.

We begin our discussion of stochastic methods using these texts by
seeking a solution to Eq~(\ref{eq:linear_problem}). For a given linear
operator $\ve{A}$, we can using diagonal splitting in the same manner
as the stationary method in Eq~(\ref{eq:linear_split_equation2}) to
define the following operator\footnote{It should be noted that
  non-diagonal splittings have been recently explored in
  \citep{srinivasan_monte_2010} and have the potential to improve
  efficiency.}:
\begin{equation}
  \ve{H} = \ve{I} - \ve{A}\:.
  \label{eq:linear_mc_iteration_matrix}
\end{equation}
We can then form an alternative representation for $\ve{A}^{-1}$ by
generating the \textit{Neumann series}:
\begin{equation}
  \ve{A}^{-1} = (\ve{I}-\ve{H})^{-1} = \sum_{k=0}^{\infty} \ve{H}^k\:,
  \label{eq:neumann_series}
\end{equation}
which will converge if the spectral radius of $\ve{H}$ is less than
1. If we then apply this inverse sum to the right hand side of
Eq~(\ref{eq:linear_problem}) we acquire the solution to the linear
problem:
\begin{equation}
  \ve{A}^{-1}\ve{b} = \sum_{k=0}^{\infty} \ve{H}^k\ve{b} = \ve{x}\:.
  \label{eq:neumann_solution}
\end{equation}
An approximation of this summation will therefore lead to an
approximation of the solution. If we expand the summation with a
succession of matrix-vector multiply operations, we arrive at an
alternative perspective of this summation by considering its $i^{th}$
component:
\begin{equation}
  x_i = \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
  \sum_{i_k}^{N}h_{i,i_1}h_{i_1,i_2}\ldots h_{i_{k-1},i_k}b_{i_k}\:,
  \label{eq:expanded_neumann_solution}
\end{equation}
which can interpreted as a series of transitions between states,
\begin{equation}
 \nu = i \rightarrow i_1 \rightarrow \cdots \rightarrow i_{k-1}
 \rightarrow i_{k}\:,
  \label{eq:mc_walk_permutation}
\end{equation}
in $\ve{H}$ where $\nu$ is a particular random walk sequence
permutation. We can generate these sequences of transitions through
Monte Carlo random walks by assigning them both a probability and
weight. As a reinterpretation of the iteration matrix, we then form
the \textit{Neumann-Ulam decomposition} of \ve{H}:
\begin{equation}
  \ve{H} = \ve{P} \circ \ve{W}\:,
  \label{eq:neumann_ulam_decomposition}
\end{equation}
where $\circ$ denotes the Hadamard product operation\footnote{The
  Hadamard product $\ve{A} = \ve{B} \circ \ve{C}$ is defined
  element-wise as $a_{ij} = b_{ij} c_{ij}$.}, $\ve{P}$ denotes the
transition probability matrix, and $\ve{W}$ denotes the transition
weight matrix. This decomposition, a generalization of Dimov's work
\citep{dimov_new_1998}, is an extension of the original Neumann-Ulam
scheme in that now a weight cutoff can be used to terminate a random
walk sequence. The formulation of $\ve{P}$ and $\ve{W}$ will be
dependent on whether we choose a direct or adjoint Monte Carlo
sequence to estimate the state transitions in
Eq~(\ref{eq:expanded_neumann_solution}).

\subsection{Direct Method}
\label{subsec:direct_mc}
In the context of matrix inversion, a direct method resembles an
adjoint Monte Carlo method in the reactor physics community where the
solution state is sampled and the source terms that contribute to it
are assembled. To achieve this, we build the direct method
Neumann-Ulam decomposition per Dimov's approach by first choosing a
probability matrix that is a row scaling of $\ve{H}$ such that its
components are:
\begin{equation}
  p_{ij} = \frac{|h_{ij}|}{\sum_j |h_{ij}|}\:.
  \label{eq:direct_probability}
\end{equation}
From this, we then see that the probability of transitioning from a
state $i$ to a state $j$ is implicitly linked to the original operator
$\ve{A}$ in that those terms with large values, and therefore those
that make the greatest contribution to the numerical solution, will be
sampled with a higher probability than smaller terms. In addition, the
row scaling provides a normalization over the state to which we are
transitioning such that $\sum_j p_{ij} = 1$, meaning that we sample
the probabilities over the rows of the matrix. The components of
the weight matrix are then defined by
Eq~(\ref{eq:neumann_ulam_decomposition}) as:
\begin{equation}
  w_{ij} = \frac{h_{ij}}{p_{ij}}\:.
  \label{eq:direct_weight}
\end{equation}
It should be noted here that if $\ve{A}$ is sparse, then $\ve{H}$,
$\ve{P}$, and $\ve{W}$ must be sparse as well by
definition. Additionally, we only compute $\ve{P}$ and $\ve{W}$ from
the non-zero elements of $\ve{H}$ as those components that are zero
will not participate in the random walk. Furthermore, it prevents an
infinite weight from being generated in Eq~(\ref{eq:direct_weight}).

Using these matrices, we can then form the expectation value of the
direct solution. For a given random walk permutation $\nu$ with $k$
events, we define the weight of that permutation to be:
\begin{equation}
  W_{m} = \sum_{m=0}^k w_{i,i_1} w_{i_1,i_2} \cdots w_{i_{m-1},i_m}\:,
  \label{eq:direct_permutation_weight}
\end{equation}
such that the weight of each transition event contributes to the
total. The contribution to the solution from a particular random walk
permutation is then:
\begin{equation}
  X_{\nu}(i_0 = i) = \sum_{m=0}^k W_{m} b_{i_m}\:,
  \label{eq:direct_permutation_contribution}
\end{equation}
where $X_{\nu}(i_0 = i)$ signifies that the solution state in which we
are tallying defines state $i$.  We can interpret this precisely as
before in that during the random walk we collect the source in the
states that are visited and apply them to the solution tally. We then
define the probability that a particular random walk permuation of $k$
events will occur:
\begin{equation}
  P_{\nu} = p_{i,i_1} p_{i_1,i_2} \cdots p_{i_{k-1},i_k}\:.
  \label{eq:direct_permutation_probability}
\end{equation}
Finally, we define the expectation value of $X$ to be the collection
of all random walk permutations and their probabilities:
\begin{equation}
  E\{X(i_0 = i)\} = \sum_{\nu} P_{\nu} X_{\nu}\:,
  \label{eq:direct_expectation_value}
\end{equation}
which, if expanded, directly recovers the exact solution:
\begin{equation}
  \begin{split}
    E\{X(i_0 = i)\}
    &=\sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
    \sum_{i_k}^{N} p_{i,i_1}p_{i_1,i_2}\ldots p_{i_{k-1},i_k}
    w_{i,i_1}w_{i_1,i_2}\ldots w_{i_{k-1},i_k} b_{i_k}\\ &= x_i\:,
  \end{split}
  \label{eq:direct_expectation_expansion}
\end{equation}
therefore providing an unbiased Monte Carlo estimator. 

\subsubsection{Estimator Variance}
\label{subsubsec:estimator_variance}
We can compute the variance of the estimator through traditional
methods by defining the variance, $\sigma_i$, for each component in
the solution:
\begin{equation}
  {\sigma_i}^2 = E\{X(i_0 = i) - (\ve{A}^{-1}\ve{b})_i\}^2 = E\{X(i_0
  = i)^2\} - x_i^2\:,
  \label{eq:direct_variance_1}
\end{equation}
where the vector exponentials are computed element-wise. Inserting
Eq~(\ref{eq:direct_expectation_value}) gives:
\begin{equation}
  \sigma_i^2 = \sum_{\nu} P_{\nu} X_{\nu}^2 - x_i^2\:,
  \label{eq:direct_variance_2}
\end{equation}
and applying Eq~(\ref{eq:direct_permutation_contribution}):
\begin{equation}
  \sigma_i^2 = \sum_{\nu} P_{\nu} \sum_{m=0}^k W_{m}^2 b_{i_m}^2 -
  x_i^2\:.
  \label{eq:direct_variance_3}
\end{equation}
Finally, expanding the transition probabilities yields:
\begin{equation}
  \sigma_i^2 = \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
  \sum_{i_k}^{N} p_{i,i_1}p_{i_1,i_2}\ldots p_{i_{k-1},i_k}
  w^2_{i,i_1}w^2_{i_1,i_2}\ldots w^2_{i_{k-1},i_k} b_{i_m} - x_i^2\:.
  \label{eq:direct_variance_4}
\end{equation}
Using this defintion for the variance, we can arrive at a more natural
reason for enforcing $\rho(\ve{H}) < 1$. Per the Hadamard product, we can
concatenate the summation in Eq~(\ref{eq:direct_variance_4}):
\begin{equation}
  (\ve{P} \circ \ve{W} \circ \ve{W})^k =
  \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots \sum_{i_k}^{N}
  p_{i,i_1}p_{i_1,i_2}\ldots p_{i_{k-1},i_k}
  w^2_{i,i_1}w^2_{i_1,i_2}\ldots w^2_{i_{k-1},i_k}\:.
  \label{eq:double_weighted_decomposition}
\end{equation}
If we assign $\ve{G} = \ve{P} \circ \ve{W} \circ \ve{W}$ as in
Eq~(\ref{eq:neumann_ulam_decomposition}), we then have a new
formulation for the variance:
\begin{equation}
  \sigma^2_i = \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
  \sum_{i_k}^{N}g_{i,i_1}g_{i_1,i_2}\ldots g_{i_{k-1},i_k} b_{i_k}^2 -
  x_i^2\:,
\end{equation}
which contains the general Neumann series for $\ve{G}$,
\begin{equation}
  \ve{T} = \sum_{k=0}^{\infty} \ve{G}^k\:,
  \label{eq:variance_neumann_series}
\end{equation}
where $\ve{T} = (\ve{I}-\ve{G})^{-1}$. We can then insert $T$ back
into the variance formulation:
\begin{equation}
  \sigma^2_i = (\ve{T}\ve{b})_i - x_i^2
  \label{eq:direct_variance_5}
\end{equation}
We can relate $\ve{G}$ to $\ve{H}$ by noting that $\ve{G}$ simply
contains an additional Hadamard product with the weight matrix. The
Hadamard product has the property that:
\begin{equation}
  |\ve{H} \circ \ve{W}| \geq |\ve{H}|\ |\ve{W}|\:,
  \label{eq:hadamard_inequality}
\end{equation}
meaning that $\rho(\ve{G}) \geq \rho(\ve{H})$. Using these relations
to analyze Eq~(\ref{eq:direct_variance_5}), we see that if
$\rho(\ve{H}) > 1$, then the sum in
Eq~(\ref{eq:variance_neumann_series}) will not converge and an
infinite variance will arise as the elements of $\ve{T}$ become
infinite. Therefore, we must restrict $\ve{H}$ with $\rho(\ve{H}) < 1$
so that our expectation values for the solution may have a finite
variance.

As we seek only approximate solutions, we need only to perform a
minimal number of random walks in order to generate an approximation
for $\ve{x}$. Furthermore, we also need conditions by which we may
terminate a random walk. We do this by noticing that the factors added
to Eq~(\ref{eq:direct_permutation_weight}) will become diminishingly
small due to their definition in Eq~(\ref{eq:direct_weight}) such that
their contributions to the solution estimate will become
negligble. Therefore, we choose terminate a random walk sequence with
a \textit{weight cutoff}, $W_c$, that is enforced when $W_m < W_c$ for
a particular random walk permutation.

\subsubsection{Reusing Random Walks}
\label{subsubsec:reusing_random_walks}
Ji recently proposed a variation of the direct method in which the
random walk permutations in Eq~(\ref{eq:mc_walk_permutation}) can be
used to contribute to the solution tally in all visited states instead
of the only starting state \citep{ji_reusing_2012}.

\subsection{Adjoint Method}
\label{subsec:adjoint_mc}
An alternative formulation for Monte Carlo matrix inversion is the
adjoint method. In this scheme, random walk histories are born in a
state generated by source sampling and tallies are generated in the
states in which the random walk currently resides. In terms of
particle transport, this adjoint method is equivalent to a traditional
forward method. To begin, we first form the \textit{adjoint
  Neumann-Ulam decomposition} of $\ve{H}$:
\begin{equation}
  \ve{H}^T = \ve{P} \circ \ve{W}\:,
  \label{eq:adjoint_neumann_ulam}
\end{equation}
where now we are forming the decomposition with respect to the
transpose of $\ve{H}$. We then following the same procedure as the
direct method for forming the probability and weight matrices in the
decomposition. Using the transpose form, probabilities should instead
be column-scaled:
\begin{equation}
  p_{ij} = \frac{|h_{ji}|}{\sum_j |h_{ji}|}\:,
  \label{eq:adjoint_probability}
\end{equation}
such that we expect to select a new state $j$ from the current state
in the random walk $j$ by sampling column-wise. Per
Eq~(\ref{eq:adjoint_neumann_ulam}), the transition weight is then
defined as:
\begin{equation}
  w_{ij} = \frac{h_{ji}}{p_{ij}}\:.
  \label{eq:adjoint_weight}
\end{equation}
Using the decomposition we can then define an expectation value for
the adjoint method. Given Eq~(\ref{eq:direct_permutation_weight}) as
the weight generated for a particular random walk permutation as in
Eq~(\ref{eq:mc_walk_permutation}) and the fact that in the adjoint
method we are only tallying the solution in the state in which the
walk currently resides, the contribution to the solution from a
particular random walk permutation is then:
\begin{equation}
  X_{\nu} = \sum_{m=0}^k W_{m} b_{i_0} \delta_{i,i_m}\:,
  \label{eq:adjoint_permutation_contribution}
\end{equation}
where the Kronecker delta indicates that the tally contributes only in
the current state and $b_{i_0}$ is that sampled source starting
state. Note here that the estimator in
Eq~(\ref{eq:adjoint_permutation_contribution}) does not have a
dependency on the source state as in
Eq~(\ref{eq:adjoint_permutation_contribution}), providing a remedy for
the situation in the direct method where we must start a random walk
in each source state for every permutation such that we may compute a
contribution for that state. In the adjoint method, we instead tally
in all states and those of lesser importance will not be visited as
frequently by the random walk. Finally, the estimator using all
permutations is:
\begin{equation}
  E\{X\} = \sum_{\nu} P_{\nu} X_{\nu}\:
  \label{eq:adjoint_expectation_value}
\end{equation}
which, if expanded in the same way as the direct method, directly
recovers the exact solution:
\begin{equation}
  \begin{split}
    E\{X\} &=\sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
    \sum_{i_k}^{N} p_{i,i_1}p_{i_1,i_2}\ldots p_{i_{k-1},i_k}
    w_{i,i_1}w_{i_1,i_2}\ldots w_{i_{k-1},i_k} b_{i_k} \\ &= x_i\:,
  \end{split}
  \label{eq:adjoint_expectation_expansion}
\end{equation}
therefore also providing an unbiased Monte Carlo estimator.

We also desire a criteria for random walk termination. For the adjoint
method, we utilize a \textit{relative weight cutoff}:
\begin{equation}
  W_f = W_c b_{i_0}\:,
  \label{eq:relative_weight_cutoff}
\end{equation}
where $W_c$ is defined as in the direct method. The adjoint random
walk will then be terminated after $m$ steps if $W_m < W_f$ as tally
contributions become increasingly small.

Given these ideas, we can then generate an algorithm for implementing
the adjoint method:
\begin{algorithm}[htpb!]
  \caption{Adjoint Monte Carlo}
  \label{alg:adjoint_mc}
  \begin{algorithmic}
    \State $\ve{r}_0 := \ve{b}-\ve{A}\ve{x}_0$
  \end{algorithmic}
\end{algorithm}

\subsection{Sequential Monte Carlo}
\label{subsec:sequential_mc}
The direct and adjoint methods described are limited by a convergence
rate of $1/\sqrt{N}$ by the Central Limit Theorem where $N$ is the
number of random walk permutations. In 1962, Halton presented a
residual Monte Carlo method that moves towards exponential convergence
rates \citep{halton_sequential_1962} and further refined his work some
years later \citep{halton_sequential_1994}. Applications of his work
by the transport community have confirmed convergence rates on the
order of of $exp(-N)$
\citep{evans_residual_2003}. In
much the same way as projection methods, Halton's method, sequential
Monte Carlo, utilizes the adjoint Monte Carlo solver as a means of
driving down the residual vector. He proposed the following iterative
scheme as a solution to Eq~(\ref{eq:linear_problem})\:
\begin{subequations}
  \begin{gather}
    \ve{r}^k = \ve{b} - \ve{A}\ve{x}^k\:,\\  
    \ve{A}\boldsymbol{\delta}^{k+1} = \ve{r}^{k}\:,\\
    \ve{x}^{k+1} = \ve{x}^k + \boldsymbol{\delta}^{k+1}\:,
  \end{gather}
  \label{eq:sequential_monte_carlo}
\end{subequations}
where the correction $\boldsymbol{\delta}$ is computed by the adjoint
Monte Carlo method. The merits of Halton's approach are immediately
visible in that we have now broken the binding of the convergence rate
to the Central Limit Thereom. Here, the Monte Carlo solve is used to
produce a correction from the residual, analagous to using the
residual to extract a correction from the search subspace in a
projection method. By doing this, the Monte Carlo error is bound in
the correction used to update the solution and therefore does not
explicitly manifest itself in the solution. The downside of such a
method is that if the solution guess is poor, then many iterations are
required in order to reach exponential converge as the Monte Carlo
error (and therefore the Central Limit Theorem) does dominate in this
situation. Therefore, if a good initial guess is not available,
Halton's method is still characterized by poor performance.

\subsection{Monte Carlo Synthetic-Acceleration}
\label{subsec:mcsa}
Using the ideas of Halton, Evans and Mosher recently developed a Monte
Carlo solution that was not prohibited severely by the quality of the
initial guess for the system \citep{evans_monte_2009}. Their approach
was instead to use residual Monte Carlo as a synthetic acceleration
for a stationary method. To derive this method, we begin by splitting
the operator in Eq~(\ref{eq:linear_problem})
\begin{equation}
  \ve{x} = (\ve{I} - \ve{A})\ve{x} + \ve{b}\:.
  \label{eq:linear_split}
\end{equation}
With this we can then define the stationary method
\textit{Richardson's iteration} as:
\begin{equation}
  \ve{x}^{k+1} = (\ve{I} - \ve{A})\ve{x}^k + \ve{b}\:,
  \label{eq:richardsons_iteration}
\end{equation}
which will converge if $\rho(\ve{I} - \ve{A}) < 1$. We then define the
solution error at the $k^{th}$ iterate relative to the true solution:
\begin{equation}
  \delta \ve{x}^k = \ve{x} - \ve{x}^k\:.
  \label{eq:mcsa_error}
\end{equation}
Subtracting Eq~(\ref{eq:richardsons_iteration}) from
Eq~(\ref{eq:linear_split}) we get:
\begin{equation}
  \delta \ve{x}^{k+1} = (\ve{I} - \ve{A})\delta \ve{x}^k\:.
  \label{eq:mcsa_setup_1}
\end{equation}
Subtracting from this $(\ve{I} - \ve{A})\delta \ve{x}^{k+1}$ yields:
\begin{equation}
  \begin{split}
    \ve{A}\delta \ve{x}^{k+1} &= (\ve{I} -
    \ve{A})(\ve{x}^{k+1}-\ve{x}^{k}) \\ &= \ve{r}^{k+1}\:.
    \label{eq:mcsa_setup_2}
  \end{split}
\end{equation}
Using this, we define the following scheme that will converge in one
iteration if $\ve{A}$ is inverted exactly.
\begin{subequations}
  \begin{gather}
    \ve{x}^{k+1} = (\ve{I} - \ve{A})\ve{x}^k + \ve{b}\:,\\
    \ve{A} \delta \ve{x}^{k+1} = \ve{r}^{k+1}\:,\\
    \ve{x} = \ve{x}^{k+1} + \delta \ve{x}^{k+1}\:.
  \end{gather}
  \label{eq:mcsa_setup_3}
\end{subequations}
However, $\ve{A}$ is only approximately inverted by our numerical
methods and therfore we instead pose an iterative scheme in which the
Monte Carlo solvers are used to invert the operator. The
\textit{Fixed-Point Monte Carlo Synthetic-Acceleration} (MCSA) method
is defined as:
\begin{subequations}
  \begin{gather}
    \ve{x}^{k+1/2} = (\ve{I} - \ve{A})\ve{x}^k + \ve{b}\:,\\
    \ve{r}^{k+1/2} = \ve{b} - \ve{A}\ve{x}^{k+1/2}\:,\\
    \ve{A}\delta\ve{x}^{k+1/2} = \ve{r}^{k+1/2}\:,\\
    \ve{x}^{k+1} = \ve{x}^{k+1/2} + \delta \ve{x}^{k+1/2}\:,
    \label{eq:mcsa}
  \end{gather}
\end{subequations}
where the adjoint Monte Carlo method is used to generate the solution
correction from the residual. Using Monte Carlo in this way achieves
the same effect as Halton's method, decoupling its convergence rate
from the overall convergence rate of the method. Here, the approximate
Monte Carlo solution is not driven to a particular convergence as it
merely supplies a correction for the initial guess generated by
Richardson's iteration. Rather, only a set number of histories are
required using the adjoint method to generate the correction.

In addition to the Monte Carlo solver parameters dictating the number
of histories and weight cutoff, the outer MCSA iterations also have
the following stopping criteria:
\begin{equation}
  ||\ve{r}||_\infty < \epsilon \ ||\ve{b}||_\infty\:,
  \label{eq:mcsa_stopping_criteria}
\end{equation}
where $\epsilon$ is a user-defined parameter. We therefore have 3
parameters to tune in an MCSA implementation: the number of Monte
Carlo histories computed in the adjoint solve during each MCSA
iteration, the weight cutoff for those histories, and the total MCSA
convergence tolerance as specified by $\epsilon$.

\subsection{Preconditioning Stochastic Methods}
\label{subsubsec:stochastic_preconditioning}
In most cases, at least a minimal amount of \textit{preconditioning}
of the linear system will be required in order to use the class of
stochastic methods described. Although these methods have no symmetry
requirements for convergence, they do require that the spectral radius
of the iteration matrix be less than one. To achieve this, a Jacobi
precondtioner, a form of left preconditioning, is used such that the
preconditioning matrix $\ve{M}$ is:
\begin{equation}
  \ve{M} = diag(\ve{A})\:,
  \label{eq:jacobi_preconditioner}
\end{equation}
such that its application means we are instead solving the following
linear system:
\begin{equation}
  \ve{M}^{-1}\ve{A}\ve{x} = \ve{M}^{-1}\ve{b}\:.
  \label{eq:jacobi_precond_linear_problem}
\end{equation}
Next, we can apply MCSA to solve
Eq~(\ref{eq:jacobi_precond_linear_problem}): 
\begin{subequations}
  \begin{gather}
    \ve{x}^{k+1/2} = (\ve{I} - \ve{M}^{-1}\ve{A})\ve{x}^k +
    \ve{M}^{-1}\ve{b}\:,\\ \ve{r}^{k+1/2} = \ve{M}^{-1}\ve{b} -
    \ve{M}^{-1}\ve{A}\ve{x}^{k+1/2}\:,\\ \ve{M}^{-1}\ve{A}\delta\ve{x}^{k+1/2}
    = \ve{r}^{k+1/2}\:,\\ \ve{x}^{k+1} = \ve{x}^{k+1/2} + \delta
    \ve{x}^{k+1/2}\:.
    \label{eq:jacobi_preconditioned_mcsa}
  \end{gather}
\end{subequations}
Choosing Jacobi preconditioning with MCSA is advantageous for several
reasons. First, $\rho(\ve{I} - \ve{M}^{-1}\ve{A}) < 1$ is true for
all $\ve{A}$ and is easy to formulate as the inversion of $\ve{M}$ is
trivial. Second, because the adjoint Monte Carlo method used within MCSA to
compute the correction operates on a linear problem with the
preconditioned operator, then $\ve{H}$ in the adjoint solver will have
a zero term in each of its diagonal elements, thereby eliminating
all in-state transitions during the random walk sequence. Because of
this, Jacobi preconditioning should always be performed, regardless of
any other preconditioning that is applied to the system.

\subsection{Parallelization of Stochastic Methods}
\label{subsec:parallel_stochastic_methods}
For Monte Carlo methods, and in particular MCSA, to be viable at the
production scale, scalable parallel implementations are required. In a
general linear algebra context, this has not yet been
achieved. Therefore, we will develop and implement parallel algorithms
for these methods levaraging both the knowledge gained from the
general parallel implementations of Krylov methods and modern parallel
strategies for Monte Carlo as developed by the reactor physics
community. In order to formulate a parallel MCSA algorithm, we
recognize that the algorithm occurs in two stages, an outer iteration
performing Richardson's iteration and applying the correction, and an
inner Monte Carlo solver that is generating the correction via the
adjoint method. The parallel aspects of both these components must be
considered.

\subsubsection{Domain Decomposition for Monte Carlo}
\label{subsubsec:msod}
As observed in the discussion on parallel Krylov methods, large-scale
problems will surely have their data partitioned such that each
parllel process owns a subset of the equations in the linear
system. Given this convention, the adjoint Monte Carlo algorithm must
perform random walks over a domain that is decomposed and must remain
decomposed due to memory limitations. This naturally leads us to seek
parallel algorithms that handle domain decomposition. In the context
of radiation transport, Brunner and colleagues provided a survey of
algorithms for achieving this as implemented in production implicit
Monte Carlo codes \citep{brunner_comparison_2006}. In their work they
identity two data sets that are required to be communicated: the
sharing of particles that are transported from one domain to another
and therefore from one processor to another and a global communication
that signals if particle transport has been completed on all
processors. The algorithms presented are a fully-locking synchronous
scheme, a asynchronous-send/synchronous-receive pattern, a traditional
master/slave scheme, and a modified master/slave scheme the implements
a binary tree pattern for the global reduction type operations needed
to communicate between the master and slave processes. They observed
that the modified master/slave scheme performed best in that global
communications were implemented more efficiently than those required
by the asynchronous scheme. Furthermore, none of these schemes handled
load-imbalanced cases efficiently. Such cases will be common if the
source sampled in the Monte Carlo random walk is not isotropic and
evenly distributed throughout the global domain. It was noted that
efficiencies were improved by increasing the frequency by which
particle data was communicated between domain-adjacent processors.
However, this ultimately increases communication costs.

The 2006 work of Brunner is notable in that the Monte Carlo codes used
to implement and test the algorithms adhered to a strict policy of
generated identical results, indepdent of domain decomposition or
domain replication as derived from the work of Gentile and colleagues
\citep{gentile_obtaining_2005}. In their work, a procedure is given for
obtaining results reproducable to machine precision for an arbitrary
number of processors and domains. Differences can arise from using a 
different random number sequence in each domain and performing
a sequence of floating point operations on identical data in a
different, leading to variations in round-off error and ultimately a
non-identical answer. They use a simple example, recreated below in
Figure~\ref{fig:gentile_example}, that illustrates these issues.
\begin{figure}[htpb!]
  \begin{center}
    \scalebox{1.5}{
      \input{chapters/linear_problem/gentile_example.pdftex_t} }
  \end{center}
  \caption{\textbf{Gentile's example illustrating how domain
      decomposition can create reproducability issues in Monte Carlo.}
    \textit{Both particles A and B start in zone 1 on processor
      1. Particle A moves to zone 2 on processor 2 and scatters back
      to zone 1 while B scatters in zone 1 and remains there.}}
  \label{fig:gentile_example}
\end{figure}


In 2010, Wagner and colleagues developed the \textit{multiple-set
  overlapping-domain} (MSOD) decomposition for parallel Monte Carlo
applications for full-core reactor analysis
\citep{wagner_hybrid_2010}. In their work, a certain amount of overlap
between domains was used to decrease the number of particles leaving
the domain.

\subsubsection{Parallel Adjoint Method}
\label{subsubsec:parallel_adjoint}

\subsubsection{Parallel MCSA}
\label{subsubsec:parallel_mcsa}
It should be noted here that a lot of the parallel matrix/vector
operations discussed in the parallel projection methods section also
apply here. Three of the four MCSA steps are in fact these operations
with convergence checks also using a norm reduction.
