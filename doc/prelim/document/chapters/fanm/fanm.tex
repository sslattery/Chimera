\chapter{The FANM Method for Nonlinear Problems}
\label{ch:fanm}

In this chapter we will devise the FANM method. Based on the
background in the previous section, we first need to motivate the
development of this work by pointing out some of the issues with
conventional methods. This includes JFNK coarseness and prohibitively
large Krylov subspace. We can than point out some of the attractive
qualities of the FANM method. Much of this will rely on advanced
concepts including automatic differentiation and on-the-fly residual
and Jacobian generation from nonlinear function evaluations. In
addition, we will want to show that the Newton method will converge
using MCSA as the linear solver. I suspect I will have some
preliminary results for a serial implementation here as I already have
a serial MCSA implemented. Finally, we will want to design the model
problems that we will test FANM with. These should be problems that
have already been worked up in the literature with benchmark-type
solutions.

\section{Issues with Current Nonlinear Methods}
\label{sec:nonlinear_issues}

\section{Automatic Differentiation}
\label{sec:automatic_differentiation}

\section{Residual and Jacobian Generation}
\label{sec:fanm_generation}

\section{Algorithm Outline}
\label{sec:fanm_algorithm_outline}

\section{Model Problems}
\label{sec:fanm_model_problems}
