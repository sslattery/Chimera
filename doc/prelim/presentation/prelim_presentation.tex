\documentclass{beamer}
\usetheme[white]{Wisconsin}
\usepackage{longtable}
\usepackage{listings}
\usepackage{color}
%% The amssymb package provides various useful mathematical symbols
\usepackage{amssymb}
%% The amsthm package provides extended theorem environments
\usepackage{amsthm} \usepackage{amsmath} \usepackage{tmadd,tmath}
\usepackage[mathcal]{euscript} \usepackage{color}
\usepackage{textcomp}
\usepackage{algorithm,algorithmic}
\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
\lstset{
  backgroundcolor=\color{lbcolor},
  tabsize=4,
  rulecolor=,
  language=c++,
  basicstyle=\scriptsize,
  upquote=true,
  aboveskip={1.5\baselineskip},
  columns=fixed,
  showstringspaces=false,
  extendedchars=true,
  breaklines=true,
  prebreak =
  \raisebox{0ex}[0ex][0ex]{\ensuremath{\hookleftarrow}},
  frame=single,
  showtabs=false,
  showspaces=false,
  showstringspaces=false,
  identifierstyle=\ttfamily,
  keywordstyle=\color[rgb]{0,0,1},
  commentstyle=\color[rgb]{0.133,0.545,0.133},
  stringstyle=\color[rgb]{0.627,0.126,0.941},
}

%% colors
\setbeamercolor{boxheadcolor}{fg=white,bg=UWRed}
\setbeamercolor{boxbodycolor}{fg=black,bg=white}


%%---------------------------------------------------------------------------%%
\author{Stuart R. Slattery
  \\ Engineering Physics Department
  \\ University of Wisconsin - Madison
}

\date{\today} 
\title{Massively Parallel Monte Carlo Methods for Discrete Linear and
  Nonlinear Systems} 
\begin{document}
\maketitle

%%---------------------------------------------------------------------------%%
\begin{frame}{Introduction}

  \begin{itemize}
    \item Predictive modeling and simulation enhances engineering
      capability
    \item Modern work focused on this task leverages multiple physics
      simulation (CASL, NEAMS)
    \item New hardware drives algorithm development (petascale and
      exascale)
    \item Monte Carlo methods have the potential to provide great
      improvements that permit finer simulations and better mapping to
      future hardware
    \item A set of massively parallel Monte Carlo methods is proposed
      to advance multiple physics simulation on contemporary and
      future leadership class machines
  \end{itemize}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Physics-Based Motivation}
 
  \begin{beamerboxesrounded}[upper=boxheadcolor,lower=boxbodycolor,shadow=true]
    {Predictive nuclear reactor analysis enables...}
    \begin{itemize}
    \item Tighter design tolerance for improved thermal performance
      and efficiency
    \item Higher fuel burn-up
    \item High confidence in accident scenario models
    \end{itemize}
  \end{beamerboxesrounded}

  \pause 
  \begin{beamerboxesrounded}[upper=boxheadcolor,lower=boxbodycolor,shadow=true]
  {Multiple physics simulations are complicated...}
    \begin{itemize}
    \item Neutronics, thermal hydraulics, computational fluid
      dynamics, structural mechanics, and many other physics
    \item Consistent models yield nonlinearities in the variables
      through feedback effects
    \item Tremendous computational resources are required with
      $O(\sn{1}{9})$ element meshes and $O(100,000)+$ cores used in
      today's simulations.
    \end{itemize}
  \end{beamerboxesrounded}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Physics-Based Motivation: DNB}

  \begin{columns}

    \begin{column}{0.35\textwidth}
      \begin{figure}[htpb!]
        \begin{center}
          \scalebox{1}{ \input{dnb_schematic.pdftex_t} }
        \end{center}
        \caption{\textbf{Departure from nucleate boiling scenario.} }
      \end{figure}
    \end{column}

    \pause

    \begin{column}{0.65\textwidth}
      \begin{figure}[htpb!]
        \begin{center}
          \scalebox{0.8}{ \input{dnb_example.pdftex_t} }
        \end{center}
        \caption{\textbf{Multiphysics dependency analysis of departure
            from nucleate boiling.} }
      \end{figure}
    \end{column}

  \end{columns}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Hardware-Based Motivation}

  \begin{itemize}
  \item Modern hardware is moving in two directions:
    \begin{itemize}
    \item Lightweight machines
    \item Heterogeneous machines
    \item Both characterized by low power and high concurrency
    \end{itemize}
  \item Some issues:
    \begin{itemize}
    \item Higher potential for both soft and hard failures
    \item Memory restrictions are expected with a continued decrease
      in memory/FLOPS
    \end{itemize}
  \item Potential resolution from Monte Carlo:
    \begin{itemize}
    \item Soft failures buried within the tally variance
    \item Hard failures are high variance events
    \item Memory savings over conventional methods
    \end{itemize}
  \end{itemize}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Research Outline}
  \begin{itemize}
    \item Parallelization of Monte Carlo methods for discrete systems
      \begin{itemize}
      \item Parallel strategies taken from modern reactor physics
        methods
      \item Research is required to explore varying parallel
        strategies
      \item Scalability is of concern
      \end{itemize}
    \item Development of a nonlinear solver leveraging Monte Carlo
      \begin{itemize}
        \item Application to nonlinear problems of interest
        \item Memory benefits
        \item Performance benefits
      \end{itemize}
  \end{itemize}
\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Linear Operator Equations}

  \begin{itemize}
  \item We seek solutions of the general linear operator equation
  \end{itemize}

  \[
  \ve{A} \ve{x} = \ve{b}\:
  \]
  \[
  \ve{A} \in \mathbb{R}^{N \times N},\ \ve{A} : \mathbb{R}^{N}
  \rightarrow \mathbb{R}^{N},\ \ve{x} \in \mathbb{R}^N,\ \ve{b} \in
  \mathbb{R}^N\:
  \]


  \[
  \ve{r} = \ve{b} - \ve{A}\ve{x}\:
  \]

  \begin{itemize}
  \item $\ve{r}=\ve{0}$ when an exact solution is found.
  \end{itemize}

  \pause
  \begin{beamerboxesrounded}[upper=boxheadcolor,lower=boxbodycolor,shadow=true]
    {A Requirement}
    Assert that $\ve{A}$ is \textit{nonsingular}. The solution is then:
    \[
    \ve{x} = \ve{A}^{-1}\ve{b}\:
    \]
  \end{beamerboxesrounded}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Stationary Methods}

  \begin{itemize}
  \item General stationary methods are formed by splitting the linear
    operator
  \end{itemize}

  \[
  \ve{A} = \ve{M} - \ve{N}\:.
  \]

  \[
  \ve{x} = \ve{M}^{-1}\ve{N}\ve{x} + \ve{M}^{-1}\ve{b}\:.
  \]

  \begin{itemize}
  \item We identify $\ve{H} =\ve{M}^{-1}\ve{N}$ as the
    \textit{iteration matrix}
  \end{itemize}

  \[
  \ve{x}^{k+1} = \ve{H}\ve{x}^{k} + \ve{c}\:.
  \]

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Stationary Methods Convergence}

  \begin{itemize}
  \item The qualities of the iteration matrix dictate convergence 
  \item Define $\ve{e}^k = \ve{x}^k-\ve{x}$ as the error at the
    $k^{th}$ iterate
  \end{itemize}

  \[
  \ve{e}^{k+1} = \ve{H} \ve{e}^k\:
  \]


  \begin{itemize}
  \item We diagonalize $\ve{H}$ to extract its Eigenvalues
  \end{itemize}

  \[
  ||\ve{e}^{k}||_2 = \rho(\ve{H})^k ||\ve{e}^0||_2\:,
  \]

  \begin{itemize}
  \item We bound $\ve{H}$ by $\rho(\ve{H}) < 1$ for convergence
  \end{itemize}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Projection Methods}

  \begin{itemize}
    \item Powerful class of iterative methods
    \item Provides theory that encapsulates most other iterative
      methods 
    \item Leveraged in many modern physics codes at the petascale
  \end{itemize}

  \pause
  \begin{beamerboxesrounded}[upper=boxheadcolor,lower=boxbodycolor,shadow=true]
    {Search Subspace $\mathcal{K}$} 
    Extract the solution from the search subspace:
    \[
    \tilde{\ve{x}} = \ve{x}_0 +
    \boldsymbol{\delta},\ \boldsymbol{\delta} \in \mathcal{K}\:
    \]
  \end{beamerboxesrounded}

  \pause
  \begin{beamerboxesrounded}[upper=boxheadcolor,lower=boxbodycolor,shadow=true]
    {Constraint Subspace $\mathcal{L}$} 
    Constrain the extraction with the constraint subspace by asserting
    orthogonality with the residual:
    \[
    \langle \tilde{\ve{r}},\ve{w} \rangle = 0,\ \forall \ve{w} \in
    \mathcal{L}\:
    \]  
  \end{beamerboxesrounded}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{The Orthogonality Constraint}

  \[
  \tilde{\ve{r}} = \ve{r}_0 - \ve{A}\boldsymbol{\delta}
  \]

  \begin{figure}[htpb!]
    \begin{center}
      \scalebox{1.25}{
        \input{orthogonal_residual.pdftex_t} }
    \end{center}
    \caption{\textbf{Orthogonality constraint of the new residual with
        respect to $\mathcal{L}$.} }
  \end{figure}

  \pause
  \begin{beamerboxesrounded}[upper=boxheadcolor,lower=boxbodycolor,shadow=true]
    {Minimization Property}

    The residual of the system will always be \textit{minimized} with
    respect to the constraints
    \[
    ||\tilde{\ve{r}}||_2 \leq ||\ve{r}_0||_2,\ \forall \ve{r}_0 \in
    \mathbb{R}^N\:,
    \]
  \end{beamerboxesrounded}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Putting it All Together}

  \begin{itemize}
  \item Choose $\ve{V}$ as a basis of $\mathcal{K}$ and $\ve{W}$ as a
    basis of $\mathcal{L}$
  \end{itemize}

  \[
  \boldsymbol{\delta} = \ve{V}\ve{y},\ \forall \ve{y} \in
  \mathbb{R}^N
  \]

  \[
  \ve{y} = (\ve{W}^T\ve{A}\ve{V})^{-1}\ve{W}^T\ve{r}_0
  \]

  \pause
  \begin{beamerboxesrounded}[upper=boxheadcolor,lower=boxbodycolor,shadow=true]
    {Projection Method Iteration}
  \[
  \ve{r}^k = \ve{b} - \ve{A}\ve{x}^k
  \]
  \[
  \ve{y}^k = (\ve{W}^T\ve{A}\ve{V})^{-1}\ve{W}^T\ve{r}^k
  \]
  \[
  \ve{x}^{k+1} = \ve{x}^k + \ve{V}\ve{y}^k\:
  \]
  \[
  Update\ \ve{V}\ and\ \ve{W}
  \]
  \end{beamerboxesrounded}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Krylov Subspace Methods}

  \[
  \mathcal{K}_m(\ve{A},\ve{r}_0) = span\{\ve{r}_0, \ve{A}\ve{r}_0,
  \ve{A}^2\ve{r}_0, \dots, \ve{A}^{m-1}\ve{r}_0\}
  \]
  \[
  \mathcal{L} = \ve{A} \mathcal{K}_m(\ve{A},\ve{r}_0)
  \]

  \begin{itemize}
  \item Yields the normal system $\ve{A}^T\ve{A}\ve{x} =
    \ve{A}^T\ve{b}$
  \item Must generate an orthonormal basis $\ve{V}_m \in \mathbb{R}^{N
    \times m}$ for $\mathcal{K}_m(\ve{A},\ve{r}_0)$
  \item $\ve{W}_m = \ve{A}\ve{V}_m$
  \item Typically choose a Gram-Schmidt-like procedure such as
    Arnoldi or Lanzcos
  \end{itemize}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}[fragile]{GMRES}

\begin{algorithm}[H]
  \begin{algorithmic}[1]
    \STATE $\ve{r}_0 := \ve{b}-\ve{A}\ve{x}_0$
    \STATE $\beta := ||\ve{r}_0||_2$
    \STATE $\ve{v}_1 := \ve{r}_0 / \beta$
    \COMMENT{Create the orthonormal basis for the Krylov subspace}
    \FOR{$j = 1, 2, \cdots, m$}
    \STATE $h_{ij} \leftarrow \langle w_j,v_j \rangle$
    \STATE $w_j \leftarrow w_j - h_{ij}v_i$
    \ENDFOR
    \STATE $h_{j+1,j} \leftarrow ||w_j||_2$
    \STATE $v_{j+1} \leftarrow w_j / h_{j+1,j}$
    \COMMENT{Apply the orthogonality constraints}
    \STATE $\ve{y}_m \leftarrow argmin_y ||\beta \ve{e}_1 - \ve{H}_m\
    \ve{y}||_2 $
    \STATE $\ve{x}_m \leftarrow \ve{x}_0 + \ve{V_m} \ve{y}_m$
  \end{algorithmic}
  \caption{GMRES Iteration}
\end{algorithm}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Parallel Projection Methods}
  
  \begin{itemize}
  \item Parallel vector update
  \end{itemize}
  \[
  \ve{y}[n] \leftarrow \ve{y}[n] + a * \ve{x}[n],\ \forall n \in [1,N_g]
  \]
  \[
  \ve{y}[n] \leftarrow \ve{y}[n] + a * \ve{x}[n],\ \forall n \in [1,N_l]
  \]
  
  \begin{itemize}
  \item Parallel dot product
  \end{itemize}
  \[
  d_l = \ve{y}_l \cdot \ve{x}_l,\ d_g = \sum_p d_l
  \]

  \begin{itemize}
  \item Parallel vector norm
  \end{itemize}
  \[
  ||x||_{\infty,l} = \max_n \ve{y}[n],\ \forall n \in [1,N_l]
  \]
  \[
  ||x||_{\infty,g} = \max_p ||x||_{\infty,l}
  \]
  
\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Parallel Matrix-Vector Multiplication}

\begin{figure}[htpb!]
  \begin{center}
    \scalebox{0.75}{
      \input{partitioned_matrix.pdftex_t} }
  \end{center}
  \caption{\textbf{Matrix-vector multiply $\ve{A}\ve{x}=\ve{y}$
      operation on 3 processors.}
  \label{fig:partitioned_matvec_multiply} }
\end{figure}

\pause
\begin{figure}[htpb!]
  \begin{center}
    \scalebox{0.75}{
      \input{matvec_proc_1.pdftex_t} }
  \end{center}
  \caption{\textbf{Components of multiply operation owned by process
      1.} }
  \label{fig:matvec_proc_1}
\end{figure}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Projection Method Notes}

\begin{itemize}
  \item Global reduction operations observed not to impede scalability
    \begin{itemize}
    \item Dot product
    \item Vector norms
    \end{itemize}
  \item Nearest neighbor computations have poor algorithmic strong
    scaling
    \begin{itemize}
      \item Matrix-vector multiply
      \item Weak scaling is better
    \end{itemize}
   
\end{itemize}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Monte Carlo Solution Methods for Discrete Linear Systems}

  \begin{itemize}
    \item First proposed by J. Von Neumann and S.M. Ulam in the 1940's
    \item Earliest published reference in 1950
    \item General lack of published work
    \item Modern work by Evans and others has yielded new applications
    \item No indication of parallel methods in the literature
  \end{itemize}
\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Monte Carlo Linear Solver Preliminaries}

  \begin{itemize}
  \item Split the operator
  \end{itemize}

  \[
  \ve{H} = \ve{I} - \ve{A}
  \]

  \[
  \ve{x} = \ve{H} \ve{x} + \ve{b}
  \]

  \begin{itemize}
  \item Generate the \textit{Neumann series}
  \end{itemize}
  
  \[
  \ve{A}^{-1} = (\ve{I}-\ve{H})^{-1} = \sum_{k=0}^{\infty} \ve{H}^k
  \]

  \begin{itemize}
  \item Require $\rho(\ve{H}) < 1$ for convergence
  \end{itemize}

  \[
  \ve{A}^{-1}\ve{b} = \sum_{k=0}^{\infty} \ve{H}^k\ve{b} = \ve{x}
  \]

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Monte Carlo Linear Solver Preliminaries}

  \begin{itemize}
  \item Expand the Nuemann series
  \end{itemize}

  \[
  x_i = \sum_{k=0}^{\infty}\sum_{i_1}^{N}\sum_{i_2}^{N}\ldots
  \sum_{i_k}^{N}h_{i,i_1}h_{i_1,i_2}\ldots h_{i_{k-1},i_k}b_{i_k}
  \]

  \begin{itemize}
  \item Define a sequence of state transitions
  \end{itemize}
  
  \[
  \nu = i \rightarrow i_1 \rightarrow \cdots \rightarrow i_{k-1}
  \rightarrow i_{k}
  \]

  \begin{itemize}
  \item Define the \textit{Neumann-Ulam decomposition}\footnote{The
    Hadamard product $\ve{A} = \ve{B} \circ \ve{C}$ is defined
    element-wise as $a_{ij} = b_{ij} c_{ij}$.}
  \end{itemize}

  \[
  \ve{H} = \ve{P} \circ \ve{W}
  \]

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Direct Method}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Adjoint Method}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Sequential Monte Carlo}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Monte Carlo Synthetic-Acceleration}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Parallelization of Stochastic Methods}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Monte Carlo Solution Methods for Nonlinear Problems}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Monte Carlo Nonlinear Solver Preliminaries}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Inexact Newton Methods}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{The FANM Method}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Research Proposal}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Experimental Framework}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Progress to Date}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Monte Carlo Methods Verification}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Proposed Numerical Experiments}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Proposed Challenge Problem}

\end{frame}

%%---------------------------------------------------------------------------%%
\begin{frame}{Conclusion}

\end{frame}

%%---------------------------------------------------------------------------%%

\end{document}


